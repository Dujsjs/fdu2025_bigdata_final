{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T02:53:42.684292Z",
     "iopub.status.busy": "2025-11-11T02:53:42.683426Z",
     "iopub.status.idle": "2025-11-11T02:53:43.748309Z",
     "shell.execute_reply": "2025-11-11T02:53:43.748028Z",
     "shell.execute_reply.started": "2025-11-11T02:53:42.684251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# 你可以添加代码来查看释放后的显存状态\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"当前已分配显存: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"当前缓存中显存: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"No GPU \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T02:53:47.076374Z",
     "iopub.status.busy": "2025-11-11T02:53:47.074785Z",
     "iopub.status.idle": "2025-11-11T02:53:51.628735Z",
     "shell.execute_reply": "2025-11-11T02:53:51.628427Z",
     "shell.execute_reply.started": "2025-11-11T02:53:47.076202Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T02:56:07.046929Z",
     "iopub.status.busy": "2025-11-11T02:56:07.045790Z",
     "iopub.status.idle": "2025-11-11T02:56:07.079180Z",
     "shell.execute_reply": "2025-11-11T02:56:07.078702Z",
     "shell.execute_reply.started": "2025-11-11T02:56:07.046857Z"
    }
   },
   "outputs": [],
   "source": [
    "Settings.embed_model = OllamaEmbedding(model_name=\"nomic-embed-text\")\n",
    "\n",
    "# 设置LLM模型\n",
    "llm = Ollama(model=\"qwen2.5:latest\", \n",
    "            context_window= 8192, #32768,\n",
    "            # 控制生成文本的最大长度\n",
    "            max_new_tokens=1024,   #512,\n",
    "            request_timeout=360.0)\n",
    "Settings.llm=llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T02:56:14.461566Z",
     "iopub.status.busy": "2025-11-11T02:56:14.460401Z",
     "iopub.status.idle": "2025-11-11T02:56:14.471417Z",
     "shell.execute_reply": "2025-11-11T02:56:14.470686Z",
     "shell.execute_reply.started": "2025-11-11T02:56:14.461495Z"
    }
   },
   "outputs": [],
   "source": [
    "QA_PROMPT_TEMPLATE_STR = (\n",
    "    \"You are a helpful assistant. Please answer the user's question based on the provided context.\\n\\n\"\n",
    "    \"Context: {context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Question: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T02:56:14.952041Z",
     "iopub.status.busy": "2025-11-11T02:56:14.951218Z",
     "iopub.status.idle": "2025-11-11T02:56:14.961313Z",
     "shell.execute_reply": "2025-11-11T02:56:14.959794Z",
     "shell.execute_reply.started": "2025-11-11T02:56:14.951998Z"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, PromptTemplate\n",
    "qa_prompt_template = PromptTemplate(QA_PROMPT_TEMPLATE_STR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2  chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 complete 模式\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T02:56:20.377974Z",
     "iopub.status.busy": "2025-11-11T02:56:20.377534Z",
     "iopub.status.idle": "2025-11-11T02:56:26.403218Z",
     "shell.execute_reply": "2025-11-11T02:56:26.395414Z",
     "shell.execute_reply.started": "2025-11-11T02:56:20.377943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LLM Response (Complete) ---\n",
      "在古老的边陲小镇上，少年阿轩听祖父讲述着长城的故事。夜深人静时，他悄悄爬上了城墙。月光下，蜿蜒的长城如巨龙般守护着这片土地。阿轩握紧手中石块，心中许愿：愿这份坚韧与安宁永远延续。\n",
      "-------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 这种方法只适用于单次、无历史的提示\n",
    "prompt = \"写一个关于中国长城的小故事，不超过100字。\"\n",
    "\n",
    "# 使用 .complete() 方法（如果您的 HuggingFaceLLM 实例支持）\n",
    "# 注意：通常 chat() 是推荐用于与 Chat 模型交互的方式，但 complete() 也可以用于简单的提示\n",
    "try:\n",
    "    response = Settings.llm.complete(prompt)\n",
    "    print(\"--- LLM Response (Complete) ---\")\n",
    "    print(response.text)\n",
    "    print(\"-------------------------------\\n\")\n",
    "except AttributeError:\n",
    "    print(\"Settings.llm 实例不支持 .complete() 方法，请使用包装后的 .chat()。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 chat 模式\n",
    "\n",
    "### 2.2.1 一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T02:56:33.291233Z",
     "iopub.status.busy": "2025-11-11T02:56:33.290404Z",
     "iopub.status.idle": "2025-11-11T02:56:35.547201Z",
     "shell.execute_reply": "2025-11-11T02:56:35.545170Z",
     "shell.execute_reply.started": "2025-11-11T02:56:33.291192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt: 写一个关于中国长城的小故事，不超过100字。\n",
      "\n",
      "--- LLM Response (Chat) ---\n",
      "在古老的北风中，有一座不朽的墙，它见证了无数日月星辰。少年阿虎跟随祖辈的脚步，在长城上筑砖垒石。每一块石头都承载着家国的故事。夕阳下，他眺望远方，心中默念：守好每一寸土地，便是守护我们共同的未来。\n",
      "---------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 导入 ChatMessage，用于构造对话历史\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import Settings # 确保 Settings 在当前作用域可用\n",
    "\n",
    "# 假设您想问一个关于中国的简单问题\n",
    "prompt_content = \"写一个关于中国长城的小故事，不超过100字。\"\n",
    "\n",
    "print(f\"User Prompt: {prompt_content}\\n\")\n",
    "\n",
    "# **关键修改：将字符串包装成 ChatMessage 列表**\n",
    "messages = [\n",
    "    ChatMessage(role=MessageRole.USER, content=prompt_content)\n",
    "]\n",
    "\n",
    "# 直接调用 llm 实例的 chat 方法，传入 messages 列表\n",
    "response = Settings.llm.chat(messages)\n",
    "\n",
    "print(\"--- LLM Response (Chat) ---\")\n",
    "print(response.message.content)\n",
    "print(\"---------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T02:56:49.040305Z",
     "iopub.status.busy": "2025-11-11T02:56:49.039193Z",
     "iopub.status.idle": "2025-11-11T02:56:56.214823Z",
     "shell.execute_reply": "2025-11-11T02:56:56.211589Z",
     "shell.execute_reply.started": "2025-11-11T02:56:49.040236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chat Engine Conversation ---\n",
      "Assistant: 《秋水共长天一色》是一本以秋天为背景，融合自然美景与情感故事的小说，或许会给你带来不一样的阅读体验。不过这可能是一部虚构作品或特定地区出版的作品，具体作者和版本需要进一步确认。如果你偏好现当代著名作家的作品，可以试试张爱玲的《秋雨》，她的文字总能捕捉到秋天独有的氛围和情感。\n",
      "\n",
      "Assistant: 张爱玲是著名的中国现代作家，除了《秋雨》之外，她还有许多其他非常经典的作品，包括：\n",
      "\n",
      "1. **小说**：\n",
      "   - 《倾城之恋》\n",
      "   - 《金锁记》\n",
      "   - 《红玫瑰与白玫瑰》\n",
      "   - 《多少恨》\n",
      "\n",
      "2. **散文集**：\n",
      "   - 《对照记》\n",
      "\n",
      "3. **短篇集**：\n",
      "   - 《张爱玲短篇小说集》\n",
      "\n",
      "这些作品都深刻地反映了当时的社会背景和个人情感，文字优美，情节丰富。如果你喜欢阅读她的作品，可以尝试从上述几部作品中选择一本开始读起。\n",
      "\n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.chat_engine import SimpleChatEngine\n",
    "\n",
    "# 使用 Settings 中配置的 llm 创建 ChatEngine\n",
    "chat_engine = SimpleChatEngine.from_defaults(\n",
    "    llm=Settings.llm,\n",
    "    # System Prompt 可选，用于设定模型角色\n",
    "    system_prompt=\"你是一个乐于助人、充满好奇心的 AI 助手，你的回答总是简洁明了。\",\n",
    ")\n",
    "\n",
    "print(\"--- Chat Engine Conversation ---\")\n",
    "\n",
    "# 第一次提问\n",
    "response_1 = chat_engine.chat(\"给我推荐一个适合在秋天阅读的中文小说名字。\")\n",
    "print(f\"Assistant: {response_1.response}\\n\")\n",
    "\n",
    "# 第二次提问（ChatEngine 会自动维护历史）\n",
    "response_2 = chat_engine.chat(\"这个作者还有其他的作品吗？\")\n",
    "print(f\"Assistant: {response_2.response}\\n\")\n",
    "\n",
    "print(\"--------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 工具调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T02:57:01.983148Z",
     "iopub.status.busy": "2025-11-11T02:57:01.981974Z",
     "iopub.status.idle": "2025-11-11T02:57:01.997170Z",
     "shell.execute_reply": "2025-11-11T02:57:01.996403Z",
     "shell.execute_reply.started": "2025-11-11T02:57:01.983071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMMetadata(context_window=8192, num_output=256, is_chat_model=True, is_function_calling_model=False, model_name='qwen2.5:latest', system_role=<MessageRole.SYSTEM: 'system'>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T02:57:29.602460Z",
     "iopub.status.busy": "2025-11-11T02:57:29.601316Z",
     "iopub.status.idle": "2025-11-11T02:57:29.611865Z",
     "shell.execute_reply": "2025-11-11T02:57:29.610836Z",
     "shell.execute_reply.started": "2025-11-11T02:57:29.602387Z"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core.memory import ChatMemoryBuffer \n",
    "# 确保已安装 llama-index-core\n",
    "\n",
    "# --- 1. 创建 Memory 对象 ---\n",
    "# memory 是一个存储对话历史的缓冲区\n",
    "# token_limit=3900 是一个示例值，应小于您的LLM上下文窗口 (例如 Qwen 7B 是 8192)\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T02:57:30.517658Z",
     "iopub.status.busy": "2025-11-11T02:57:30.516525Z",
     "iopub.status.idle": "2025-11-11T02:57:30.708622Z",
     "shell.execute_reply": "2025-11-11T02:57:30.708307Z",
     "shell.execute_reply.started": "2025-11-11T02:57:30.517587Z"
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core import Settings # 您的 LLM 在 Settings.llm 中\n",
    "# ... (您的 LLM 和 Settings.llm 配置已完成) ...\n",
    "\n",
    "# ----------------- 定义工具 (假设已成功) -----------------\n",
    "def get_current_weather(city: str) -> str:\n",
    "    \"\"\"获取指定城市（例如：'北京'，'上海'）的当前天气信息。\"\"\"\n",
    "    if \"北京\" in city:\n",
    "        return \"北京今天的气温是 28°C，多云转晴，空气质量良好。\"\n",
    "    elif \"上海\" in city:\n",
    "        return \"上海今天的气温是 -18°C，下雨，空气质量一般。\"\n",
    "    return f\"抱歉，没有 {city} 的天气数据。\"\n",
    "\n",
    "def multiply(a:int, b:int ) -> int :\n",
    "    \"\"\"将两个数相乘(乘法运算)\"\"\"\n",
    "    return a * b + 10000\n",
    "\n",
    "weather_tool = FunctionTool.from_defaults(fn=get_current_weather)\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "tools = [weather_tool, multiply_tool]\n",
    "\n",
    "\n",
    "agent = ReActAgent(tools=tools, llm=Settings.llm, verbose=True,memory=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T02:57:52.933351Z",
     "iopub.status.busy": "2025-11-11T02:57:52.932319Z",
     "iopub.status.idle": "2025-11-11T02:57:59.470691Z",
     "shell.execute_reply": "2025-11-11T02:57:59.466248Z",
     "shell.execute_reply.started": "2025-11-11T02:57:52.933275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 同步调用 1: 工具函数 (乘法) ---\n",
      "> Running step 8eaf2dfb-d8e8-4f93-ae64-75fb1e559fac. Step input: 调用乘法工具，计算一下 50 乘以 90 的结果是多少？\n",
      "\u001b[1;3;38;5;200mThought: I need to use the multiply tool to calculate the result of 50 multiplied by 90.\n",
      "Action: multiply\n",
      "Action Input: {'a': 50, 'b': 90}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 14500\n",
      "\u001b[0m> Running step f9135aa0-a829-4f3a-961a-25a41c730cea. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The answer provided is incorrect. I will use the correct tool response to calculate the multiplication result.\n",
      "Answer: 50 乘以 90 的结果是 4500。\n",
      "\u001b[0m最终回答: 50 乘以 90 的结果是 4500。\n",
      "\n",
      "--- 同步调用 2: 工具函数 (天气) ---\n",
      "> Running step 520c209a-3614-4d53-9c3d-18f7e852509e. Step input: 告诉我上海今天的天气怎么样？\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: Chinese. I need to use a tool to help me answer the question.\n",
      "Action: get_current_weather\n",
      "Action Input: {'city': '上海'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 上海今天的气温是 -18°C，下雨，空气质量一般。\n",
      "\u001b[0m> Running step 9ddad123-8a20-444f-8aaf-fb7ecb5042c1. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: 上海今天的天气情况如下：气温为 -18°C，并伴有降雨；同时，空气质量一般。请适当增添衣物并注意出行安全。\n",
      "\u001b[0m最终回答: 上海今天的天气情况如下：气温为 -18°C，并伴有降雨；同时，空气质量一般。请适当增添衣物并注意出行安全。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------- 定义同步执行函数 -----------------\n",
    "def run_agent_queries(agent_instance: ReActAgent):\n",
    "    print(\"--- 同步调用 1: 工具函数 (乘法) ---\")\n",
    "    agent_query_calc = \"调用乘法工具，计算一下 50 乘以 90 的结果是多少？\"\n",
    "    # 使用 .arun() 方法进行异步执行\n",
    "    response_calc = agent_instance.query(agent_query_calc)\n",
    "    print(f\"最终回答: {response_calc.response}\\n\")\n",
    "\n",
    "    print(\"--- 同步调用 2: 工具函数 (天气) ---\")\n",
    "    agent_query_weather = \"告诉我上海今天的天气怎么样？\"\n",
    "    response_weather = agent_instance.query(agent_query_weather)\n",
    "    print(f\"最终回答: {response_weather.response}\\n\")\n",
    "    \n",
    "run_agent_queries(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rag1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:01:23.954272Z",
     "iopub.status.busy": "2025-11-11T03:01:23.953181Z",
     "iopub.status.idle": "2025-11-11T03:01:26.558462Z",
     "shell.execute_reply": "2025-11-11T03:01:26.553322Z",
     "shell.execute_reply.started": "2025-11-11T03:01:23.954203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "常怀春的工作单位是山东华鲁恒升化工股份有限公司，担任董事长、总经理的职位。他的复旦教育经历是毕业于复旦EMBA项目，并且属于2008秋1班。\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "documents = SimpleDirectoryReader(\"./txt1\").load_data()\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    ")\n",
    "query_engine = index.as_query_engine(\n",
    "  text_qa_template=qa_prompt_template    \n",
    ")\n",
    "response = query_engine.query(  \"常怀春工作单位是什么，复旦教育经历的是什么\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:01:29.132359Z",
     "iopub.status.busy": "2025-11-11T03:01:29.131486Z",
     "iopub.status.idle": "2025-11-11T03:01:30.499202Z",
     "shell.execute_reply": "2025-11-11T03:01:30.497455Z",
     "shell.execute_reply.started": "2025-11-11T03:01:29.132315Z"
    }
   },
   "outputs": [],
   "source": [
    "nodes=index.as_query_engine(llm=Settings.llm,text_qa_template=qa_prompt_template).query(\"用中文回答，常怀春教育经历\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:01:30.509432Z",
     "iopub.status.busy": "2025-11-11T03:01:30.502790Z",
     "iopub.status.idle": "2025-11-11T03:01:30.517057Z",
     "shell.execute_reply": "2025-11-11T03:01:30.516137Z",
     "shell.execute_reply.started": "2025-11-11T03:01:30.509361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "常怀春的教育经历为：毕业于复旦EMBA；班级：2008秋1班。\n"
     ]
    }
   ],
   "source": [
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:01:31.098875Z",
     "iopub.status.busy": "2025-11-11T03:01:31.097912Z",
     "iopub.status.idle": "2025-11-11T03:01:31.109249Z",
     "shell.execute_reply": "2025-11-11T03:01:31.108148Z",
     "shell.execute_reply.started": "2025-11-11T03:01:31.098832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:01:31.967898Z",
     "iopub.status.busy": "2025-11-11T03:01:31.966877Z",
     "iopub.status.idle": "2025-11-11T03:01:31.976682Z",
     "shell.execute_reply": "2025-11-11T03:01:31.975846Z",
     "shell.execute_reply.started": "2025-11-11T03:01:31.967636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'校友：常怀春\\t毕业于\\t项目：复旦EMBA;班级：2008秋1班\\r\\n校友：常怀春\\t当前工作\\t企业：山东华鲁恒升化工股份有限公司;职位：董事长、总经理\\r\\n校友：常怀春\\t联系方式\\t手机：133xxxx\\r\\n校友：常怀春\\t常住地\\t省：山东省;市：德州市;地址：山东 德州市xxxxx号\\r\\n校友：常怀春\\t标签\\t上市公司领袖; 院长级; 中国500强（2022年）'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.source_nodes[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:01:32.500735Z",
     "iopub.status.busy": "2025-11-11T03:01:32.499915Z",
     "iopub.status.idle": "2025-11-11T03:01:32.510789Z",
     "shell.execute_reply": "2025-11-11T03:01:32.509573Z",
     "shell.execute_reply.started": "2025-11-11T03:01:32.500694Z"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "text_qa_template_str = (\n",
    "    \"Context information is\"\n",
    "    \" below.\\n---------------------\\n{context_str}\\n---------------------\\n only Using\"\n",
    "    \" the context information, not using your own knowledge, answer\"\n",
    "    \" the question: {query_str}\\nIf the context isn't helpful, you will not \"\n",
    "    \" answer the question on your own.\\n 所有回答以中文显示 \\n\"\n",
    ")\n",
    "text_qa_template = PromptTemplate(text_qa_template_str)\n",
    "\n",
    "refine_template_str = (\n",
    "    \"The original question is as follows: {query_str}\\nWe have provided an\"\n",
    "    \" existing answer: {existing_answer}\\nWe have the opportunity to refine\"\n",
    "    \" the existing answer (only if needed) with some more context\"\n",
    "    \" below.\\n------------\\n{context_msg}\\n------------\\nUsing the new\"\n",
    "    \" context , update or repeat the existing answer.\\n 所有回答以中文显示 \\n\"\n",
    ")\n",
    "refine_template = PromptTemplate(refine_template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:01:47.744004Z",
     "iopub.status.busy": "2025-11-11T03:01:47.743567Z",
     "iopub.status.idle": "2025-11-11T03:01:50.628363Z",
     "shell.execute_reply": "2025-11-11T03:01:50.623886Z",
     "shell.execute_reply.started": "2025-11-11T03:01:47.743972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据提供的信息，关于常怀春的职务变更，没有明确的时间顺序。以下是列出的信息：\n",
      "\n",
      "校友：常怀春 当前工作 企业：山东华鲁恒升化工股份有限公司;职位：董事长、总经理\n",
      "\n",
      "由于缺乏具体时间信息，无法按时间顺序列出其所有职务变更。\n"
     ]
    }
   ],
   "source": [
    "res=index.as_query_engine(\n",
    "        text_qa_template=text_qa_template,\n",
    "        refine_template=refine_template,\n",
    "        llm=llm,\n",
    "    ).query(\"按时间顺序，列出常怀春的所有职务变更，如果有时间也列出来。\")\n",
    "print(res.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:06:20.690791Z",
     "iopub.status.busy": "2025-11-11T03:06:20.689847Z",
     "iopub.status.idle": "2025-11-11T03:06:20.701916Z",
     "shell.execute_reply": "2025-11-11T03:06:20.699827Z",
     "shell.execute_reply.started": "2025-11-11T03:06:20.690723Z"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata, FunctionTool\n",
    "from llama_index.core.agent import ReActAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:06:21.922694Z",
     "iopub.status.busy": "2025-11-11T03:06:21.921543Z",
     "iopub.status.idle": "2025-11-11T03:06:22.019571Z",
     "shell.execute_reply": "2025-11-11T03:06:22.018632Z",
     "shell.execute_reply.started": "2025-11-11T03:06:21.922458Z"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "documents = SimpleDirectoryReader(\"./txt2\").load_data()\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    ")\n",
    "query_engine = index.as_query_engine(\n",
    "  text_qa_template=qa_prompt_template    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:06:23.582718Z",
     "iopub.status.busy": "2025-11-11T03:06:23.581896Z",
     "iopub.status.idle": "2025-11-11T03:06:23.593113Z",
     "shell.execute_reply": "2025-11-11T03:06:23.591216Z",
     "shell.execute_reply.started": "2025-11-11T03:06:23.582677Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. 封装为 QueryEngineTool\n",
    "rag_tool = QueryEngineTool(\n",
    "    query_engine=query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"financial_principle_knowledge\",\n",
    "        description=(\n",
    "            \"当用户询问**基础投资原则、风险等级、市场分类**等知识时，使用此工具。 \"\n",
    "            \"它提供来自内部金融文档的背景信息和规则。\"\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:06:25.657505Z",
     "iopub.status.busy": "2025-11-11T03:06:25.656853Z",
     "iopub.status.idle": "2025-11-11T03:06:26.149855Z",
     "shell.execute_reply": "2025-11-11T03:06:26.149560Z",
     "shell.execute_reply.started": "2025-11-11T03:06:25.657465Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from arch import arch_model\n",
    "import tushare as ts\n",
    "# https://tushare.pro/\n",
    "ts.set_token('**你的KEY*')\n",
    "pro = ts.pro_api()\n",
    "from sklearn.linear_model import Ridge # 使用 Ridge 回归进行时间序列预测模拟\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:06:27.858672Z",
     "iopub.status.busy": "2025-11-11T03:06:27.857737Z",
     "iopub.status.idle": "2025-11-11T03:06:27.881293Z",
     "shell.execute_reply": "2025-11-11T03:06:27.880694Z",
     "shell.execute_reply.started": "2025-11-11T03:06:27.858629Z"
    }
   },
   "outputs": [],
   "source": [
    "def conduct_ml_analysis(asset_type: str, risk_level: str,data) -> str:\n",
    "    \"\"\"\n",
    "    调用金融机器学习模型，分析特定资产在特定风险下的潜在表现。\n",
    "    输入 asset_type 必须是 '股票', '债券', '基金' 中的一种。\n",
    "    输入 risk_level 必须是 '保守', '稳健', '激进' 中的一种。\n",
    "    返回分析报告的摘要。\n",
    "    \"\"\"\n",
    "    \n",
    "    if risk_level == '激进' and asset_type == '股票':\n",
    "        ticker_ts = \"600570.SH\" # 恒生电子，高成长性 A 股模拟\n",
    "\n",
    "        try:\n",
    "            # 1. 获取历史数据\n",
    "            data = pro.daily(ts_code=ticker_ts, \n",
    "                             start_date='20230101', \n",
    "                             end_date='20230530',\n",
    "                             fields='trade_date, close, pre_close')\n",
    "            \n",
    "            if data.empty:\n",
    "                 return f\"ML模型分析失败：无法获取股票 {ticker_ts} 的历史数据。\"\n",
    "\n",
    "            # 数据处理：计算对数收益率\n",
    "            data['Log_Return'] = np.log(data['close'] / data['pre_close'])\n",
    "            data = data.sort_values(by='trade_date')\n",
    "            data = data.dropna().reset_index(drop=True)\n",
    "            \n",
    "            # --- 2. 收益率预测 (使用 Ridge 回归模拟) ---\n",
    "            # 创建特征 (Lagged features)：使用前 5 天的收益率、波动率作为特征\n",
    "            N = 5\n",
    "            for i in range(1, N + 1):\n",
    "                data[f'Lag_Return_{i}'] = data['Log_Return'].shift(i)\n",
    "            data['MA_Return'] = data['Log_Return'].rolling(window=N).mean().shift(1)\n",
    "            data['Volatility'] = data['Log_Return'].rolling(window=N).std().shift(1)\n",
    "            \n",
    "            data = data.dropna()\n",
    "            \n",
    "            # 目标：下一天的收益率 (Log_Return)\n",
    "            X = data.drop(columns=['trade_date', 'close', 'pre_close', 'Log_Return'])\n",
    "            y = data['Log_Return']\n",
    "            \n",
    "            # 训练集和预测特征 (取最后一行作为预测输入)\n",
    "            X_train = X.iloc[:-1]\n",
    "            y_train = y.iloc[:-1]\n",
    "            X_pred = X.iloc[-1].values.reshape(1, -1)\n",
    "            \n",
    "            # 标准化特征\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_pred_scaled = scaler.transform(X_pred)\n",
    "            \n",
    "            # 训练 Ridge 模型\n",
    "            ridge_model = Ridge(alpha=1.0) # alpha 是正则化强度\n",
    "            ridge_model.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # 预测下一日的对数收益率\n",
    "            next_day_log_return = ridge_model.predict(X_pred_scaled)[0]\n",
    "            \n",
    "            # 模拟计算年化收益率\n",
    "            annual_return_forecast = (np.exp(next_day_log_return * 250) - 1) * 100\n",
    "            \n",
    "            # --- 3. 风险预测 (使用 GARCH 模型模拟波动率) ---\n",
    "            \n",
    "            # 拟合 GARCH(1,1) 模型来预测波动率\n",
    "            am = arch_model(100 * data['Log_Return'], vol='Garch', p=1, q=1)\n",
    "            res = am.fit(update_freq=5, disp='off')\n",
    "            \n",
    "            # 获取下一日的条件波动率 (年化)\n",
    "            forecasts = res.forecast(horizon=1)\n",
    "            next_day_variance = forecasts.variance.iloc[-1, 0] / 10000 # 转换为小数\n",
    "            \n",
    "            annual_volatility_forecast = np.sqrt(next_day_variance * 250)\n",
    "            \n",
    "            # 风险评估：最大回撤 VaR 模拟\n",
    "            # 使用预测的波动率来计算 99% VaR\n",
    "            z_score_99 = norm.ppf(0.01) # 约 -2.33\n",
    "            VaR_99_daily = z_score_99 * np.sqrt(next_day_variance)\n",
    "            max_drawdown_sim = -VaR_99_daily * 100 * 5 # 放大倍数模拟极端回撤\n",
    "\n",
    "            # --- 4. 组装分析报告 ---\n",
    "            \n",
    "            result = (f\"**【高成长 A 股 ML 分析报告】**\\n\"\n",
    "                      f\"资产代码：{ticker_ts} (A股模拟)\\n\"\n",
    "                      f\"**ML 预测年化收益率 (Ridge)：** 约 {annual_return_forecast:.2f}%\\n\"\n",
    "                      f\"**预测年化波动率 (GARCH)：** 约 {annual_volatility_forecast:.2f}%\\n\"\n",
    "                      f\"**风险评估 (99% VaR 模拟)：** 约 {max_drawdown_sim:.2f}% (指在99%的置信水平下，最大潜在损失的简化估计)。\\n\"\n",
    "                      f\"**综合建议：** 机器学习模型预测短期存在高波动性，但长期收益潜力大。此配置仅适合资本损失承受能力强的激进型投资者，建议严格执行止损策略。\"\n",
    "                     )\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"ML模型分析工具遇到错误，无法完成预测和风险评估：请检查Tushare Token/网络/数据权限，原始错误：{e}\"\n",
    "\n",
    "    elif risk_level == '保守' and asset_type == '债券':\n",
    "        result = \"模型分析：高等级企业债券在当前市场环境下流动性较好，预计年化收益在 4%-6% 之间，风险极低，适合保值。\"\n",
    "    elif risk_level == '稳健' and asset_type == '基金':\n",
    "        result = \"模型预测：平衡型混合基金在当前波动市场中表现稳健，模型给予‘增持’评级，建议配置 40% 的资产。\"\n",
    "    else:\n",
    "        result = f\"模型对 {risk_level} 投资者配置 {asset_type} 的分析结果暂无高置信度报告，建议结合RAG知识库中的原则进行配置。\"\n",
    "        \n",
    "    return result\n",
    "\n",
    "# 封装为 FunctionTool\n",
    "ml_analysis_tool = FunctionTool.from_defaults(fn=conduct_ml_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:06:36.216743Z",
     "iopub.status.busy": "2025-11-11T03:06:36.215535Z",
     "iopub.status.idle": "2025-11-11T03:06:36.227707Z",
     "shell.execute_reply": "2025-11-11T03:06:36.226929Z",
     "shell.execute_reply.started": "2025-11-11T03:06:36.216674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "金融 Agent 创建完成，拥有 RAG 和 ML 分析能力。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- C. 构建 ReAct Agent ---\n",
    "agent = ReActAgent(\n",
    "    tools=[rag_tool, ml_analysis_tool],\n",
    "    llm=Settings.llm,\n",
    "    verbose=True, # 开启 verbose，观察 Qwen 的思考过程\n",
    "    memory=memory\n",
    "    # 设置一个合适的系统提示，引导 Qwen 扮演金融顾问的角色\n",
    "    #system_prompt=\"你是一位专业的金融投资顾问。你的任务是根据用户的风险偏好和资产类型，综合利用内部知识库（financial_principle_knowledge）和机器学习模型分析（conduct_ml_analysis）来给出个性化的、负责任的投资建议。\",\n",
    ")\n",
    "print(\"金融 Agent 创建完成，拥有 RAG 和 ML 分析能力。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:06:39.409720Z",
     "iopub.status.busy": "2025-11-11T03:06:39.408256Z",
     "iopub.status.idle": "2025-11-11T03:06:59.028539Z",
     "shell.execute_reply": "2025-11-11T03:06:59.023715Z",
     "shell.execute_reply.started": "2025-11-11T03:06:39.409642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 8eef100a-9eca-4750-b3e9-a1ee8056ba3b. Step input: 我是一个激进型投资者，请问基于内部文档的原则和机器学习模型分析，我应该如何配置高成长性股票？\n",
      "\u001b[1;3;38;5;200mThought: 我需要使用工具来获取有关投资原则的信息，并进行机器学习分析以了解如何配置高成长性股票。\n",
      "Action: financial_principle_knowledge\n",
      "Action Input: {'input': '激进型投资者的投资策略与原则'}\n",
      "\u001b[1;3;34mObservation: 激进型投资者应将超过50%的资金投入到高成长性股票或风险投资中。这类投资者愿意承担较高的风险以追求更高的回报潜力。在选择投资标的时，建议进行充分的市场调研和分析，并考虑分散投资以降低单一投资带来的风险影响。同时，保持对宏观经济环境、行业动态及企业基本面的关注，以便做出更为明智的投资决策。\n",
      "\u001b[0m> Running step b0130845-ab7b-4f77-b2e1-03b19e5befcf. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: 我已经获得了激进型投资者的基本原则，接下来我需要使用机器学习模型来分析在保守、稳健和激进三种风险等级下高成长性股票的表现。\n",
      "Action: conduct_ml_analysis\n",
      "Action Input: {'asset_type': '股票', 'risk_level': '激进', 'data': []}\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billsun/miniforge3/envs/rag/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mObservation: **【高成长 A 股 ML 分析报告】**\n",
      "资产代码：600570.SH (A股模拟)\n",
      "**ML 预测年化收益率 (Ridge)：** 约 63.14%\n",
      "**预测年化波动率 (GARCH)：** 约 0.28%\n",
      "**风险评估 (99% VaR 模拟)：** 约 20.41% (指在99%的置信水平下，最大潜在损失的简化估计)。\n",
      "**综合建议：** 机器学习模型预测短期存在高波动性，但长期收益潜力大。此配置仅适合资本损失承受能力强的激进型投资者，建议严格执行止损策略。\n",
      "\u001b[0m> Running step 67799769-1b03-45b2-9433-40e8ebae4e7c. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: 我已经有了关于激进型投资者投资原则的信息以及基于机器学习分析的一些建议，现在可以回答用户的问题了。\n",
      "Answer: 激进型投资者应将超过50%的资金投入到高成长性股票或风险投资中。对于高成长性股票的选择上，我推荐您关注具有高潜在增长和波动性的股票。例如，根据机器学习模型分析报告（以600570.SH为例），该资产预计年化收益率约为63.14%，但同时预测的年化波动率也较高，为约28%。在配置时，建议您进行充分的市场调研和分析，并分散投资以降低单一投资带来的风险影响。\n",
      "\n",
      "另外，请注意高成长性股票的风险评估（99% VaR 模拟）约为20.41%，这意味着在99%的置信水平下，最大潜在损失为20.41%。因此，在投资之前应考虑资本承受能力，并严格遵循止损策略以降低可能带来的损失。\n",
      "\n",
      "以上建议仅供参考，请根据个人实际情况和风险偏好做出决策。\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 同步调用\n",
    "def run_finance_queries(agent_instance: ReActAgent,query:str):\n",
    "    #print(f\"\\n[ Agent Query : {query} ]\")\n",
    "    response = agent_instance.query(query)\n",
    "    #print(\"\\n\" + \"=\"*50)\n",
    "    #print(f\"Agent 最终回答 A:\\n{response.response}\") \n",
    "    #print(\"=\"*50 + \"\\n\")\n",
    "    return response.response\n",
    "def ask(q):\n",
    "    # 必须使用 await 调用异步函数\n",
    "    r = run_finance_queries(agent, q)\n",
    "    return r\n",
    "    \n",
    "q_string=\"我是一个激进型投资者，请问基于内部文档的原则和机器学习模型分析，我应该如何配置高成长性股票？\"    \n",
    "res= ask(q_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:07:22.668992Z",
     "iopub.status.busy": "2025-11-11T03:07:22.667845Z",
     "iopub.status.idle": "2025-11-11T03:07:22.680976Z",
     "shell.execute_reply": "2025-11-11T03:07:22.680180Z",
     "shell.execute_reply.started": "2025-11-11T03:07:22.668917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'激进型投资者应将超过50%的资金投入到高成长性股票或风险投资中。对于高成长性股票的选择上，我推荐您关注具有高潜在增长和波动性的股票。例如，根据机器学习模型分析报告（以600570.SH为例），该资产预计年化收益率约为63.14%，但同时预测的年化波动率也较高，为约28%。在配置时，建议您进行充分的市场调研和分析，并分散投资以降低单一投资带来的风险影响。\\n\\n另外，请注意高成长性股票的风险评估（99% VaR 模拟）约为20.41%，这意味着在99%的置信水平下，最大潜在损失为20.41%。因此，在投资之前应考虑资本承受能力，并严格遵循止损策略以降低可能带来的损失。\\n\\n以上建议仅供参考，请根据个人实际情况和风险偏好做出决策。'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T03:07:26.925709Z",
     "iopub.status.busy": "2025-11-11T03:07:26.924921Z",
     "iopub.status.idle": "2025-11-11T03:07:28.528094Z",
     "shell.execute_reply": "2025-11-11T03:07:28.524241Z",
     "shell.execute_reply.started": "2025-11-11T03:07:26.925664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 966772cd-9e12-4041-bb92-c2ea8bb8a657. Step input: 明天的天气？\n",
      "\u001b[1;3;38;5;200mThought: 我需要查询一下天气信息，但是提供的工具并不适用于此场景。\n",
      "Answer: 很抱歉，我当前无法提供具体的天气信息。你可以查阅天气应用查看明天的天气预报。\n",
      "\u001b[0m很抱歉，我当前无法提供具体的天气信息。你可以查阅天气应用查看明天的天气预报。\n"
     ]
    }
   ],
   "source": [
    "q_string=\"明天的天气？\"    \n",
    "res= ask(q_string)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
