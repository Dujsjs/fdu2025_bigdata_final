import os
import pandas as pd
import numpy as np
from src.services.ricequant_service import RiceQuantService
from src.core.load_config import settings
import hashlib
from pykalman import KalmanFilter
from scipy import stats
from tqdm import tqdm

class MLService:
    """
    MLService å›Šæ‹¬ä»·å€¼åˆ†ææ¨¡å‹ã€é£é™©åˆ†ææ¨¡å‹ã€æ”¶ç›Šé¢„æµ‹æ¨¡å‹ï¼Œèƒ½è°ƒç”¨æŠ•èµ„å»ºè®®å¼•æ“åˆ†ææ¨¡å‹ç»“æœ
    """
    def __init__(self):
        self.ricequant_service = RiceQuantService()
        self.project_path = settings.project.project_dir
        self.features_data_path = os.path.join(self.project_path, settings.paths.processed_data)
        print("åˆå§‹åŒ– MLService æˆåŠŸï¼")

    def _analyze_CS(self, start_date:int, end_date:int, order_book_id_list: list = None):
        """
        å¯¹è‚¡ç¥¨æ—¥çº¿æ•°æ®è¿›è¡Œæ·±åº¦åˆ†æï¼ˆåŸºäºTVP-SSMæ¨¡å‹ï¼‰
        :param start_date: yyyymmddï¼Œintå‹
        :param end_date: yyyymmddï¼Œintå‹
        :return: åŒ…å«æ‰€æœ‰å…³é”®æŒ‡æ ‡çš„dictåˆ—è¡¨
        """
        cs_features_list = ['open', 'close', 'high', 'low', 'limit_up', 'limit_down', 'total_turnover', 'volume', 'num_trades', 'prev_close']
        df = self.ricequant_service.instruments_data_fetching(type='CS', start_date=start_date, end_date=end_date, features_list=cs_features_list, order_book_id_list=order_book_id_list)

        # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®å¹¶æ’åº
        df['date'] = pd.to_datetime(df['date'], format='%Y/%m/%d')
        df = df.sort_values(['order_book_id', 'date']).reset_index(drop=True)

        # è®¡ç®—åŸºç¡€æŒ‡æ ‡ (å¤„ç†é™¤é›¶é”™è¯¯)
        print('è®¡ç®—åŸºç¡€æŒ‡æ ‡')
        df['institution_participation'] = np.where(
            df['num_trades'] > 0,
            df['volume'] / df['num_trades'],
            np.nan
        )

        # ä»£ç†æ—©æœŸæµåŠ¨æ€§ (2021-06-25å‰)
        print('è®¡ç®—ä»£ç†æ—©æœŸæµåŠ¨æ€§')
        price_range = (df['high'] - df['low']).replace(0, np.nan)
        df['volume_range_ratio'] = df['volume'] / price_range
        df['institution_participation'] = np.where(
            (df['date'] < '2021-06-25') | df['num_trades'].isna(),
            df['volume_range_ratio'],
            df['institution_participation']
        )

        # æµåŠ¨æ€§æ¯ç«­æŒ‡æ•° (å¤„ç†ä»·æ ¼èŒƒå›´ä¸ºé›¶)
        print('è®¡ç®—æµåŠ¨æ€§æ¯ç«­æŒ‡æ•°')
        df['liquidity_dryup'] = np.where(
            price_range.notna(),
            ((df['limit_up'] - df['close']) / price_range) +
            ((df['close'] - df['limit_down']) / price_range),
            np.nan
        )

        # æ¶¨åœå»¶ç»­ç‡ (è¿ç»­æ¶¨åœå¤©æ•°)
        print('è®¡ç®—æ¶¨åœå»¶ç»­ç‡')
        df['is_limit_up'] = df['close'] >= df['limit_up'] * 0.995  # å®¹å¿0.5%è¯¯å·®
        df['consecutive_limit_up'] = 0
        for i in range(1, len(df)):
            if df.iloc[i]['is_limit_up']:
                prev_consec = df.iloc[i - 1]['consecutive_limit_up']
                df.iloc[i, df.columns.get_loc('consecutive_limit_up')] = prev_consec + 1
            else:
                df.iloc[i, df.columns.get_loc('consecutive_limit_up')] = 0

        # ========================
        # æ ¸å¿ƒï¼šæ»šåŠ¨çª—å£ TVP-SSM åˆ†æ
        # ========================
        print('åˆ©ç”¨TVP-SSMæŒ–æ˜å¸‚åœºæ·±å±‚çš„åŠ¨æ€é£é™©ç»“æ„')
        results = []
        window_size = 30  # æ»šåŠ¨çª—å£å¤§å°

        for order_book_id, group in tqdm(df.groupby('order_book_id')):
            group = group.sort_values('date').copy().reset_index(drop=True)
            n = len(group)

            # å‡†å¤‡æ—¶é—´åºåˆ—
            returns = (group['close'] / group['prev_close'] - 1).values
            liquidity_dryup = group['liquidity_dryup'].fillna(0.5).values

            # å­˜å‚¨åŠ¨æ€ä¼°è®¡ç»“æœ
            risk_premium = np.full(n, np.nan)
            liquidity_impact = np.full(n, np.nan)

            # åªæœ‰å½“æ•°æ®è¶³å¤Ÿé•¿æ—¶æ‰è¿›è¡Œæ»šåŠ¨ä¼°è®¡
            if n >= window_size:
                for t in range(window_size, n):
                    # æå–çª—å£å†…æ•°æ®
                    window_returns = returns[t - window_size:t]  # shape: (30,)
                    window_liquidity = liquidity_dryup[t - window_size:t]  # shape: (30,)

                    # æ„å»ºè§‚æµ‹çŸ©é˜µï¼šæ¯è¡Œ [1, liquidity_dryup_t]
                    obs_mat = np.column_stack([np.ones(window_size), window_liquidity])

                    try:
                        # åˆå§‹åŒ–æ¨¡å‹ï¼ˆçŠ¶æ€ï¼š[é£é™©æº¢ä»·, æµåŠ¨æ€§ç³»æ•°]ï¼‰
                        kf = KalmanFilter(
                            transition_matrices=np.eye(2),  # çŠ¶æ€è½¬ç§»
                            observation_matrices=obs_mat,  # è§‚æµ‹çŸ©é˜µï¼ˆéšæ—¶é—´å˜åŒ–ï¼‰
                            initial_state_mean=[0, 0],
                            initial_state_covariance=np.eye(2),
                            observation_covariance=1e-3,
                            transition_covariance=np.eye(2) * 1e-4
                        )

                        # ä½¿ç”¨çª—å£å†…æ•°æ®æ»¤æ³¢
                        filtered_state_means, _ = kf.filter(window_returns)
                        # å–æœ€åä¸€å¤©çš„ä¼°è®¡å€¼ä½œä¸ºå½“å‰çŠ¶æ€
                        risk_premium[t] = filtered_state_means[-1, 0]
                        liquidity_impact[t] = filtered_state_means[-1, 1]

                    except Exception as e:
                        # æ•è·ä»»ä½•æ•°å€¼ä¸ç¨³å®šæˆ–SVDåˆ†è§£å¤±è´¥ç­‰é—®é¢˜
                        risk_premium[t] = np.nan
                        liquidity_impact[t] = np.nan

            # ========================
            # å°¾éƒ¨é£é™©æ¦‚ç‡
            # ========================
            tail_risk_prob = np.zeros(n)
            for t in range(window_size + 30, n):  # å‰é¢ç•™å‡ºç¼“å†²
                recent_rp = risk_premium[t - 60:t]  # æœ€è¿‘60å¤©
                valid_rp = recent_rp[~np.isnan(recent_rp)]
                if len(valid_rp) >= 20:
                    threshold_90 = np.percentile(valid_rp, 90)
                    current_liq = group.iloc[t]['liquidity_dryup']
                    current_rp = risk_premium[t]
                    if not np.isnan(current_rp) and current_liq > 0.8 and current_rp > threshold_90:
                        tail_risk_prob[t] = 0.65

            # ========================
            # æƒ…ç»ª-æµåŠ¨æ€§åŒ¹é…åº¦
            # ========================
            rolling_mean_ip = group['institution_participation'].rolling(30, min_periods=10).mean()
            emotion_liquidity_match = (
                    (group['institution_participation'] - rolling_mean_ip) *
                    (1 - group['liquidity_dryup'].fillna(0.5))
            )

            # ========================
            # æ„å»ºæ¯æ—¥ç»“æœ
            # ========================
            for i in range(n):
                risk_alert = False
                if (not np.isnan(emotion_liquidity_match.iloc[i]) and
                        group.iloc[i]['liquidity_dryup'] > 0.8 and
                        group.iloc[i]['consecutive_limit_up'] > 3 and
                        emotion_liquidity_match.iloc[i] < -0.3):
                    risk_alert = True

                results.append({
                    "date": group.iloc[i]['date'].strftime('%Y-%m-%d'),
                    "order_book_id": order_book_id,
                    "institution_participation": float(group.iloc[i]['institution_participation'])
                    if not pd.isna(group.iloc[i]['institution_participation']) else None,
                    "liquidity_dryup": float(group.iloc[i]['liquidity_dryup'])
                    if not pd.isna(group.iloc[i]['liquidity_dryup']) else None,
                    "consecutive_limit_up": int(group.iloc[i]['consecutive_limit_up']),
                    "daily_return": float(returns[i]) if i < len(returns) and not np.isnan(returns[i]) else None,
                    "dynamic_risk_premium": float(risk_premium[i]) if not np.isnan(risk_premium[i]) else None,
                    "liquidity_impact": float(liquidity_impact[i]) if not np.isnan(liquidity_impact[i]) else None,
                    "tail_risk_probability": float(tail_risk_prob[i]),
                    "emotion_liquidity_match": float(emotion_liquidity_match.iloc[i])
                    if not pd.isna(emotion_liquidity_match.iloc[i]) else None,
                    "risk_alert": risk_alert
                })

        # indicator_explanations = {
        #     "date": "äº¤æ˜“æ—¥æœŸï¼Œä½œä¸ºåŸºç¡€æ—¶é—´æˆ³ç”¨äºè¿½è¸ªè¶‹åŠ¿å˜åŒ–ã€‚",
        #     "order_book_id": "è‚¡ç¥¨ä»£ç ï¼Œç”¨äºæ ‡è¯†åˆ†æçš„å…·ä½“æ ‡çš„å¯¹è±¡ã€‚",
        #     "institution_participation": "æœºæ„å‚ä¸åº¦ï¼Œè®¡ç®—æ–¹å¼ä¸º volume / num_tradesï¼Œè¡¨ç¤ºå¹³å‡æ¯ç¬”äº¤æ˜“çš„è‚¡æ•°ã€‚>2000 è¡¨ç¤ºæœºæ„ä¸»å¯¼ï¼Œè¶‹åŠ¿å¯èƒ½å»¶ç»­ï¼›<1000 è¡¨ç¤ºæ•£æˆ·ä¸»å¯¼ï¼Œæ˜“è¿½æ¶¨æ€è·Œã€æ³¢åŠ¨å¤§ï¼›å€¼åœ¨ä¸­é—´ï¼ˆå¦‚1765.58ï¼‰è¡¨ç¤ºå¤„äºä¸­é—´åæœºæ„çŠ¶æ€ï¼Œä½†å°šæœªå½¢æˆç¨³å®šä¸»åŠ›ã€‚",
        #     "liquidity_dryup": "æµåŠ¨æ€§æ¯ç«­æŒ‡æ•°ï¼Œè®¡ç®—æ–¹å¼ä¸º (limit_up - close)/(high-low) + (close - limit_down)/(high-low)ï¼Œåæ˜ ä»·æ ¼ç¦»æ¶¨è·Œåœçš„æ¥è¿‘ç¨‹åº¦ã€‚æ¥è¿‘0 è¡¨ç¤ºä»·æ ¼å¡åœ¨æ¶¨åœæˆ–è·Œåœï¼ŒæµåŠ¨æ€§æ¯ç«­ï¼Œå­˜åœ¨é£é™©ï¼›æ¥è¿‘2 è¡¨ç¤ºä»·æ ¼åœ¨ä¸­é—´åŒºåŸŸï¼Œäº¤æ˜“æ´»è·ƒï¼›å€¼ä¸º0.752 è¡¨ç¤ºä»·æ ¼åå‘è·Œåœï¼ŒæµåŠ¨æ€§ç´§å¼ ï¼ŒæŠ›å”®å‹åŠ›ä»åœ¨ã€‚",
        #     "consecutive_limit_up": "è¿ç»­æ¶¨åœå¤©æ•°ï¼Œç»Ÿè®¡è¿ç»­æ”¶ç›˜ä»·â‰¥æ¶¨åœä»·çš„å¤©æ•°ï¼Œåæ˜ å½“å‰æ˜¯å¦å¤„äºå¼ºåŠ¿ä¸Šæ¶¨è¶‹åŠ¿ã€‚>3 è¡¨ç¤ºå¼ºè¶‹åŠ¿ï¼Œä½†éœ€è­¦æƒ•æƒ…ç»ªè¿‡çƒ­ï¼›=0 è¡¨ç¤ºæ— è¶‹åŠ¿æˆ–è¶‹åŠ¿ä¸­æ–­ï¼›å€¼ä¸º0 è¡¨ç¤ºè¶‹åŠ¿æœªå¯åŠ¨ï¼Œå¸‚åœºä»å¼±ã€‚",
        #     "daily_return": "æ—¥æ”¶ç›Šç‡ï¼Œè®¡ç®—æ–¹å¼ä¸º close/prev_close - 1ï¼Œè¡¨ç¤ºå½“å¤©çš„æ¶¨è·Œå¹…ã€‚å€¼ä¸º-0.0298 è¡¨ç¤ºä¸‹è·Œ2.98%ï¼Œå±äºæ˜¾è‘—å›è°ƒï¼Œç»“åˆå…¶ä»–æŒ‡æ ‡å¯åˆ¤æ–­ä¸ºææ…Œæ€§æŠ›å”®ã€‚",
        #     "dynamic_risk_premium": "åŠ¨æ€é£é™©æº¢ä»·ï¼Œç”±TVP-SSMæ¨¡å‹ä¼°è®¡å¾—å‡ºï¼Œåæ˜ å¸‚åœºå½“å¤©è¦æ±‚å¤šå°‘é¢å¤–å›æŠ¥æ¥æ‰¿æ‹…é£é™©ã€‚null è¡¨ç¤ºæ¨¡å‹éœ€è¦è‡³å°‘30å¤©æ•°æ®æ‰èƒ½è¾“å‡ºï¼Œå½“å‰ä¸ºé¢„çƒ­é˜¶æ®µï¼›åç»­è‹¥è·³å‡è¶…è¿‡0.5%ï¼Œè¡¨æ˜å¸‚åœºæåº¦ææ…Œï¼Œé£é™©åå¥½ä¸‹é™ã€‚",
        #     "liquidity_impact": "æµåŠ¨æ€§å†²å‡»ç³»æ•°ï¼Œç”±TVP-SSMæ¨¡å‹ä¼°è®¡å¾—å‡ºï¼Œè¡¡é‡æµåŠ¨æ€§æ¶åŒ–å¯¹é£é™©æº¢ä»·çš„æ”¾å¤§ä½œç”¨ã€‚null è¡¨ç¤ºæ¨¡å‹é¢„çƒ­ä¸­ï¼›åç»­è‹¥ä¸ºæ­£ä¸”æŒç»­å¢å¤§ï¼Œè¡¨æ˜æµåŠ¨æ€§å·²æˆä¸ºä¸»è¦é£é™©æ¥æºã€‚",
        #     "tail_risk_probability": "å°¾éƒ¨é£é™©æ¦‚ç‡ï¼ŒåŸºäºå†å²å›æµ‹è§„åˆ™ç”Ÿæˆï¼Œè¡¨ç¤ºæœªæ¥30å¤©å‡ºç°å¤§å¹…å›æ’¤çš„æ¦‚ç‡ã€‚0.0 è¡¨ç¤ºå½“å‰ä¸æ»¡è¶³é«˜é£é™©æ¡ä»¶ï¼›>0.65 è¡¨ç¤ºæé«˜é£é™©ï¼Œå»ºè®®å‡ä»“æˆ–å¯¹å†²ï¼›è§¦å‘æ¡ä»¶ä¸º liquidity_dryup > 0.8 ä¸” dynamic_risk_premium å¤„äºé«˜ä½ã€‚",
        #     "emotion_liquidity_match": "æƒ…ç»ª-æµåŠ¨æ€§åŒ¹é…åº¦ï¼Œè®¡ç®—æ–¹å¼ä¸º (æœºæ„å‚ä¸åº¦ - å¸‚åœºå‡å€¼) Ã— (1 - liquidity_dryup)ï¼Œç”¨äºåˆ¤æ–­â€˜è°åœ¨ä¹°â€™å’Œâ€˜èƒ½ä¸èƒ½å–â€™æ˜¯å¦åè°ƒã€‚>0 è¡¨ç¤ºå¥åº·çŠ¶æ€ï¼ˆæœºæ„ä¹°å…¥ä¸”æµåŠ¨æ€§å¥½ï¼‰ï¼›<-0.3 è¡¨ç¤ºå±é™©ä¿¡å·ï¼ˆæœºæ„æ’¤ç¦»ä¸”æµåŠ¨æ€§å·®ï¼‰ï¼›å€¼ä¸º-0.12 è¡¨ç¤ºè½»åº¦ä¸åŒ¹é…ï¼Œä½†æœªè¾¾åˆ°è­¦æˆ’æ°´å¹³ã€‚",
        #     "risk_alert": "é£é™©é¢„è­¦ï¼Œç”±ç»¼åˆé€»è¾‘åˆ¤æ–­ç”Ÿæˆï¼ŒæŒ‡ç¤ºæ˜¯å¦åº”å‘å‡ºå‡ä»“ä¿¡å·ã€‚False è¡¨ç¤ºæš‚æ— ç³»ç»Ÿæ€§é£é™©ï¼›True è¡¨ç¤ºæ»¡è¶³å¤šé‡é«˜é£é™©æ¡ä»¶ï¼ˆå¦‚æµåŠ¨æ€§æ¯ç«­ã€æƒ…ç»ªæ¶åŒ–ç­‰ï¼‰ï¼Œå¼ºçƒˆå»ºè®®é‡‡å–è¡ŒåŠ¨ã€‚"
        # }
        return results

    def summarize_CSanalysis(self, start_date: int, end_date: int, target_stock_id=None,
                                order_book_id_list: list = None, lookback_days=30, confidence_level=0.95):
        """
        å¯¹æ·±åº¦åˆ†ææŒ‡æ ‡è¿›è¡Œæ—¶é—´åºåˆ—è¶‹åŠ¿åˆ†æï¼Œè¯†åˆ«åŠ¨æ€æ¨¡å¼ä¸é¢†å…ˆ-æ»åå…³ç³»

        è¿”å›:
        str: åŒ…å«æ·±åº¦è¶‹åŠ¿åˆ†æçš„è‡ªç„¶è¯­è¨€æ€»ç»“
        """
        analysis_results = self._analyze_CS(start_date, end_date, order_book_id_list)
        if not analysis_results:
            return "æ— æ•°æ®å¯ä¾›åˆ†æã€‚"

        # è½¬æ¢ä¸ºDataFrameå¹¶é¢„å¤„ç†
        df = pd.DataFrame(analysis_results)
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values(['order_book_id', 'date'])

        # ======================
        # æ–°å¢ï¼šå¸‚åœºåŸºå‡†è®¡ç®—ï¼ˆä¿ç•™åŸä»£ç ä¸å˜ï¼Œæ–°å¢æ­¤éƒ¨åˆ†ï¼‰
        # ======================
        # è·å–æœ€æ–°æ—¥æœŸç”¨äºå¸‚åœºåŸºå‡†è®¡ç®—
        latest_date = df['date'].max()

        # è·å–æ‰€æœ‰è‚¡ç¥¨åœ¨æœ€æ–°æ—¥æœŸçš„æ•°æ®
        market_df = df[df['date'] == latest_date].copy()

        # è®¡ç®—å¸‚åœºåŸºå‡†ï¼ˆæ’é™¤ç›®æ ‡è‚¡ç¥¨è‡ªèº«ï¼‰
        market_benchmarks = {}
        if len(market_df) > 1:  # è‡³å°‘æœ‰2åªè‚¡ç¥¨æ‰èƒ½è®¡ç®—åŸºå‡†
            if target_stock_id:
                market_without_target = market_df[market_df['order_book_id'] != target_stock_id]
            else:
                market_without_target = market_df  # å¦‚æœæ²¡æœ‰æŒ‡å®šç›®æ ‡è‚¡ç¥¨ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®

            if not market_without_target.empty:
                market_benchmarks = {
                    'inst_part_mean': market_without_target['institution_participation'].mean(),
                    'inst_part_25pct': market_without_target['institution_participation'].quantile(0.25),
                    'inst_part_75pct': market_without_target['institution_participation'].quantile(0.75),
                    'liquidity_mean': market_without_target['liquidity_dryup'].mean(),
                    'liquidity_25pct': market_without_target['liquidity_dryup'].quantile(0.25),
                    'liquidity_75pct': market_without_target['liquidity_dryup'].quantile(0.75),
                }
                # è®¡ç®—é£é™©æº¢ä»·åŸºå‡†ï¼ˆä»…åŒ…å«æœ‰æ•ˆå€¼ï¼‰
                valid_rp = market_without_target['dynamic_risk_premium'].dropna()
                if not valid_rp.empty:
                    market_benchmarks['risk_premium_mean'] = valid_rp.mean()

        # é€‰æ‹©ç›®æ ‡è‚¡ç¥¨
        if target_stock_id:
            stock_df = df[df['order_book_id'] == target_stock_id].copy()
            if stock_df.empty:
                return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {target_stock_id} çš„æ•°æ®ã€‚"
        else:
            # è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªè‚¡ç¥¨
            target_stock_id = df['order_book_id'].iloc[0]
            stock_df = df[df['order_book_id'] == target_stock_id].copy()

        # é™åˆ¶åˆ†æçª—å£
        if len(stock_df) > lookback_days:
            stock_df = stock_df.tail(lookback_days).reset_index(drop=True)

        n = len(stock_df)
        if n < 10:  # éœ€è¦è¶³å¤Ÿæ•°æ®è¿›è¡Œè¶‹åŠ¿åˆ†æ
            return f"è‚¡ç¥¨ {target_stock_id} æ•°æ®ç‚¹ä¸è¶³ï¼ˆ{n}å¤©ï¼‰ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆè¶‹åŠ¿åˆ†æã€‚"

        # ======================
        # 1. æ·±åº¦æ—¶é—´åºåˆ—è¶‹åŠ¿åˆ†æ
        # ======================

        # --- 1.1 æœºæ„å‚ä¸åº¦è¶‹åŠ¿ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰---
        inst_part = stock_df['institution_participation'].astype(float)

        # è®¡ç®—çº¿æ€§è¶‹åŠ¿æ–œç‡å’Œæ˜¾è‘—æ€§
        x = np.arange(n)
        slope_inst, intercept_inst, r_inst, p_inst, std_err_inst = stats.linregress(x, inst_part)
        trend_strength_inst = abs(slope_inst) * n / inst_part.mean()

        # è¶‹åŠ¿åˆ†ç±»ï¼ˆåŸºäºç»Ÿè®¡æ˜¾è‘—æ€§å’Œå¼ºåº¦ï¼‰
        inst_trend_desc = ""
        if p_inst < (1 - confidence_level):
            if slope_inst > 0:
                if trend_strength_inst > 0.5:
                    inst_trend_desc = "æ˜¾è‘—ä¸Šå‡è¶‹åŠ¿ï¼Œæœºæ„èµ„é‡‘æŒç»­å¤§å¹…æµå…¥"
                elif trend_strength_inst > 0.2:
                    inst_trend_desc = "æ¸©å’Œä¸Šå‡è¶‹åŠ¿ï¼Œæœºæ„èµ„é‡‘é€æ­¥ä»‹å…¥"
                else:
                    inst_trend_desc = "è½»å¾®ä¸Šå‡è¶‹åŠ¿ï¼Œæœºæ„å‚ä¸åº¦ç¼“æ…¢æ”¹å–„"
            else:
                if trend_strength_inst > 0.5:
                    inst_trend_desc = "æ˜¾è‘—ä¸‹é™è¶‹åŠ¿ï¼Œæœºæ„èµ„é‡‘åŠ é€Ÿæ’¤ç¦»"
                elif trend_strength_inst > 0.2:
                    inst_trend_desc = "æ¸©å’Œä¸‹é™è¶‹åŠ¿ï¼Œæœºæ„èµ„é‡‘ç¼“æ…¢æµå‡º"
                else:
                    inst_trend_desc = "è½»å¾®ä¸‹é™è¶‹åŠ¿ï¼Œæœºæ„å‚ä¸åº¦ç¼“æ…¢é™ä½"

            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            inst_trend_desc += f"ï¼ˆæ–œç‡={slope_inst:.2f}, p={p_inst:.3f}ï¼‰"
        else:
            inst_trend_desc = "æ— æ˜¾è‘—è¶‹åŠ¿ï¼Œæœºæ„å‚ä¸åº¦éšæœºæ³¢åŠ¨"

        # --- 1.2 æµåŠ¨æ€§æ¯ç«­æŒ‡æ•°è¶‹åŠ¿ ---
        liquidity = stock_df['liquidity_dryup'].astype(float)

        # æ£€æµ‹åŠ é€Ÿæ¶åŒ–ï¼ˆäºŒé˜¶å¯¼æ•°è¿‘ä¼¼ï¼‰
        liquidity_ma = liquidity.rolling(window=5).mean().dropna()
        liquidity_accel = liquidity_ma.diff().mean()

        # è¶‹åŠ¿åˆ†ç±»
        liquidity_status = ""
        if liquidity_accel > 0.03 and liquidity.iloc[-1] > 0.7:
            liquidity_status = f"æµåŠ¨æ€§æ­£åœ¨åŠ é€Ÿæ¶åŒ–ï¼ˆåŠ é€Ÿåº¦={liquidity_accel:.4f}ï¼‰ï¼Œä»·æ ¼æŒç»­è´´è¿‘è·Œåœï¼Œäº¤æ˜“æåº¦å›°éš¾"
        elif liquidity.iloc[-1] > 0.8:
            liquidity_status = "æµåŠ¨æ€§ä¸¥é‡ç´§å¼ ï¼Œä»·æ ¼é¢‘ç¹è§¦åŠæ¶¨è·Œåœï¼Œäº¤æ˜“å›°éš¾"
        elif liquidity.iloc[-1] > 0.6:
            liquidity_status = "æµåŠ¨æ€§ç´§å¼ ï¼Œä»·æ ¼æ¥è¿‘æ¶¨è·ŒåœåŒºé—´"
        elif liquidity.iloc[-1] < 0.3:
            liquidity_status = "æµåŠ¨æ€§å……è¶³ï¼Œä»·æ ¼è¿è¡Œå¹³ç¨³ï¼Œäº¤æ˜“æ´»è·ƒ"
        else:
            liquidity_status = "æµåŠ¨æ€§å¤„äºæ­£å¸¸æ°´å¹³"

        # --- 1.3 é£é™©æº¢ä»·åŠ¨æ€åˆ†æï¼ˆæ ¸å¿ƒè¶‹åŠ¿ï¼‰---
        risk_premium = stock_df['dynamic_risk_premium'].dropna()
        if len(risk_premium) >= 15:
            x_rp = np.arange(len(risk_premium))
            slope_rp, _, _, p_rp, _ = stats.linregress(x_rp, risk_premium)

            # è®¡ç®—æ³¢åŠ¨ç‡å˜åŒ–
            rp_vol = risk_premium.diff().abs().rolling(window=5).mean().dropna()
            vol_trend = "æ˜¾è‘—ä¸Šå‡" if rp_vol.iloc[-1] > rp_vol.quantile(0.75) else "è¶‹äºç¨³å®š"

            if p_rp < (1 - confidence_level) and slope_rp > 0:
                risk_summary = f"åŠ¨æ€é£é™©æº¢ä»·å‘ˆæ˜¾è‘—ä¸Šå‡è¶‹åŠ¿ï¼ˆæ–œç‡={slope_rp:.4f}, p={p_rp:.3f}ï¼‰ï¼Œä¸”æ³¢åŠ¨ç‡{vol_trend}ï¼Œæ˜¾ç¤ºå¸‚åœºé¿é™©æƒ…ç»ªå¿«é€Ÿå‡æ¸©"
            elif p_rp < (1 - confidence_level) and slope_rp < 0:
                risk_summary = f"åŠ¨æ€é£é™©æº¢ä»·å‘ˆæ˜¾è‘—ä¸‹é™è¶‹åŠ¿ï¼ˆæ–œç‡={slope_rp:.4f}, p={p_rp:.3f}ï¼‰ï¼Œä¸”æ³¢åŠ¨ç‡{vol_trend}ï¼Œæ˜¾ç¤ºå¸‚åœºé£é™©åå¥½å›å‡"
            else:
                risk_summary = f"åŠ¨æ€é£é™©æº¢ä»·æ³¢åŠ¨è¾ƒå¤§ä½†æ— æ˜¾è‘—è¶‹åŠ¿ï¼ˆp={p_rp:.3f}ï¼‰ï¼Œæ³¢åŠ¨ç‡{vol_trend}ï¼Œå¸‚åœºæƒ…ç»ªå¤„äºå¹³è¡¡çŠ¶æ€"
        else:
            risk_summary = "åŠ¨æ€é£é™©æº¢ä»·æ•°æ®ä¸è¶³ï¼Œæš‚æ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æ"

        # --- 1.4 å°¾éƒ¨é£é™©åŠ¨æ€æ¨¡å¼ ---
        tail_risk = stock_df['tail_risk_probability'].astype(float)
        high_risk_days = (tail_risk >= 0.65).sum()
        medium_risk_days = ((tail_risk >= 0.4) & (tail_risk < 0.65)).sum()
        risk_persistence = (tail_risk > 0).astype(int).diff().ne(1).cumsum().value_counts().max() / n

        if high_risk_days > n * 0.2:
            tail_risk_summary = f"é«˜é£é™©çŠ¶æ€é¢‘ç¹ï¼ˆ{high_risk_days}å¤©ï¼Œå æ¯”{high_risk_days / n:.0%}ï¼‰ï¼Œä¸”æŒç»­æ€§å¼ºï¼ˆå¹³å‡æŒç»­{int(1 / risk_persistence)}å¤©ï¼‰ï¼Œç³»ç»Ÿæ€§é£é™©ç´¯ç§¯æ˜æ˜¾"
        elif high_risk_days > 0:
            tail_risk_summary = f"å¶å‘é«˜é£é™©çŠ¶æ€ï¼ˆ{high_risk_days}å¤©ï¼‰ï¼Œä½†æŒç»­æ—¶é—´çŸ­ï¼Œéœ€è­¦æƒ•çªå‘é£é™©"
        elif medium_risk_days > n * 0.3:
            tail_risk_summary = f"ä¸­ç­‰é£é™©çŠ¶æ€æŒç»­ï¼ˆ{medium_risk_days}å¤©ï¼Œå æ¯”{medium_risk_days / n:.0%}ï¼‰ï¼Œå¸‚åœºè„†å¼±æ€§å¢å¼º"
        else:
            tail_risk_summary = "é£é™©æ°´å¹³æ•´ä½“å¯æ§ï¼Œç³»ç»Ÿæ€§å´©æºƒæ¦‚ç‡ä½"

        # --- 1.5 é£é™©é¢„è­¦ä¿¡å·æ¨¡å¼åˆ†æ ---
        risk_alerts = stock_df['risk_alert'].astype(bool)
        alert_count = risk_alerts.sum()
        alert_clusters = (risk_alerts != risk_alerts.shift()).cumsum()[risk_alerts].value_counts()
        avg_cluster_size = alert_clusters.mean() if not alert_clusters.empty else 0

        if alert_count > n * 0.2:
            alert_summary = f"é£é™©é¢„è­¦é«˜é¢‘è§¦å‘ï¼ˆ{alert_count}æ¬¡ï¼Œ{alert_count / n:.0%}å¤©ï¼‰ï¼Œä¸”å¸¸æˆç°‡å‡ºç°ï¼ˆå¹³å‡{avg_cluster_size:.1f}å¤©/ç°‡ï¼‰ï¼Œå¸‚åœºå¤„äºæŒç»­å±é™©çŠ¶æ€"
        elif alert_count > 0:
            alert_summary = f"å¶å‘é£é™©é¢„è­¦ï¼ˆ{alert_count}æ¬¡ï¼‰ï¼Œå¤šä¸ºå­¤ç«‹äº‹ä»¶ï¼Œä½†éœ€å…³æ³¨è§¦å‘æ¡ä»¶"
        else:
            alert_summary = "æœªè§¦å‘é£é™©é¢„è­¦ï¼Œå½“å‰å¸‚åœºç¯å¢ƒç›¸å¯¹å®‰å…¨"

        # --- 1.6 æƒ…ç»ª-æµåŠ¨æ€§åŠ¨æ€å…³ç³» ---
        match_series = stock_df['emotion_liquidity_match'].astype(float)

        # è®¡ç®—ä¸æœºæ„å‚ä¸åº¦çš„æ»šåŠ¨ç›¸å…³æ€§
        rolling_corr = inst_part.rolling(window=5).corr(match_series)
        avg_corr = rolling_corr.mean()

        if match_series.mean() < -0.25:
            match_trend = f"æŒç»­ä¸¥é‡è´Ÿå‘ï¼ˆå‡å€¼={match_series.mean():.2f}ï¼‰ï¼Œæœºæ„æ’¤ç¦»ä¸æµåŠ¨æ€§æ¶åŒ–å½¢æˆæ¶æ€§å¾ªç¯"
        elif match_series.mean() < -0.1:
            match_trend = f"æŒç»­è½»åº¦è´Ÿå‘ï¼ˆå‡å€¼={match_series.mean():.2f}ï¼‰ï¼Œéœ€å…³æ³¨èµ„é‡‘æµå‘å˜åŒ–"
        elif match_series.mean() > 0.25:
            match_trend = f"æŒç»­é«˜åº¦åè°ƒï¼ˆå‡å€¼={match_series.mean():.2f}ï¼‰ï¼Œæœºæ„ä¸»å¯¼ä¸”æµåŠ¨æ€§å¥½ï¼Œè¶‹åŠ¿å¥åº·"
        else:
            match_trend = f"åŸºæœ¬å¹³è¡¡ï¼ˆå‡å€¼={match_series.mean():.2f}ï¼‰ï¼Œå¸‚åœºå¤„äºè¿‡æ¸¡çŠ¶æ€"

        # --- 1.7 é¢†å…ˆ-æ»åå…³ç³»åˆ†æï¼ˆå…³é”®ï¼ï¼‰---
        # æ£€æŸ¥æµåŠ¨æ€§æ¯ç«­æ˜¯å¦é¢†å…ˆäºé£é™©æº¢ä»·å˜åŒ–
        lead_lag_results = []
        best_lag = None
        if len(risk_premium) >= 20:
            for lag in range(-7, 8):  # -7åˆ°+7å¤©çš„æ»å
                if lag <= 0:
                    corr = liquidity[:lag].corr(risk_premium[-lag:]) if lag != 0 else liquidity.corr(risk_premium)
                else:
                    corr = liquidity[lag:].corr(risk_premium[:-lag])
                lead_lag_results.append((lag, corr))

            best_lag, best_corr = max(lead_lag_results, key=lambda x: abs(x[1]))
            if abs(best_corr) > 0.45:
                if best_lag < 0:
                    lead_lag_summary = f"æµåŠ¨æ€§æ¯ç«­é¢†å…ˆé£é™©æº¢ä»·çº¦{-best_lag}å¤©ï¼ˆæœ€å¤§ç›¸å…³ç³»æ•°={best_corr:.2f}ï¼‰ï¼Œæ˜¯å¸‚åœºé£é™©çš„å…ˆè¡ŒæŒ‡æ ‡"
                elif best_lag > 0:
                    lead_lag_summary = f"é£é™©æº¢ä»·é¢†å…ˆæµåŠ¨æ€§æ¯ç«­çº¦{best_lag}å¤©ï¼ˆæœ€å¤§ç›¸å…³ç³»æ•°={best_corr:.2f}ï¼‰ï¼Œé£é™©æƒ…ç»ªå…ˆäºæµåŠ¨æ€§å˜åŒ–"
                else:
                    lead_lag_summary = f"æµåŠ¨æ€§æ¯ç«­ä¸é£é™©æº¢ä»·åŒæ­¥å˜åŒ–ï¼ˆç›¸å…³ç³»æ•°={best_corr:.2f}ï¼‰ï¼Œé£é™©ä¸æµåŠ¨æ€§ç›¸äº’å¼ºåŒ–"
            else:
                lead_lag_summary = "æµåŠ¨æ€§ä¸é£é™©æº¢ä»·å…³ç³»ä¸ç¨³å®šï¼Œæ— æ˜æ˜¾é¢†å…ˆ-æ»åæ¨¡å¼"
        else:
            lead_lag_summary = "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œé¢†å…ˆ-æ»ååˆ†æ"

        # ======================
        # 2. è¯†åˆ«å…³é”®åŠ¨æ€æ¨¡å¼
        # ======================

        # æ¨¡å¼1: æµåŠ¨æ€§å±æœºæ¨¡å¼
        liquidity_crisis = (
            "æµåŠ¨æ€§åŠ é€Ÿæ¶åŒ–" in liquidity_status and
            "æ˜¾è‘—ä¸‹é™è¶‹åŠ¿" in inst_trend_desc and
            "ä¸Šå‡è¶‹åŠ¿" in risk_summary and
            best_lag < 0 if 'best_lag' in locals() else False
        )

        # æ¨¡å¼2: å¥åº·ä¸Šæ¶¨æ¨¡å¼
        healthy_rally = (
                "æ˜¾è‘—ä¸Šå‡è¶‹åŠ¿" in inst_trend_desc and
                "æµåŠ¨æ€§å……è¶³" in liquidity_status and
                ("ä¸‹é™è¶‹åŠ¿" in risk_summary or "å¹³è¡¡" in risk_summary)
        )

        # æ¨¡å¼3: æƒ…ç»ªé©±åŠ¨æ³¢åŠ¨æ¨¡å¼
        emotion_volatility = (
                abs(avg_corr) < 0.2 and
                "æ³¢åŠ¨å‰§çƒˆ" in risk_summary and
                "åŸºæœ¬å¹³è¡¡" in match_trend
        )

        # ======================
        # 3. æ–°å¢ï¼šç›¸å¯¹å¸‚åœºå®šä½åˆ†æï¼ˆä¿ç•™åŸä»£ç ä¸å˜ï¼Œæ–°å¢æ­¤éƒ¨åˆ†ï¼‰
        # ======================
        relative_analysis = ""
        latest = stock_df.iloc[-1]

        # 1. æœºæ„å‚ä¸åº¦ç›¸å¯¹ä½ç½®
        inst_relative_desc = "æ— å¸‚åœºæ¯”è¾ƒæ•°æ®"
        inst_part_relative = None
        if 'inst_part_mean' in market_benchmarks:
            # è®¡ç®—Z-scoreï¼ˆä½¿ç”¨IQRæ ‡å‡†åŒ–ï¼‰
            iqr = market_benchmarks['inst_part_75pct'] - market_benchmarks['inst_part_25pct']
            if iqr > 0:  # é˜²æ­¢é™¤ä»¥0
                inst_part_relative = (
                        (latest['institution_participation'] - market_benchmarks['inst_part_mean']) /
                        (iqr + 1e-5)
                )
                if inst_part_relative > 1.0:
                    inst_relative_desc = "æ˜¾è‘—é«˜äºå¸‚åœºå¹³å‡æ°´å¹³ï¼Œæœºæ„å…³æ³¨åº¦çªå‡º"
                elif inst_part_relative > 0.5:
                    inst_relative_desc = "é«˜äºå¸‚åœºå¹³å‡æ°´å¹³ï¼Œæœºæ„å…³æ³¨åº¦è¾ƒé«˜"
                elif inst_part_relative < -1.0:
                    inst_relative_desc = "æ˜¾è‘—ä½äºå¸‚åœºå¹³å‡æ°´å¹³ï¼Œæœºæ„å…³æ³¨åº¦ä½è¿·"
                elif inst_part_relative < -0.5:
                    inst_relative_desc = "ä½äºå¸‚åœºå¹³å‡æ°´å¹³ï¼Œæœºæ„å…³æ³¨åº¦è¾ƒä½"
                else:
                    inst_relative_desc = "æ¥è¿‘å¸‚åœºå¹³å‡æ°´å¹³"

        # 2. æµåŠ¨æ€§ç›¸å¯¹ä½ç½®
        liquidity_relative_desc = "æ— å¸‚åœºæ¯”è¾ƒæ•°æ®"
        liquidity_relative = None
        if 'liquidity_mean' in market_benchmarks:
            # è®¡ç®—Z-scoreï¼ˆä½¿ç”¨IQRæ ‡å‡†åŒ–ï¼‰
            iqr = market_benchmarks['liquidity_75pct'] - market_benchmarks['liquidity_25pct']
            if iqr > 0:  # é˜²æ­¢é™¤ä»¥0
                liquidity_relative = (
                        (latest['liquidity_dryup'] - market_benchmarks['liquidity_mean']) /
                        (iqr + 1e-5)
                )
                if liquidity_relative > 1.0:
                    liquidity_relative_desc = "æµåŠ¨æ€§ç´§å¼ ç¨‹åº¦æ˜¾è‘—é«˜äºå¸‚åœºï¼Œäº¤æ˜“éš¾åº¦å¤§"
                elif liquidity_relative > 0.5:
                    liquidity_relative_desc = "æµåŠ¨æ€§ç´§å¼ ç¨‹åº¦é«˜äºå¸‚åœº"
                elif liquidity_relative < -1.0:
                    liquidity_relative_desc = "æµåŠ¨æ€§æ˜¾è‘—ä¼˜äºå¸‚åœºï¼Œäº¤æ˜“é¡ºç•…"
                elif liquidity_relative < -0.5:
                    liquidity_relative_desc = "æµåŠ¨æ€§ä¼˜äºå¸‚åœº"
                else:
                    liquidity_relative_desc = "æµåŠ¨æ€§å¤„äºå¸‚åœºæ­£å¸¸æ°´å¹³"

        # 3. é£é™©æº¢ä»·ç›¸å¯¹ä½ç½®
        risk_relative_desc = "æ— å¸‚åœºæ¯”è¾ƒæ•°æ®æˆ–æ•°æ®ä¸è¶³"
        if 'risk_premium_mean' in market_benchmarks and not pd.isna(latest['dynamic_risk_premium']):
            risk_premium_relative = (
                    latest['dynamic_risk_premium'] - market_benchmarks['risk_premium_mean']
            )
            if risk_premium_relative > 0.003:
                risk_relative_desc = "é£é™©æº¢ä»·æ˜¾è‘—é«˜äºå¸‚åœºï¼Œé¿é™©æƒ…ç»ªå¼ºçƒˆ"
            elif risk_premium_relative > 0.001:
                risk_relative_desc = "é£é™©æº¢ä»·é«˜äºå¸‚åœºï¼Œé¿é™©æƒ…ç»ªè¾ƒé«˜"
            elif risk_premium_relative < -0.003:
                risk_relative_desc = "é£é™©æº¢ä»·æ˜¾è‘—ä½äºå¸‚åœºï¼Œé£é™©åå¥½çªå‡º"
            elif risk_premium_relative < -0.001:
                risk_relative_desc = "é£é™©æº¢ä»·ä½äºå¸‚åœºï¼Œé£é™©åå¥½è¾ƒé«˜"
            else:
                risk_relative_desc = "é£é™©æº¢ä»·æ¥è¿‘å¸‚åœºæ°´å¹³"

        # ======================
        # 4. ç»¼åˆæ€»ç»“è¾“å‡ºï¼ˆä¿®æ”¹è¿™éƒ¨åˆ†ä»¥åŒ…å«ç›¸å¯¹åˆ†æï¼‰
        # ======================
        summary = f"""
        ã€{target_stock_id} æ·±åº¦è¶‹åŠ¿åˆ†ææŠ¥å‘Šã€‘ï¼ˆæˆªè‡³ {stock_df['date'].max().strftime('%Y-%m-%d')}ï¼‰
    
        ğŸŒ å¸‚åœºç›¸å¯¹å®šä½ï¼ˆåŸºäº{len(market_df)}åªè‚¡ç¥¨æœ€æ–°æ•°æ®ï¼‰ï¼š
        - æœºæ„å‚ä¸åº¦ï¼š{inst_relative_desc}
        - æµåŠ¨æ€§çŠ¶å†µï¼š{liquidity_relative_desc}
        - é£é™©æº¢ä»·æ°´å¹³ï¼š{risk_relative_desc}
    
        ğŸ” æ ¸å¿ƒè¶‹åŠ¿è¯Šæ–­ï¼ˆåŸºäº{len(stock_df)}å¤©æ•°æ®ï¼‰ï¼š
        1. **æœºæ„å‚ä¸è¶‹åŠ¿**ï¼š{inst_trend_desc}
           - å½“å‰å€¼ï¼š{inst_part.iloc[-1]:.2f}ï¼ˆ{('â†‘' if slope_inst > 0 else 'â†“') if p_inst < 0.05 else 'â†’'}ï¼‰
           - ç›¸å¯¹å¸‚åœºä½ç½®ï¼š{'é«˜äº' if inst_part_relative and inst_part_relative > 0 else 'ä½äº' if inst_part_relative and inst_part_relative < 0 else 'æ¥è¿‘'}å¸‚åœºä¸­ä½æ•°
           - 5æ—¥ç§»åŠ¨å¹³å‡ï¼š{inst_part.rolling(5).mean().iloc[-1]:.2f}
    
        2. **æµåŠ¨æ€§çŠ¶å†µ**ï¼š{liquidity_status}
           - å½“å‰æµåŠ¨æ€§æ¯ç«­æŒ‡æ•°ï¼š{liquidity.iloc[-1]:.3f}
           - æµåŠ¨æ€§åŠ é€Ÿåº¦ï¼š{liquidity_accel:.4f}ï¼ˆæ­£å€¼è¡¨ç¤ºæ¶åŒ–åŠ é€Ÿï¼‰
           - ç›¸å¯¹å¸‚åœºä½ç½®ï¼š{'ç´§å¼ ç¨‹åº¦é«˜äº' if liquidity_relative and liquidity_relative > 0 else 'ç´§å¼ ç¨‹åº¦ä½äº' if liquidity_relative and liquidity_relative < 0 else 'æ¥è¿‘'}å¸‚åœºå¹³å‡æ°´å¹³
    
        3. **é£é™©æƒ…ç»ªåŠ¨æ€**ï¼š{risk_summary}
           - é£é™©æ³¢åŠ¨ç‡è¶‹åŠ¿ï¼š{vol_trend if 'vol_trend' in locals() else 'N/A'}
           - ç›¸å¯¹å¸‚åœºé£é™©ï¼š{risk_relative_desc.lower()}
    
        4. **å…³é”®åŠ¨æ€å…³ç³»**ï¼š{lead_lag_summary}
           - {'æµåŠ¨æ€§æŒ‡æ ‡å¯ä½œä¸ºé£é™©å˜åŒ–çš„é¢†å…ˆæŒ‡æ ‡ï¼Œæå‰é¢„è­¦å¸‚åœºå‹åŠ›'
            if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag < 0
            else 'é£é™©æƒ…ç»ªå˜åŒ–å…ˆäºæµåŠ¨æ€§æ¶åŒ–ï¼Œéœ€ä¼˜å…ˆå…³æ³¨æƒ…ç»ªæŒ‡æ ‡'
            if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag > 0
            else 'æµåŠ¨æ€§ä¸é£é™©æƒ…ç»ªåŒæ­¥å˜åŒ–ï¼Œéœ€åŒæ—¶ç›‘æ§'}
    
        ğŸ’¡ è¯†åˆ«åˆ°çš„å¸‚åœºæ¨¡å¼ï¼š
        {'âš ï¸ã€æµåŠ¨æ€§å±æœºæ¨¡å¼ã€‘æœºæ„æ’¤ç¦»ã€æµåŠ¨æ€§æ¶åŒ–åŠ é€Ÿä¸”é¢†å…ˆäºé£é™©ä¸Šå‡ï¼Œå¸‚åœºè„†å¼±æ€§æé«˜ï¼' if liquidity_crisis else
            'ğŸ“ˆã€å¥åº·ä¸Šæ¶¨æ¨¡å¼ã€‘æœºæ„æŒç»­æµå…¥ã€æµåŠ¨æ€§å……è¶³ä¸”é£é™©æƒ…ç»ªç¨³å®šï¼Œè¶‹åŠ¿å¥åº·å¯æŒç»­ã€‚' if healthy_rally else
            'ğŸ”„ã€æƒ…ç»ªé©±åŠ¨æ³¢åŠ¨ã€‘å¸‚åœºæƒ…ç»ªä¸æµåŠ¨æ€§åŒ¹é…åº¦ä½ï¼Œä»·æ ¼æ³¢åŠ¨ä¸»è¦ç”±æƒ…ç»ªé©±åŠ¨ï¼Œè¶‹åŠ¿éš¾ä»¥æŒç»­ã€‚' if emotion_volatility else
            'ğŸ”ã€æ··åˆçŠ¶æ€ã€‘å¸‚åœºå¤„äºè¿‡æ¸¡æœŸï¼Œéœ€å¯†åˆ‡å…³æ³¨é¢†å…ˆæŒ‡æ ‡å˜åŒ–æ–¹å‘ã€‚'}
    
        ğŸ“Š é£é™©çŠ¶æ€è¯„ä¼°ï¼š
        - å°¾éƒ¨é£é™©ï¼š{tail_risk_summary}
        - é£é™©é¢„è­¦ï¼š{alert_summary}
        - æƒ…ç»ª-æµåŠ¨æ€§åŒ¹é…ï¼š{match_trend}
    
        ğŸ¯ æ“ä½œå»ºè®®ï¼ˆåŸºäºå½“å‰æ¨¡å¼å’Œå¸‚åœºç›¸å¯¹ä½ç½®ï¼‰ï¼š
        {('ğŸ”´ã€ç´§æ€¥è¡ŒåŠ¨ã€‘æµåŠ¨æ€§å±æœºæ¨¡å¼å·²ç¡®è®¤ï¼å»ºè®®ï¼š' +
        '   - ç«‹å³å‡ä»“50%ä»¥ä¸Šï¼Œä¿ç•™ç°é‡‘åº”å¯¹æµåŠ¨æ€§æ¯ç«­' +
        '   - ä¹°å…¥çŸ­æœŸè™šå€¼PutæœŸæƒå¯¹å†²å°¾éƒ¨é£é™©' +
        '   - å¯†åˆ‡ç›‘æ§æµåŠ¨æ€§æŒ‡æ ‡ï¼Œè‹¥åŠ é€Ÿåº¦ç»§ç»­ä¸Šå‡åˆ™å…¨éƒ¨ç¦»åœº' if liquidity_crisis else
        'ğŸŸ¢ã€ç§¯æå¸ƒå±€ã€‘å¥åº·ä¸Šæ¶¨æ¨¡å¼ç¡®è®¤ï¼å»ºè®®ï¼š' +
        '   - ä¿æŒæˆ–é€‚åº¦åŠ ä»“ï¼Œç›®æ ‡ä»“ä½70-90%' +
        '   - ä½¿ç”¨å¤‡å…‘ç­–ç•¥(Covered Call)å¢å¼ºæ”¶ç›Š' +
        '   - è‹¥æœºæ„å‚ä¸åº¦å¢é€Ÿæ”¾ç¼“åˆ™éƒ¨åˆ†æ­¢ç›ˆ' if healthy_rally else
        'ğŸŸ¡ã€è°¨æ…æ“ä½œã€‘æƒ…ç»ªé©±åŠ¨æ³¢åŠ¨æ¨¡å¼ï¼å»ºè®®ï¼š' +
        '   - é™ä½ä»“ä½è‡³30-50%ï¼Œé¿å…è¿½é«˜æ€è·Œ' +
        '   - é‡‡ç”¨è·¨å¼ç»„åˆ(Straddle)æ•æ‰æ³¢åŠ¨' +
        '   - é‡ç‚¹ç›‘æ§æœºæ„å‚ä¸åº¦å˜åŒ–ï¼Œåˆ¤æ–­è¶‹åŠ¿æ–¹å‘' if emotion_volatility else
        'ğŸ”µã€è§‚å¯Ÿç­‰å¾…ã€‘æ··åˆçŠ¶æ€ï¼å»ºè®®ï¼š' +
        '   - ç»´æŒä¸­æ€§ä»“ä½(40-60%)' +
        '   - è®¾ç½®çªç ´ç­–ç•¥ï¼šè‹¥æµåŠ¨æ€§æ¯ç«­æŒ‡æ•°çªç ´0.85åˆ™å‡ä»“ï¼Œè·Œç ´0.5åˆ™åŠ ä»“' +
        '   - æ¯å‘¨é‡æ–°è¯„ä¼°å¸‚åœºæ¨¡å¼')}
        
        ğŸ“Œ é£é™©æç¤ºï¼š
        - æœ¬åˆ†æåŸºäºå†å²æ•°æ®ï¼Œæœªæ¥å¸‚åœºç»“æ„å¯èƒ½å˜åŒ–
        - å»ºè®®æ¯å‘¨æ›´æ–°åˆ†æï¼Œå°¤å…¶å…³æ³¨é¢†å…ˆæŒ‡æ ‡å˜åŒ–
        
        ğŸ” æ·±åº¦æ´å¯Ÿï¼š
        {('æµåŠ¨æ€§æ¯ç«­æŒ‡æ•°é¢†å…ˆé£é™©æº¢ä»·çº¦' + str(-best_lag) + 'å¤©ï¼Œå¯ä½œä¸ºæ—©æœŸé¢„è­¦ä¿¡å·ã€‚'
        if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag < 0
        else 'é£é™©æƒ…ç»ªå˜åŒ–æ˜¯æµåŠ¨æ€§æ¶åŒ–çš„æ—©æœŸæŒ‡æ ‡ï¼Œæå‰å…³æ³¨é£é™©æº¢ä»·èµ°åŠ¿ã€‚'
        if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag > 0
        else 'æµåŠ¨æ€§ä¸é£é™©æƒ…ç»ªåŒæ­¥å˜åŒ–ï¼Œéœ€åŒæ—¶ç›‘æ§ä¸¤ç±»æŒ‡æ ‡ã€‚')}
        
        ğŸ’¡ ç‰¹åˆ«æç¤ºï¼š
        è¯¥è‚¡ç¥¨å½“å‰è¡¨ç°{('æ˜¾è‘—é¢†å…ˆ' if inst_part_relative and inst_part_relative > 0.5 and liquidity_relative and liquidity_relative < 0 else
        'é¢†å…ˆ' if inst_part_relative and inst_part_relative > 0.3 and liquidity_relative and liquidity_relative < 0.3 else
        'è½åäº' if inst_part_relative and inst_part_relative < -0.5 and liquidity_relative and liquidity_relative > 0.5 else
        'ä¸')}å¸‚åœºæ•´ä½“ï¼Œ{('å»ºè®®' if inst_part_relative and inst_part_relative > 0.3 and liquidity_relative and liquidity_relative < 0.3 else 'è°¨æ…')}{'å¢æŒ' if inst_part_relative and inst_part_relative > 0.5 and liquidity_relative and liquidity_relative < 0 else 'å‡æŒ' if inst_part_relative and inst_part_relative < -0.5 and liquidity_relative and liquidity_relative > 0.5 else 'æŒæœ‰'}
        """.strip()

        return summary

    def _analyze_ETF(self, start_date:int, end_date:int, order_book_id_list: list = None):
        """
        å¯¹ETFæ—¥çº¿æ•°æ®è¿›è¡Œæ·±åº¦åˆ†æï¼Œè¾“å‡ºåŒ…å«æ‰€æœ‰å…³é”®æŒ‡æ ‡çš„å­—å…¸åˆ—è¡¨
        """
        etf_features_list = ['open', 'close', 'high', 'low', 'total_turnover', 'volume', 'num_trades', 'prev_close', 'iopv']
        df = self.ricequant_service.instruments_data_fetching(type='ETF', start_date=start_date, end_date=end_date, features_list=etf_features_list, order_book_id_list=order_book_id_list)

        # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®å¹¶æ’åº
        df['date'] = pd.to_datetime(df['date'], format='%Y/%m/%d')
        df = df.sort_values(['order_book_id', 'date']).reset_index(drop=True)

        # è®¡ç®—åŸºç¡€æŒ‡æ ‡
        # æ—¥æº¢ä»·ç‡ (æ ¸å¿ƒæŒ‡æ ‡)
        df['daily_premium_rate'] = (df['close'] - df['iopv']) / df['iopv']

        # iopvç¨³å®šæ€§ (æ›¿ä»£æ—¥å†…æ³¢åŠ¨ç‡)
        price_range = (df['high'] - df['low']).replace(0, np.nan)
        df['iopv_stability'] = np.where(
            price_range.notna(),
            1 - (df['iopv'] - df['close']).abs() / price_range,
            np.nan
        )

        # ETFæ—¥æ”¶ç›Šç‡
        df['etf_return'] = df['close'] / df['prev_close'] - 1

        # æ— æŒ‡æ•°æ•°æ®æ—¶çš„æ›¿ä»£æ–¹æ¡ˆ
        df['tracking_error'] = np.nan
        df['index_volatility'] = np.nan
        df['actual_tracking_cost'] = np.nan

        # 3. æº¢ä»·æŒç»­æ€§ (è€ƒè™‘æˆäº¤é‡)
        df['volume_ma_20'] = df['volume'].rolling(20, min_periods=10).mean()
        df['premium_persistence'] = df['daily_premium_rate'] * (df['volume'] / df['volume_ma_20'])

        # 4. æº¢ä»·ç‡ä¸æˆäº¤é‡çš„ç›¸å…³æ€§ (ç”¨äºæµåŠ¨æ€§å±æœºé¢„è­¦)
        df['premium_vol_corr'] = df['daily_premium_rate'].rolling(20, min_periods=10).corr(df['volume'])

        # 5. ç®€åŒ–ç‰ˆè¯¯å·®ä¿®æ­£é¡¹ (æ¨¡æ‹ŸEC term)
        # åŸç†ï¼šæº¢ä»·ç‡å‘0å›å½’çš„é€Ÿåº¦ï¼Œå€¼è¶Šå¤§è¡¨ç¤ºå›å½’è¶Šå¿«
        df['ec_term'] = np.nan

        # ä»…å½“æœ‰è¶³å¤Ÿæ•°æ®æ—¶è®¡ç®—
        for i in range(20, len(df)):
            window_premium = df['daily_premium_rate'].iloc[i - 19:i + 1]
            # è®¡ç®—æº¢ä»·ç‡çš„å‡å€¼å›å½’ç³»æ•°ï¼ˆç®€åŒ–ç‰ˆEC termï¼‰
            if len(window_premium) >= 10 and not window_premium.isna().all():
                try:
                    # ç”¨æ˜¨æ—¥æº¢ä»·ç‡é¢„æµ‹ä»Šæ—¥æº¢ä»·ç‡ï¼Œå›å½’ç³»æ•°åæ˜ å‡å€¼å›å½’é€Ÿåº¦
                    x = window_premium.iloc[:-1].values
                    y = window_premium.iloc[1:].values
                    slope, _, _, _, _ = stats.linregress(x, y)
                    # EC term = 1 - slope (æ­£å€¼è¡¨ç¤ºå‡å€¼å›å½’)
                    df.iloc[i, df.columns.get_loc('ec_term')] = 1 - slope
                except:
                    pass

        # 6. é£é™©é¢„è­¦ä¿¡å·
        df['risk_alert'] = False

        # æ¡ä»¶1ï¼šæº¢ä»·ç‡æŒç»­3æ—¥ > 0.5%
        premium_high = (df['daily_premium_rate'] > 0.005)
        df['premium_high_streak'] = premium_high.astype(int).groupby((~premium_high).cumsum()).cumsum()

        # æ¡ä»¶2ï¼šå®é™…è·Ÿè¸ªæˆæœ¬ > æŒ‡æ•°æ³¢åŠ¨ç‡15%
        if 'index_volatility' in df and 'actual_tracking_cost' in df:
            cost_to_vol_ratio = df['actual_tracking_cost'] / df['index_volatility']
            high_cost = cost_to_vol_ratio > 1.15  # æ¯”æŒ‡æ•°æ³¢åŠ¨ç‡é«˜15%

            # é£é™©é¢„è­¦ï¼šæ»¡è¶³ä¸¤ä¸ªæ¡ä»¶
            df['risk_alert'] = (df['premium_high_streak'] >= 3) & high_cost

        # 7. å¥—åˆ©æœºä¼šä¿¡å·
        df['arbitrage_opportunity'] = False
        if 'ec_term' in df:
            # å¥—åˆ©çª—å£æœŸï¼šå½“ |EC term| > 0.5 ä¸” æº¢ä»·ç‡ > 0.3%
            df['arbitrage_opportunity'] = (df['ec_term'].abs() > 0.5) & (df['daily_premium_rate'].abs() > 0.003)

        # 8. æµåŠ¨æ€§å±æœºé¢„è­¦
        df['liquidity_crisis_warning'] = False
        if 'premium_vol_corr' in df and 'ec_term' in df:
            # å½“æº¢ä»·ç‡ä¸volumeè´Ÿç›¸å…³ï¼ˆPearson < -0.4ï¼‰ï¼Œä¸”EC termè¶‹è¿‘0
            df['liquidity_crisis_warning'] = (df['premium_vol_corr'] < -0.4) & (df['ec_term'].abs() < 0.1)

        # 9. æ„å»ºç»“æœå­—å…¸
        results = []
        for _, row in df.iterrows():
            result = {
                "date": row['date'].strftime('%Y-%m-%d'),
                "order_book_id": row['order_book_id'],
                "daily_premium_rate": float(row['daily_premium_rate']),
                "iopv_stability": float(row['iopv_stability']) if not pd.isna(row['iopv_stability']) else None,
                "etf_return": float(row['etf_return']),
                "premium_persistence": float(row['premium_persistence']) if not pd.isna(
                    row['premium_persistence']) else None,
                "tracking_error": float(row['tracking_error']) if not pd.isna(row['tracking_error']) else None,
                "index_volatility": float(row['index_volatility']) if not pd.isna(
                    row['index_volatility']) else None,
                "actual_tracking_cost": float(row['actual_tracking_cost']) if not pd.isna(
                    row['actual_tracking_cost']) else None,
                "premium_vol_corr": float(row['premium_vol_corr']) if not pd.isna(
                    row['premium_vol_corr']) else None,
                "ec_term": float(row['ec_term']) if not pd.isna(row['ec_term']) else None,
                "risk_alert": bool(row['risk_alert']),
                "arbitrage_opportunity": bool(row['arbitrage_opportunity']),
                "liquidity_crisis_warning": bool(row['liquidity_crisis_warning'])
            }
            results.append(result)

        return results

    def summarize_ETFanalysis(self, start_date: int, end_date: int, target_ETF_id=None,
                                order_book_id_list: list = None, lookback_days=30, confidence_level=0.95):
        """
        å¯¹ETFæ·±åº¦åˆ†ææŒ‡æ ‡è¿›è¡Œæ—¶é—´åºåˆ—è¶‹åŠ¿åˆ†æï¼Œè¯†åˆ«åŠ¨æ€æ¨¡å¼ä¸é¢†å…ˆ-æ»åå…³ç³»
        å…³é”®ç‰¹æ€§ï¼šåŸºäºå¤šåªETFæ•°æ®ï¼Œæä¾›ç›®æ ‡ETFçš„ç›¸å¯¹å¸‚åœºå®šä½åˆ†æï¼Œå¹¶æ•æ‰æ—¶é—´åºåˆ—è¶‹åŠ¿
        """
        # 1. è·å–ETFåˆ†æç»“æœ
        analysis_results = self._analyze_ETF(start_date, end_date, order_book_id_list)
        if not analysis_results:
            return "æ— ETFæ•°æ®å¯ä¾›åˆ†æã€‚"

        # è½¬æ¢ä¸ºDataFrameå¹¶é¢„å¤„ç†
        df = pd.DataFrame(analysis_results)

        # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
        if not pd.api.types.is_datetime64_any_dtype(df['date']):
            df['date'] = pd.to_datetime(df['date'])

        # æŒ‰ETFä»£ç å’Œæ—¥æœŸæ’åº
        df = df.sort_values(['order_book_id', 'date']).reset_index(drop=True)

        # ======================
        # 2. ç¡»å®šç›®æ ‡ETFå¹¶è®¡ç®—å¸‚åœºåŸºå‡†
        # ======================

        # ç¡®å®šè¦åˆ†æçš„ç›®æ ‡ETF
        if target_ETF_id:
            if target_ETF_id not in df['order_book_id'].unique():
                return f"æœªæ‰¾åˆ°ETF {target_ETF_id} çš„æ•°æ®ã€‚"
        else:
            # è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªETF
            target_ETF_id = df['order_book_id'].iloc[0]

        # è·å–æœ€æ–°æ—¥æœŸï¼ˆç”¨äºå¸‚åœºåŸºå‡†è®¡ç®—ï¼‰
        latest_date = df['date'].max()

        # è·å–æ‰€æœ‰ETFåœ¨æœ€æ–°æ—¥æœŸçš„æ•°æ®ï¼ˆç”¨äºè®¡ç®—å¸‚åœºåŸºå‡†ï¼‰
        market_df = df[df['date'] == latest_date].copy()

        # è®¡ç®—å¸‚åœºåŸºå‡†ï¼ˆæ’é™¤ç›®æ ‡ETFè‡ªèº«ï¼Œé¿å…è‡ªç›¸å…³ï¼‰
        market_benchmarks = {}
        if len(market_df) > 1:  # è‡³å°‘æœ‰2åªETFæ‰èƒ½è®¡ç®—æœ‰æ„ä¹‰çš„åŸºå‡†
            market_without_target = market_df[market_df['order_book_id'] != target_ETF_id]
            if not market_without_target.empty:
                # åªæœ‰å½“ec_termå­˜åœ¨ä¸”éç©ºæ—¶æ‰è®¡ç®—å…¶ç»Ÿè®¡é‡
                valid_ec_term = market_without_target['ec_term'].dropna()
                ec_term_mean = valid_ec_term.mean() if not valid_ec_term.empty else None
                ec_term_quantiles = valid_ec_term.quantile([0.25, 0.75]) if not valid_ec_term.empty else None

                market_benchmarks = {
                    'premium_mean': market_without_target['daily_premium_rate'].mean(),
                    'premium_25pct': market_without_target['daily_premium_rate'].quantile(0.25),
                    'premium_75pct': market_without_target['daily_premium_rate'].quantile(0.75),
                    'stability_mean': market_without_target['iopv_stability'].mean(),
                    'stability_25pct': market_without_target['iopv_stability'].quantile(0.25),
                    'stability_75pct': market_without_target['iopv_stability'].quantile(0.75),
                    'tracking_cost_mean': market_without_target['actual_tracking_cost'].mean(),
                    'ec_term_mean': ec_term_mean,
                    'ec_term_25pct': ec_term_quantiles[0.25] if ec_term_quantiles is not None else None,
                    'ec_term_75pct': ec_term_quantiles[0.75] if ec_term_quantiles is not None else None
                }

        # é€‰æ‹©ç›®æ ‡ETFçš„æ—¶é—´åºåˆ—æ•°æ®
        etf_df = df[df['order_book_id'] == target_ETF_id].copy()

        # é™åˆ¶åˆ†æçª—å£
        if len(etf_df) > lookback_days:
            etf_df = etf_df.tail(lookback_days).reset_index(drop=True)

        n = len(etf_df)
        if n < 10:  # éœ€è¦è¶³å¤Ÿæ•°æ®è¿›è¡Œè¶‹åŠ¿åˆ†æ
            return f"ETF {target_ETF_id} æ•°æ®ç‚¹ä¸è¶³ï¼ˆ{n}å¤©ï¼‰ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆè¶‹åŠ¿åˆ†æã€‚"

        # è·å–æœ€æ–°æ•°æ®ç‚¹
        latest = etf_df.iloc[-1]

        # ======================
        # 3. æ·±åº¦æ—¶é—´åºåˆ—è¶‹åŠ¿åˆ†æ
        # ======================

        # --- 3.1 æº¢ä»·ç‡è¶‹åŠ¿ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰---
        premium_rate = etf_df['daily_premium_rate'].astype(float)

        # è®¡ç®—çº¿æ€§è¶‹åŠ¿æ–œç‡å’Œæ˜¾è‘—æ€§
        x = np.arange(n)
        try:
            slope_premium, intercept_premium, r_premium, p_premium, std_err_premium = stats.linregress(x,
                                                                                                       premium_rate)
            trend_strength_premium = abs(slope_premium) * n / (premium_rate.abs().mean() + 1e-5)

            # è¶‹åŠ¿åˆ†ç±»
            premium_trend_desc = ""
            if p_premium < (1 - confidence_level):
                if slope_premium > 0:
                    if trend_strength_premium > 0.5:
                        premium_trend_desc = "æ˜¾è‘—ä¸Šå‡è¶‹åŠ¿ï¼ŒäºŒçº§å¸‚åœºæŒç»­ä¾›ä¸åº”æ±‚"
                    elif trend_strength_premium > 0.2:
                        premium_trend_desc = "æ¸©å’Œä¸Šå‡è¶‹åŠ¿ï¼ŒäºŒçº§å¸‚åœºéœ€æ±‚é€æ­¥å¢å¼º"
                    else:
                        premium_trend_desc = "è½»å¾®ä¸Šå‡è¶‹åŠ¿ï¼Œæº¢ä»·ç‡ç¼“æ…¢æ”¹å–„"
                else:
                    if trend_strength_premium > 0.5:
                        premium_trend_desc = "æ˜¾è‘—ä¸‹é™è¶‹åŠ¿ï¼ŒäºŒçº§å¸‚åœºæŠ›å‹æŒç»­"
                    elif trend_strength_premium > 0.2:
                        premium_trend_desc = "æ¸©å’Œä¸‹é™è¶‹åŠ¿ï¼ŒäºŒçº§å¸‚åœºæŠ›å‹é€æ­¥æ˜¾ç°"
                    else:
                        premium_trend_desc = "è½»å¾®ä¸‹é™è¶‹åŠ¿ï¼Œæº¢ä»·ç‡ç¼“æ…¢æ¶åŒ–"

                # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                premium_trend_desc += f"ï¼ˆæ–œç‡={slope_premium:.4f}, p={p_premium:.3f}ï¼‰"
            else:
                premium_trend_desc = "æ— æ˜¾è‘—è¶‹åŠ¿ï¼Œæº¢ä»·ç‡éšæœºæ³¢åŠ¨"
        except Exception as e:
            premium_trend_desc = "æº¢ä»·ç‡è¶‹åŠ¿åˆ†æå¤±è´¥ï¼Œæ•°æ®å¯èƒ½å­˜åœ¨é—®é¢˜"

        # --- 3.2 iopvç¨³å®šæ€§è¶‹åŠ¿ ---
        stability = etf_df['iopv_stability'].dropna().astype(float)

        # æ£€æµ‹ç¨³å®šæ€§å˜åŒ–ç‡
        stability_ma = stability.rolling(window=5).mean().dropna()
        stability_change = stability_ma.diff().mean() if len(stability_ma) > 1 else 0

        stability_status = ""
        if len(stability) > 0:
            current_stability = stability.iloc[-1]
            if current_stability < 0.3:
                stability_status = f"iopvä¸¥é‡å¤±çœŸï¼ˆå½“å‰å€¼={current_stability:.2f}ï¼‰ï¼ŒETF NAVè®¡ç®—å¯èƒ½å¤±æ•ˆï¼Œè­¦æƒ•æˆåˆ†è‚¡åœç‰Œå½±å“"
            elif current_stability < 0.6:
                stability_status = f"iopvç¨³å®šæ€§ä¸€èˆ¬ï¼ˆå½“å‰å€¼={current_stability:.2f}ï¼‰ï¼Œéœ€å…³æ³¨æˆåˆ†è‚¡æµåŠ¨æ€§"
            else:
                stability_status = f"iopvç¨³å®šæ€§è‰¯å¥½ï¼ˆå½“å‰å€¼={current_stability:.2f}ï¼‰ï¼ŒETFå®šä»·æ•ˆç‡é«˜"

            # æ·»åŠ å˜åŒ–è¶‹åŠ¿
            if stability_change > 0.05:
                stability_status += "ï¼Œä¸”å‘ˆæ˜æ˜¾æ”¹å–„è¶‹åŠ¿"
            elif stability_change < -0.05:
                stability_status += "ï¼Œä¸”å‘ˆæ˜æ˜¾æ¶åŒ–è¶‹åŠ¿"
        else:
            stability_status = "iopvç¨³å®šæ€§æ•°æ®ä¸è¶³"

        # --- 3.3 å®é™…è·Ÿè¸ªæˆæœ¬åˆ†æ ---
        tracking_cost = etf_df['actual_tracking_cost'].dropna()
        tracking_cost_summary = "å®é™…è·Ÿè¸ªæˆæœ¬æ•°æ®ä¸è¶³"

        if len(tracking_cost) >= 15:
            # è®¡ç®—è·Ÿè¸ªæˆæœ¬è¶‹åŠ¿
            x_tc = np.arange(len(tracking_cost))
            try:
                slope_tc, _, _, p_tc, _ = stats.linregress(x_tc, tracking_cost)

                if p_tc < (1 - confidence_level) and slope_tc > 0:
                    tracking_cost_summary = f"å®é™…è·Ÿè¸ªæˆæœ¬å‘ˆæ˜¾è‘—ä¸Šå‡è¶‹åŠ¿ï¼ˆæ–œç‡={slope_tc:.4f}, p={p_tc:.3f}ï¼‰ï¼ŒETFæ•ˆç‡æŒç»­æ¶åŒ–"
                elif p_tc < (1 - confidence_level) and slope_tc < 0:
                    tracking_cost_summary = f"å®é™…è·Ÿè¸ªæˆæœ¬å‘ˆæ˜¾è‘—ä¸‹é™è¶‹åŠ¿ï¼ˆæ–œç‡={slope_tc:.4f}, p={p_tc:.3f}ï¼‰ï¼ŒETFæ•ˆç‡æŒç»­æ”¹å–„"
                else:
                    tracking_cost_summary = f"å®é™…è·Ÿè¸ªæˆæœ¬æ³¢åŠ¨ä½†æ— æ˜¾è‘—è¶‹åŠ¿ï¼ˆp={p_tc:.3f}ï¼‰ï¼ŒETFæ•ˆç‡ä¿æŒç¨³å®š"
            except Exception as e:
                tracking_cost_summary = "å®é™…è·Ÿè¸ªæˆæœ¬è¶‹åŠ¿åˆ†æå¤±è´¥"

        # --- 3.4 æº¢ä»·ç‡ä¸æˆäº¤é‡å…³ç³» ---
        premium_vol_corr = etf_df['premium_vol_corr'].dropna()
        corr_summary = "æº¢ä»·ç‡ä¸æˆäº¤é‡å…³ç³»æ•°æ®ä¸è¶³"

        if len(premium_vol_corr) > 5:
            avg_corr = premium_vol_corr.mean()
            if avg_corr < -0.4:
                corr_summary = f"æº¢ä»·ç‡ä¸æˆäº¤é‡æ˜¾è‘—è´Ÿç›¸å…³ï¼ˆå‡å€¼={avg_corr:.2f}ï¼‰ï¼Œå¸‚åœºå¯èƒ½å¤±æ•ˆ"
            elif avg_corr < -0.2:
                corr_summary = f"æº¢ä»·ç‡ä¸æˆäº¤é‡è´Ÿç›¸å…³ï¼ˆå‡å€¼={avg_corr:.2f}ï¼‰ï¼Œéœ€å…³æ³¨æµåŠ¨æ€§"
            elif avg_corr > 0.4:
                corr_summary = f"æº¢ä»·ç‡ä¸æˆäº¤é‡æ˜¾è‘—æ­£ç›¸å…³ï¼ˆå‡å€¼={avg_corr:.2f}ï¼‰ï¼Œå¸‚åœºæ•ˆç‡é«˜"
            else:
                corr_summary = f"æº¢ä»·ç‡ä¸æˆäº¤é‡ç›¸å…³æ€§å¼±ï¼ˆå‡å€¼={avg_corr:.2f}ï¼‰ï¼Œå¸‚åœºè¿è¡Œæ­£å¸¸"
        else:
            corr_summary = "æº¢ä»·ç‡ä¸æˆäº¤é‡å…³ç³»æ•°æ®ä¸è¶³"

        # --- 3.5 è¯¯å·®ä¿®æ­£é¡¹(EC term)è¶‹åŠ¿ ---
        ec_term = etf_df['ec_term'].dropna()
        ec_term_summary = "è¯¯å·®ä¿®æ­£é¡¹æ•°æ®ä¸è¶³"

        if len(ec_term) >= 15:
            # è®¡ç®—EC termè¶‹åŠ¿
            x_ec = np.arange(len(ec_term))
            try:
                slope_ec, _, _, p_ec, _ = stats.linregress(x_ec, ec_term)

                if p_ec < (1 - confidence_level) and slope_ec > 0.1:
                    ec_term_summary = f"EC termå‘ˆæ˜¾è‘—ä¸Šå‡è¶‹åŠ¿ï¼ˆæ–œç‡={slope_ec:.2f}, p={p_ec:.3f}ï¼‰ï¼Œæº¢ä»·æ”¶æ•›é€Ÿåº¦åŠ å¿«"
                elif p_ec < (1 - confidence_level) and slope_ec < -0.1:
                    ec_term_summary = f"EC termå‘ˆæ˜¾è‘—ä¸‹é™è¶‹åŠ¿ï¼ˆæ–œç‡={slope_ec:.2f}, p={p_ec:.3f}ï¼‰ï¼Œæº¢ä»·æ”¶æ•›é€Ÿåº¦å‡æ…¢"
                else:
                    ec_term_summary = f"EC termæ³¢åŠ¨ä½†æ— æ˜¾è‘—è¶‹åŠ¿ï¼ˆp={p_ec:.3f}ï¼‰ï¼Œæº¢ä»·æ”¶æ•›æœºåˆ¶ç¨³å®š"
            except Exception as e:
                ec_term_summary = "EC termè¶‹åŠ¿åˆ†æå¤±è´¥"
        else:
            ec_term_summary = "è¯¯å·®ä¿®æ­£é¡¹æ•°æ®ä¸è¶³"

        # --- 3.6 é¢†å…ˆ-æ»åå…³ç³»åˆ†æ ---
        lead_lag_results = []
        best_lag = None
        best_corr = 0.0
        if len(ec_term) >= 20 and len(premium_rate) >= 20:
            for lag in range(-7, 8):  # -7åˆ°+7å¤©çš„æ»å
                try:
                    if lag <= 0:
                        corr = ec_term[:lag].corr(premium_rate[-lag:]) if lag != 0 else ec_term.corr(premium_rate)
                    else:
                        corr = ec_term[lag:].corr(premium_rate[:-lag])
                    lead_lag_results.append((lag, corr))
                except:
                    continue

            if lead_lag_results:
                best_lag, best_corr = max(lead_lag_results, key=lambda x: abs(x[1]))
                if abs(best_corr) > 0.4:
                    if best_lag < 0:
                        lead_lag_summary = f"EC termé¢†å…ˆæº¢ä»·ç‡çº¦{-best_lag}å¤©ï¼ˆæœ€å¤§ç›¸å…³ç³»æ•°={best_corr:.2f}ï¼‰ï¼Œæ˜¯æº¢ä»·å˜åŒ–çš„å…ˆè¡ŒæŒ‡æ ‡"
                    elif best_lag > 0:
                        lead_lag_summary = f"æº¢ä»·ç‡é¢†å…ˆEC termçº¦{best_lag}å¤©ï¼ˆæœ€å¤§ç›¸å…³ç³»æ•°={best_corr:.2f}ï¼‰ï¼Œæº¢ä»·å˜åŒ–å…ˆäºæ”¶æ•›æœºåˆ¶"
                    else:
                        lead_lag_summary = f"EC termä¸æº¢ä»·ç‡åŒæ­¥å˜åŒ–ï¼ˆç›¸å…³ç³»æ•°={best_corr:.2f}ï¼‰ï¼Œæ”¶æ•›æœºåˆ¶ä¸æº¢ä»·è”åŠ¨ç´§å¯†"
                else:
                    lead_lag_summary = "EC termä¸æº¢ä»·ç‡å…³ç³»ä¸ç¨³å®šï¼Œæ— æ˜æ˜¾é¢†å…ˆ-æ»åæ¨¡å¼"
            else:
                lead_lag_summary = "æ— æ³•è®¡ç®—é¢†å…ˆ-æ»åå…³ç³»ï¼Œç›¸å…³ç³»æ•°è®¡ç®—å¤±è´¥"
        else:
            lead_lag_summary = "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œé¢†å…ˆ-æ»ååˆ†æ"

        # ======================
        # 4. è¯†åˆ«å…³é”®åŠ¨æ€æ¨¡å¼
        # ======================

        # æ¨¡å¼1: å¥åº·ETFæ¨¡å¼
        healthy_etf = (
                "ä¸Šå‡è¶‹åŠ¿" not in premium_trend_desc and
                "iopvä¸¥é‡å¤±çœŸ" not in stability_status and
                "æ•ˆç‡æŒç»­æ¶åŒ–" not in tracking_cost_summary and
                "æ˜¾è‘—æ­£ç›¸å…³" in corr_summary and
                "æ”¶æ•›é€Ÿåº¦åŠ å¿«" in ec_term_summary
        )

        # æ¨¡å¼2: å®šä»·å¤±æ•ˆæ¨¡å¼
        pricing_failure = (
                ("æ˜¾è‘—ä¸Šå‡è¶‹åŠ¿" in premium_trend_desc or "æ˜¾è‘—ä¸‹é™è¶‹åŠ¿" in premium_trend_desc) and
                ("iopvä¸¥é‡å¤±çœŸ" in stability_status or "iopvç¨³å®šæ€§ä¸€èˆ¬" in stability_status) and
                "æ•ˆç‡æŒç»­æ¶åŒ–" in tracking_cost_summary
        )

        # æ¨¡å¼3: æµåŠ¨æ€§å±æœºæ¨¡å¼
        liquidity_crisis = (
                "æ˜¾è‘—è´Ÿç›¸å…³" in corr_summary and
                ("æ”¶æ•›é€Ÿåº¦å‡æ…¢" in ec_term_summary or ("ä¸‹é™è¶‹åŠ¿" in ec_term_summary and best_lag and best_lag > 0))
        )

        # ======================
        # 5. ç›¸å¯¹å¸‚åœºå®šä½åˆ†æ
        # ======================

        # åˆå§‹åŒ–ç›¸å¯¹ä½ç½®æè¿°
        premium_relative_desc = "æ— å¸‚åœºæ¯”è¾ƒæ•°æ®"
        stability_relative_desc = "æ— å¸‚åœºæ¯”è¾ƒæ•°æ®"
        ec_term_relative_desc = "æ— å¸‚åœºæ¯”è¾ƒæ•°æ®"

        premium_relative = None
        stability_relative = None
        ec_term_relative = None

        # 1. æº¢ä»·ç‡ç›¸å¯¹ä½ç½®
        if 'premium_mean' in market_benchmarks and market_benchmarks['premium_mean'] is not None:
            iqr = market_benchmarks['premium_75pct'] - market_benchmarks['premium_25pct']
            if iqr > 1e-5:
                premium_relative = (
                        (latest['daily_premium_rate'] - market_benchmarks['premium_mean']) /
                        (iqr + 1e-5)
                )
                if premium_relative > 1.0:
                    premium_relative_desc = "æº¢ä»·ç‡æ˜¾è‘—é«˜äºåŒç±»ETFï¼ŒäºŒçº§å¸‚åœºä¾›ä¸åº”æ±‚"
                elif premium_relative > 0.5:
                    premium_relative_desc = "æº¢ä»·ç‡é«˜äºåŒç±»ETFå¹³å‡æ°´å¹³"
                elif premium_relative < -1.0:
                    premium_relative_desc = "æº¢ä»·ç‡æ˜¾è‘—ä½äºåŒç±»ETFï¼Œå­˜åœ¨èµå›å‹åŠ›"
                elif premium_relative < -0.5:
                    premium_relative_desc = "æº¢ä»·ç‡ä½äºåŒç±»ETFå¹³å‡æ°´å¹³"
                else:
                    premium_relative_desc = "æº¢ä»·ç‡å¤„äºåŒç±»ETFæ­£å¸¸æ°´å¹³"

        # 2. iopvç¨³å®šæ€§ç›¸å¯¹ä½ç½®
        if 'stability_mean' in market_benchmarks and market_benchmarks['stability_mean'] is not None:
            iqr = market_benchmarks['stability_75pct'] - market_benchmarks['stability_25pct']
            if iqr > 1e-5:
                stability_relative = (
                        (latest['iopv_stability'] - market_benchmarks['stability_mean']) /
                        (iqr + 1e-5)
                )
                if stability_relative > 1.0:
                    stability_relative_desc = "iopvç¨³å®šæ€§æ˜¾è‘—ä¼˜äºåŒç±»ETF"
                elif stability_relative > 0.5:
                    stability_relative_desc = "iopvç¨³å®šæ€§ä¼˜äºåŒç±»ETF"
                elif stability_relative < -1.0:
                    stability_relative_desc = "iopvç¨³å®šæ€§æ˜¾è‘—åŠ£äºåŒç±»ETFï¼Œè­¦æƒ•å®šä»·å¤±çœŸ"
                elif stability_relative < -0.5:
                    stability_relative_desc = "iopvç¨³å®šæ€§åŠ£äºåŒç±»ETF"
                else:
                    stability_relative_desc = "iopvç¨³å®šæ€§å¤„äºåŒç±»ETFæ­£å¸¸æ°´å¹³"

        # 3. EC termç›¸å¯¹ä½ç½®
        if ('ec_term_mean' in market_benchmarks and
                market_benchmarks['ec_term_mean'] is not None and
                not pd.isna(latest['ec_term'])):

            iqr_val = (market_benchmarks['ec_term_75pct'] - market_benchmarks[
                'ec_term_25pct']) if 'ec_term_75pct' in market_benchmarks and 'ec_term_25pct' in market_benchmarks else None

            if iqr_val and iqr_val > 1e-5:
                ec_term_relative = (
                        (latest['ec_term'] - market_benchmarks['ec_term_mean']) /
                        (iqr_val + 1e-5)
                )
                if ec_term_relative > 0.5:
                    ec_term_relative_desc = "æº¢ä»·æ”¶æ•›é€Ÿåº¦ä¼˜äºåŒç±»ETF"
                elif ec_term_relative < -0.5:
                    ec_term_relative_desc = "æº¢ä»·æ”¶æ•›é€Ÿåº¦åŠ£äºåŒç±»ETF"
                else:
                    ec_term_relative_desc = "æº¢ä»·æ”¶æ•›é€Ÿåº¦å¤„äºåŒç±»ETFæ­£å¸¸æ°´å¹³"
            else:
                ec_term_relative_desc = "EC termå¸‚åœºåŸºå‡†æ•°æ®ä¸è¶³"

        # ======================
        # 6. ç»¼åˆæ€»ç»“è¾“å‡º
        # ======================
        summary = f"""
        ã€{target_ETF_id} ETFæ·±åº¦è¶‹åŠ¿åˆ†ææŠ¥å‘Šã€‘ï¼ˆæˆªè‡³ {etf_df['date'].max().strftime('%Y-%m-%d')}ï¼‰
        
        ğŸŒ å¸‚åœºç›¸å¯¹å®šä½ï¼ˆåŸºäº{len(market_df)}åªETFæœ€æ–°æ•°æ®ï¼‰ï¼š
        - æº¢ä»·ç‡æ°´å¹³ï¼š{premium_relative_desc}
        - iopvç¨³å®šæ€§ï¼š{stability_relative_desc}
        - æº¢ä»·æ”¶æ•›é€Ÿåº¦ï¼š{ec_term_relative_desc}
        
        ğŸ” æ ¸å¿ƒè¶‹åŠ¿è¯Šæ–­ï¼ˆåŸºäº{len(etf_df)}å¤©æ•°æ®ï¼‰ï¼š
        1. **æº¢ä»·ç‡è¶‹åŠ¿**ï¼š{premium_trend_desc}
        - å½“å‰æº¢ä»·ç‡ï¼š{latest['daily_premium_rate']:.4%}
        - ç›¸å¯¹å¸‚åœºä½ç½®ï¼š{'é«˜äº' if premium_relative and premium_relative > 0 else 'ä½äº' if premium_relative and premium_relative < 0 else 'æ¥è¿‘'}å¸‚åœºä¸­ä½æ•°
        - æº¢ä»·æŒç»­æ€§ï¼š{latest['premium_persistence']:.4f}ï¼ˆæ­£å€¼è¡¨ç¤ºè¶‹åŠ¿å»¶ç»­ï¼‰
        - 5æ—¥ç§»åŠ¨å¹³å‡ï¼š{premium_rate.rolling(5).mean().iloc[-1]:.4%}
        
        2. **iopvç¨³å®šæ€§**ï¼š{stability_status}
        - å½“å‰ç¨³å®šæ€§ï¼š{latest['iopv_stability']:.2f}
        - ç›¸å¯¹å¸‚åœºä½ç½®ï¼š{'ä¼˜äº' if stability_relative and stability_relative > 0 else 'åŠ£äº' if stability_relative and stability_relative < 0 else 'æ¥è¿‘'}å¸‚åœºå¹³å‡æ°´å¹³
        
        3. **å…³é”®åŠ¨æ€å…³ç³»**ï¼š{lead_lag_summary}
        - {'EC termå¯ä½œä¸ºæº¢ä»·å˜åŒ–çš„é¢†å…ˆæŒ‡æ ‡ï¼Œæå‰é¢„è­¦å®šä»·æ•ˆç‡å˜åŒ–'
        if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag < 0
        else 'æº¢ä»·å˜åŒ–å…ˆäºæ”¶æ•›æœºåˆ¶å˜åŒ–ï¼Œéœ€ä¼˜å…ˆå…³æ³¨æº¢ä»·èµ°åŠ¿'
        if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag > 0
        else 'EC termä¸æº¢ä»·ç‡åŒæ­¥å˜åŒ–ï¼Œæ”¶æ•›æœºåˆ¶ä¸æº¢ä»·è”åŠ¨ç´§å¯†'}
        
        ğŸ’¡ è¯†åˆ«åˆ°çš„å¸‚åœºæ¨¡å¼ï¼š
        {'âš ï¸ã€æµåŠ¨æ€§å±æœºæ¨¡å¼ã€‘ETFå¸‚åœºç»“æ„å¤±æ•ˆï¼Œå®šä»·æœºåˆ¶å´©æºƒï¼Œéœ€ç«‹å³å…³æ³¨ï¼' if liquidity_crisis else
        'âš ï¸ã€å®šä»·å¤±æ•ˆæ¨¡å¼ã€‘ETFæº¢ä»·ç‡å¼‚å¸¸ï¼Œå®šä»·æ•ˆç‡ä½ä¸‹ï¼Œéœ€è°¨æ…æŒæœ‰' if pricing_failure else
        'âœ…ã€å¥åº·ETFæ¨¡å¼ã€‘ETFå®šä»·æ•ˆç‡é«˜ï¼Œå¥—åˆ©æœºåˆ¶æœ‰æ•ˆï¼Œå¯æ”¾å¿ƒé…ç½®' if healthy_etf else
        'ğŸ”ã€æ··åˆçŠ¶æ€ã€‘ETFè¡¨ç°ä¸ç¨³å®šï¼Œéœ€å¯†åˆ‡å…³æ³¨é¢†å…ˆæŒ‡æ ‡å˜åŒ–'}
        
        ğŸ“Š é£é™©çŠ¶æ€è¯„ä¼°ï¼š
        - å¥—åˆ©æœºä¼šè¯„ä¼°ï¼š{ec_term_summary}
        - å¸‚åœºæ•ˆç‡è¯„ä¼°ï¼š{corr_summary}
        - é£é™©é¢„è­¦ä¿¡å·ï¼š{'é«˜é¢‘è§¦å‘' if etf_df['risk_alert'].sum() > n * 0.2 else 'å¶å‘è§¦å‘' if etf_df['risk_alert'].sum() > 0 else 'æœªè§¦å‘'}
        
        ğŸ¯ æ“ä½œå»ºè®®ï¼ˆåŸºäºå½“å‰æ¨¡å¼å’Œå¸‚åœºç›¸å¯¹ä½ç½®ï¼‰ï¼š
        {('ğŸ”´ã€ç´§æ€¥è¡ŒåŠ¨ã€‘æµåŠ¨æ€§å±æœºæ¨¡å¼å·²ç¡®è®¤ï¼å»ºè®®ï¼š' +
        '   - ç«‹å³åœæ­¢ä½¿ç”¨è¯¥ETFä½œä¸ºæ ¸å¿ƒé…ç½®' +
        '   - åˆ‡æ¢è‡³åŒç±»å…¶ä»–ETFæˆ–ç›´æ¥æŒæœ‰æˆåˆ†è‚¡' +
        '   - å¦‚å¿…é¡»ä½¿ç”¨ï¼Œéœ€å¤§å¹…é™ä½ä»“ä½å¹¶åŠ å¼ºç›‘æ§' if liquidity_crisis else
        'ğŸŸ¡ã€è°¨æ…æ“ä½œã€‘å®šä»·å¤±æ•ˆæ¨¡å¼ç¡®è®¤ï¼å»ºè®®ï¼š' +
        '   - é™ä½è¯¥ETFé…ç½®æ¯”ä¾‹ï¼Œä¸è¶…è¿‡æ€»ä»“ä½10%' +
        '   - å…³æ³¨æº¢ä»·ç‡æŒç»­æ€§ï¼Œè‹¥è¿ç»­3æ—¥>0.5%åˆ™å‡ä»“' +
        '   - è€ƒè™‘ä½¿ç”¨å…¶ä»–è·Ÿè¸ªåŒä¸€æŒ‡æ•°çš„ETFæ›¿ä»£' if pricing_failure else
        'ğŸŸ¢ã€ç§¯æé…ç½®ã€‘å¥åº·ETFæ¨¡å¼ç¡®è®¤ï¼å»ºè®®ï¼š' +
        '   - å¯ä½œä¸ºæ ¸å¿ƒé…ç½®ï¼Œç›®æ ‡ä»“ä½20-30%' +
        '   - åˆ©ç”¨å¥—åˆ©æœºä¼šè¿›è¡Œæ³¢æ®µæ“ä½œ' +
        '   - å®šæœŸç›‘æ§æº¢ä»·ç‡å˜åŒ–ï¼Œç¡®ä¿æ¨¡å¼æŒç»­' if healthy_etf else
        'ğŸ”µã€è§‚å¯Ÿç­‰å¾…ã€‘æ··åˆçŠ¶æ€ï¼å»ºè®®ï¼š' +
        '   - ç»´æŒä¸­æ€§ä»“ä½(10-20%)' +
        '   - è®¾ç½®é¢„è­¦çº¿ï¼šæº¢ä»·ç‡>0.7%æˆ–ç¨³å®šæ€§<0.4åˆ™å‡ä»“' +
        '   - æ¯å‘¨é‡æ–°è¯„ä¼°ETFæ•ˆç‡çŠ¶æ€')}
        
        ğŸ“Œ é£é™©æç¤ºï¼š
        - 2025å¹´12æœˆå¸‚åœºç‰¹å¾ï¼šé™æ¯å‘¨æœŸä¸­å€ºåˆ¸ETFæ˜“å‡ºç°æŠ˜ä»·ï¼Œéœ€ç‰¹åˆ«å…³æ³¨æµåŠ¨æ€§
        - æœ¬åˆ†æåŸºäºå†å²æ•°æ®ï¼Œæœªæ¥ETFç»“æ„å˜åŒ–å¯èƒ½å½±å“ç»“æœ
        - å»ºè®®æ¯å‘¨æ›´æ–°åˆ†æï¼Œå°¤å…¶å…³æ³¨é¢†å…ˆæŒ‡æ ‡å˜åŒ–
        
        ğŸ” æ·±åº¦æ´å¯Ÿï¼š
        {('EC termé¢†å…ˆæº¢ä»·ç‡å˜åŒ–çº¦' + str(-best_lag) + 'å¤©ï¼Œå¯ä½œä¸ºæ—©æœŸé¢„è­¦ä¿¡å·ã€‚'
        if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag < 0
        else 'æº¢ä»·ç‡å˜åŒ–å…ˆäºEC termå˜åŒ–çº¦' + str(best_lag) + 'å¤©ï¼Œéœ€ä¼˜å…ˆå…³æ³¨æº¢ä»·èµ°åŠ¿ã€‚'
        if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag > 0
        else 'EC termä¸æº¢ä»·ç‡åŒæ­¥å˜åŒ–ï¼Œéœ€åŒæ—¶ç›‘æ§ä¸¤ç±»æŒ‡æ ‡ã€‚')}
        å½“é£é™©é¢„è­¦ä¿¡å·è§¦å‘åï¼Œæœªæ¥{int(abs(best_lag)) + 3 if best_lag else '5'}å¤©å†…å®é™…è·Ÿè¸ªæˆæœ¬å¹³å‡ä¸Šå‡{abs(best_corr) * 100:.0f}%ã€‚
        
        ğŸ’¡ ç‰¹åˆ«æç¤ºï¼š
        è¯¥ETFå½“å‰è¡¨ç°{('æ˜¾è‘—ä¼˜äº' if premium_relative and premium_relative > 0.5 and stability_relative and stability_relative > 0.5 else
        'ä¼˜äº' if premium_relative and premium_relative > 0.3 and stability_relative and stability_relative > 0.3 else
        'æ˜¾è‘—åŠ£äº' if premium_relative and premium_relative < -0.5 and stability_relative and stability_relative < -0.5 else
        'ä¸')}åŒç±»ETFæ•´ä½“æ°´å¹³ï¼Œ{('å»ºè®®' if (premium_relative and premium_relative > 0.3 and stability_relative and stability_relative > 0.3) or (premium_relative and premium_relative < -0.3 and stability_relative and stability_relative > 0.3) else 'è°¨æ…')}{'å¢æŒ' if premium_relative and premium_relative > 0.5 and stability_relative and stability_relative > 0.5 else 'æŒæœ‰' if premium_relative and abs(premium_relative) < 0.3 and stability_relative and stability_relative > -0.3 else 'å‡æŒ' if premium_relative and premium_relative < -0.5 or stability_relative and stability_relative < -0.5 else 'è§‚å¯Ÿ'}
        """.strip()

        return summary

    def _analyze_index(self, start_date:int, end_date:int, order_book_id_list: list = None):
        """
        å¯¹æŒ‡æ•°æ—¥çº¿æ•°æ®è¿›è¡Œæ·±åº¦åˆ†æï¼ŒåŸºäºä»·æ ¼èŒƒå›´åæ¨éšå«æ³¢åŠ¨ç‡æ›²é¢
        """
        index_features_list = ['open', 'close', 'high', 'low', 'prev_close']
        df = self.ricequant_service.instruments_data_fetching(type='INDX', start_date=start_date, end_date=end_date, features_list=index_features_list, order_book_id_list=order_book_id_list)

        # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®å¹¶æ’åº
        df['date'] = pd.to_datetime(df['date'], format='%Y/%m/%d')
        df = df.sort_values(['order_book_id', 'date']).reset_index(drop=True)

        # 2. åŸºç¡€æŒ‡æ ‡è®¡ç®—
        # ä»·æ ¼èŒƒå›´
        price_range = (df['high'] - df['low']).replace(0, np.nan)

        # å·¦åé£é™© (è¡¡é‡ä¸‹è·Œå°¾éƒ¨é£é™©)
        df['left_skew_risk'] = np.where(
            price_range.notna(),
            (df['prev_close'] - df['low']) / price_range,
            np.nan
        )

        # æ›²é¢æ›²ç‡ (è¡¡é‡æ³¢åŠ¨ç‡å¾®ç¬‘å½¢çŠ¶)
        df['surface_curvature'] = np.where(
            ((df['close'] - df['low']) > 0) & price_range.notna(),
            (df['high'] - df['close']) / (df['close'] - df['low']) - 1,
            np.nan
        )

        # æŒ‡æ•°è·³è·ƒå¼ºåº¦ (å¼€ç›˜è·³ç©ºç¨‹åº¦)
        df['jump_intensity'] = np.where(
            price_range.notna(),
            np.abs(df['close'] - df['open']) / price_range,
            np.nan
        )

        # æ—¥æ”¶ç›Šç‡
        df['daily_return'] = df['close'] / df['prev_close'] - 1

        # å·²å®ç°æ³¢åŠ¨ç‡ (åŸºäºä»·æ ¼èŒƒå›´)
        df['realized_vol'] = np.where(
            df['prev_close'] > 0,
            price_range / df['prev_close'],
            np.nan
        )

        # 3. éšå«ååº¦ä¼°è®¡ (ç®€åŒ–ç‰ˆ)
        # åŸç†ï¼šå·¦åé£é™©ä¸æ›²é¢æ›²ç‡çš„ç»„åˆå¯ä»¥ä»£ç†éšå«ååº¦
        df['implied_skew'] = np.nan

        # ä»…å½“æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®æ—¶è®¡ç®—
        for i in range(10, len(df)):
            # ä½¿ç”¨10æ—¥çª—å£è®¡ç®—åŠ¨æ€éšå«ååº¦
            left_skew_window = df['left_skew_risk'].iloc[i - 9:i + 1]
            surface_curv_window = df['surface_curvature'].iloc[i - 9:i + 1]

            if len(left_skew_window.dropna()) > 5 and len(surface_curv_window.dropna()) > 5:
                # ç»¼åˆå·¦åé£é™©å’Œæ›²é¢æ›²ç‡ï¼Œæ ‡å‡†åŒ–åç»„åˆ
                skew_risk_std = (left_skew_window - left_skew_window.mean()) / (left_skew_window.std() + 1e-5)
                curv_std = (surface_curv_window - surface_curv_window.mean()) / (surface_curv_window.std() + 1e-5)

                # ç»„åˆæŒ‡æ ‡ï¼ˆæƒé‡å¯æ ¹æ®å›æµ‹è°ƒæ•´ï¼‰
                combined_skew = 0.7 * skew_risk_std + 0.3 * curv_std
                df.iloc[i, df.columns.get_loc('implied_skew')] = combined_skew.mean()

        # 4. æ³¢åŠ¨ç‡æœŸé™ç»“æ„åˆ†æ
        # çŸ­æœŸæ³¢åŠ¨ç‡ (5æ—¥)
        df['short_term_vol'] = df['realized_vol'].rolling(5, min_periods=3).mean()

        # é•¿æœŸæ³¢åŠ¨ç‡ (20æ—¥)
        df['long_term_vol'] = df['realized_vol'].rolling(20, min_periods=10).mean()

        # æ³¢åŠ¨ç‡æœŸé™ç»“æ„æ–œç‡
        df['vol_term_structure'] = df['short_term_vol'] / (df['long_term_vol'] + 1e-5)

        # 5. å°¾éƒ¨é£é™©é¢„è­¦ä¿¡å·
        df['tail_risk_alert'] = False

        # æ¡ä»¶1ï¼šå·¦åé£é™©æŒç»­5æ—¥ > 0.5
        high_left_skew = (df['left_skew_risk'] > 0.5)
        df['left_skew_streak'] = high_left_skew.astype(int).groupby((~high_left_skew).cumsum()).cumsum()

        # æ¡ä»¶2ï¼šæ›²é¢æ›²ç‡ > 0.2
        high_curvature = (df['surface_curvature'] > 0.2)

        # é£é™©é¢„è­¦ï¼šæ»¡è¶³ä¸¤ä¸ªæ¡ä»¶
        df['tail_risk_alert'] = (df['left_skew_streak'] >= 5) & high_curvature

        # 6. å†å¹³è¡¡æ•ˆåº”æ£€æµ‹
        df['rebalance_signal'] = False

        # å¼€ç›˜è·³ç©º + ç‰¹å®šæ—¥æœŸï¼ˆå¯æ ¹æ®æ—¥å†äº‹ä»¶è°ƒæ•´ï¼‰
        df['rebalance_signal'] = (df['jump_intensity'] > 0.8) & (df['date'].dt.day.isin([1, 15]))

        # 7. æ„å»ºç»“æœå­—å…¸
        results = []
        for _, row in df.iterrows():
            result = {
                "date": row['date'].strftime('%Y-%m-%d'),
                "order_book_id": row['order_book_id'],
                "left_skew_risk": float(row['left_skew_risk']) if not pd.isna(row['left_skew_risk']) else None,
                "surface_curvature": float(row['surface_curvature']) if not pd.isna(row['surface_curvature']) else None,
                "jump_intensity": float(row['jump_intensity']) if not pd.isna(row['jump_intensity']) else None,
                "daily_return": float(row['daily_return']) if not pd.isna(row['daily_return']) else None,
                "realized_vol": float(row['realized_vol']) if not pd.isna(row['realized_vol']) else None,
                "implied_skew": float(row['implied_skew']) if not pd.isna(row['implied_skew']) else None,
                "short_term_vol": float(row['short_term_vol']) if not pd.isna(row['short_term_vol']) else None,
                "long_term_vol": float(row['long_term_vol']) if not pd.isna(row['long_term_vol']) else None,
                "vol_term_structure": float(row['vol_term_structure']) if not pd.isna(
                    row['vol_term_structure']) else None,
                "tail_risk_alert": bool(row['tail_risk_alert']),
                "rebalance_signal": bool(row['rebalance_signal'])
            }
            results.append(result)

        return results

    def summarize_INDXanalysis(self, start_date: int, end_date: int, target_index_id=None,
                                index_id_list: list = None, lookback_days=30, confidence_level=0.95):
        # 1. è·å–æŒ‡æ•°åˆ†æç»“æœ
        analysis_results = self._analyze_index(start_date, end_date, index_id_list)
        if not analysis_results:
            return "æ— æŒ‡æ•°æ•°æ®å¯ä¾›åˆ†æã€‚"

            # è½¬æ¢ä¸ºDataFrameå¹¶é¢„å¤„ç†
        df = pd.DataFrame(analysis_results)

        # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
        if not pd.api.types.is_datetime64_any_dtype(df['date']):
            df['date'] = pd.to_datetime(df['date'])

        # æŒ‰æŒ‡æ•°ä»£ç å’Œæ—¥æœŸæ’åº
        df = df.sort_values(['order_book_id', 'date']).reset_index(drop=True)

        # ======================
        # 2. ç¡®å®šç›®æ ‡æŒ‡æ•°å¹¶è®¡ç®—å¸‚åœºåŸºå‡†
        # ======================

        # ç¡®å®šè¦åˆ†æçš„ç›®æ ‡æŒ‡æ•°
        if target_index_id:
            if target_index_id not in df['order_book_id'].unique():
                return f"æœªæ‰¾åˆ°æŒ‡æ•° {target_index_id} çš„æ•°æ®ã€‚"
        else:
            # è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªæŒ‡æ•°
            target_index_id = df['order_book_id'].iloc[0]

        # è·å–æœ€æ–°æ—¥æœŸï¼ˆç”¨äºå¸‚åœºåŸºå‡†è®¡ç®—ï¼‰
        latest_date = df['date'].max()

        # è·å–æ‰€æœ‰æŒ‡æ•°åœ¨æœ€æ–°æ—¥æœŸçš„æ•°æ®ï¼ˆç”¨äºè®¡ç®—å¸‚åœºåŸºå‡†ï¼‰
        market_df = df[df['date'] == latest_date].copy()

        # è®¡ç®—å¸‚åœºåŸºå‡†ï¼ˆæ’é™¤ç›®æ ‡æŒ‡æ•°è‡ªèº«ï¼Œé¿å…è‡ªç›¸å…³ï¼‰
        market_benchmarks = {}
        if len(market_df) > 1:  # è‡³å°‘æœ‰2åªæŒ‡æ•°æ‰èƒ½è®¡ç®—æœ‰æ„ä¹‰çš„åŸºå‡†
            market_without_target = market_df[market_df['order_book_id'] != target_index_id]
            if not market_without_target.empty:
                # åªæœ‰å½“æœ‰æ•ˆæ•°æ®å­˜åœ¨æ—¶æ‰è®¡ç®—åŸºå‡†
                valid_skew = market_without_target['implied_skew'].dropna()
                valid_vol_term = market_without_target['vol_term_structure'].dropna()

                market_benchmarks = {
                    'skew_mean': valid_skew.mean() if not valid_skew.empty else None,
                    'skew_25pct': valid_skew.quantile(0.25) if not valid_skew.empty else None,
                    'skew_75pct': valid_skew.quantile(0.75) if not valid_skew.empty else None,
                    'vol_term_mean': valid_vol_term.mean() if not valid_vol_term.empty else None,
                    'vol_term_25pct': valid_vol_term.quantile(0.25) if not valid_vol_term.empty else None,
                    'vol_term_75pct': valid_vol_term.quantile(0.75) if not valid_vol_term.empty else None,
                    'left_skew_mean': market_without_target['left_skew_risk'].mean()
                }

        # é€‰æ‹©ç›®æ ‡æŒ‡æ•°çš„æ—¶é—´åºåˆ—æ•°æ®
        index_df = df[df['order_book_id'] == target_index_id].copy()

        # é™åˆ¶åˆ†æçª—å£
        if len(index_df) > lookback_days:
            index_df = index_df.tail(lookback_days).reset_index(drop=True)

        n = len(index_df)
        if n < 10:  # éœ€è¦è¶³å¤Ÿæ•°æ®è¿›è¡Œè¶‹åŠ¿åˆ†æ
            return f"æŒ‡æ•° {target_index_id} æ•°æ®ç‚¹ä¸è¶³ï¼ˆ{n}å¤©ï¼‰ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆè¶‹åŠ¿åˆ†æã€‚"

        # è·å–æœ€æ–°æ•°æ®ç‚¹
        latest = index_df.iloc[-1]

        # ======================
        # 3. æ·±åº¦æ—¶é—´åºåˆ—è¶‹åŠ¿åˆ†æ
        # ======================

        # --- 3.1 å·¦åé£é™©è¶‹åŠ¿ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰---
        left_skew = index_df['left_skew_risk'].astype(float).dropna()

        # è®¡ç®—çº¿æ€§è¶‹åŠ¿æ–œç‡å’Œæ˜¾è‘—æ€§
        trend_desc = "å·¦åé£é™©è¶‹åŠ¿åˆ†æå¤±è´¥ï¼Œæ•°æ®å¯èƒ½å­˜åœ¨é—®é¢˜"
        if len(left_skew) >= 10:
            x = np.arange(len(left_skew))
            try:
                slope_skew, intercept_skew, r_skew, p_skew, std_err_skew = stats.linregress(x, left_skew)
                trend_strength = abs(slope_skew) * len(left_skew) / (left_skew.mean() + 1e-5)

                # è¶‹åŠ¿åˆ†ç±»
                if p_skew < (1 - confidence_level):
                    if slope_skew > 0:
                        if trend_strength > 0.5:
                            trend_desc = "æ˜¾è‘—ä¸Šå‡è¶‹åŠ¿ï¼Œå°¾éƒ¨ä¸‹è·Œé£é™©å¿«é€Ÿç´¯ç§¯"
                        elif trend_strength > 0.2:
                            trend_desc = "æ¸©å’Œä¸Šå‡è¶‹åŠ¿ï¼Œå°¾éƒ¨ä¸‹è·Œé£é™©é€æ­¥å¢åŠ "
                        else:
                            trend_desc = "è½»å¾®ä¸Šå‡è¶‹åŠ¿ï¼Œå°¾éƒ¨é£é™©ç¼“æ…¢ä¸Šå‡"
                    else:
                        if trend_strength > 0.5:
                            trend_desc = "æ˜¾è‘—ä¸‹é™è¶‹åŠ¿ï¼Œå°¾éƒ¨ä¸‹è·Œé£é™©å¿«é€Ÿæ¶ˆé€€"
                        elif trend_strength > 0.2:
                            trend_desc = "æ¸©å’Œä¸‹é™è¶‹åŠ¿ï¼Œå°¾éƒ¨ä¸‹è·Œé£é™©é€æ­¥é™ä½"
                        else:
                            trend_desc = "è½»å¾®ä¸‹é™è¶‹åŠ¿ï¼Œå°¾éƒ¨é£é™©ç¼“æ…¢é™ä½"

                    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                    trend_desc += f"ï¼ˆæ–œç‡={slope_skew:.2f}, p={p_skew:.3f}ï¼‰"
                else:
                    trend_desc = "æ— æ˜¾è‘—è¶‹åŠ¿ï¼Œå°¾éƒ¨é£é™©éšæœºæ³¢åŠ¨"
            except Exception as e:
                pass

        # --- 3.2 æ›²é¢æ›²ç‡è¶‹åŠ¿ ---
        surface_curv = index_df['surface_curvature'].astype(float).dropna()

        curv_status = ""
        if len(surface_curv) > 0:
            current_curv = surface_curv.iloc[-1]
            if current_curv > 0.2:
                curv_status = f"æ³¢åŠ¨ç‡å¾®ç¬‘å³åï¼ˆå½“å‰å€¼={current_curv:.2f}ï¼‰ï¼Œå¸‚åœºææ…Œæƒ…ç»ªæµ“åš"
            elif current_curv < -0.2:
                curv_status = f"æ³¢åŠ¨ç‡å¾®ç¬‘å·¦åï¼ˆå½“å‰å€¼={current_curv:.2f}ï¼‰ï¼Œå¸‚åœºç‹‚çƒ­æƒ…ç»ªæµ“åš"
            else:
                curv_status = f"æ³¢åŠ¨ç‡å¾®ç¬‘æ¥è¿‘å¯¹ç§°ï¼ˆå½“å‰å€¼={current_curv:.2f}ï¼‰ï¼Œå¸‚åœºæƒ…ç»ªå¹³è¡¡"
        else:
            curv_status = "æ³¢åŠ¨ç‡æ›²é¢æ•°æ®ä¸è¶³"

        # --- 3.3 éšå«ååº¦è¶‹åŠ¿ ---
        implied_skew = index_df['implied_skew'].dropna()
        skew_summary = "éšå«ååº¦æ•°æ®ä¸è¶³"

        if len(implied_skew) >= 15:
            # è®¡ç®—éšå«ååº¦è¶‹åŠ¿
            x_skew = np.arange(len(implied_skew))
            try:
                slope_skew, _, _, p_skew, _ = stats.linregress(x_skew, implied_skew)

                if p_skew < (1 - confidence_level) and slope_skew < -0.1:
                    skew_summary = f"éšå«ååº¦å‘ˆæ˜¾è‘—ä¸‹é™è¶‹åŠ¿ï¼ˆæ–œç‡={slope_skew:.2f}, p={p_skew:.3f}ï¼‰ï¼Œå°¾éƒ¨ä¸‹è·Œé£é™©æŒç»­ä¸Šå‡"
                elif p_skew < (1 - confidence_level) and slope_skew > 0.1:
                    skew_summary = f"éšå«ååº¦å‘ˆæ˜¾è‘—ä¸Šå‡è¶‹åŠ¿ï¼ˆæ–œç‡={slope_skew:.2f}, p={p_skew:.3f}ï¼‰ï¼Œå°¾éƒ¨ä¸‹è·Œé£é™©æŒç»­ä¸‹é™"
                else:
                    skew_summary = f"éšå«ååº¦æ³¢åŠ¨ä½†æ— æ˜¾è‘—è¶‹åŠ¿ï¼ˆp={p_skew:.3f}ï¼‰ï¼Œå°¾éƒ¨é£é™©ä¿æŒç¨³å®š"
            except Exception as e:
                pass

        # --- 3.4 æ³¢åŠ¨ç‡æœŸé™ç»“æ„åˆ†æ ---
        vol_term = index_df['vol_term_structure'].dropna()
        vol_term_summary = "æ³¢åŠ¨ç‡æœŸé™ç»“æ„æ•°æ®ä¸è¶³"

        if len(vol_term) >= 10:
            current_vol_term = vol_term.iloc[-1]
            if current_vol_term > 1.2:
                vol_term_summary = f"æ³¢åŠ¨ç‡æœŸé™ç»“æ„é™¡å³­ï¼ˆå½“å‰å€¼={current_vol_term:.2f}ï¼‰ï¼ŒçŸ­æœŸæ³¢åŠ¨ç‡æ˜¾è‘—é«˜äºé•¿æœŸ"
            elif current_vol_term < 0.8:
                vol_term_summary = f"æ³¢åŠ¨ç‡æœŸé™ç»“æ„å¹³å¦ç”šè‡³å€’æŒ‚ï¼ˆå½“å‰å€¼={current_vol_term:.2f}ï¼‰ï¼Œå¸‚åœºé¢„æœŸæ³¢åŠ¨ç‡ä¸‹é™"
            else:
                vol_term_summary = f"æ³¢åŠ¨ç‡æœŸé™ç»“æ„æ­£å¸¸ï¼ˆå½“å‰å€¼={current_vol_term:.2f}ï¼‰ï¼ŒçŸ­æœŸä¸é•¿æœŸæ³¢åŠ¨ç‡å‡è¡¡"
        else:
            vol_term_summary = "æ³¢åŠ¨ç‡æœŸé™ç»“æ„æ•°æ®ä¸è¶³"

        # --- 3.5 å°¾éƒ¨é£é™©åŠ¨æ€æ¨¡å¼ ---
        tail_risk_alerts = index_df['tail_risk_alert'].sum()
        tail_risk_summary = ""

        if tail_risk_alerts > n * 0.3:
            tail_risk_summary = f"å°¾éƒ¨é£é™©é«˜é¢‘è§¦å‘ï¼ˆ{tail_risk_alerts}æ¬¡ï¼Œ{tail_risk_alerts / n:.0%}å¤©ï¼‰ï¼Œå¸‚åœºè„†å¼±æ€§æé«˜"
        elif tail_risk_alerts > 0:
            tail_risk_summary = f"å¶å‘å°¾éƒ¨é£é™©é¢„è­¦ï¼ˆ{tail_risk_alerts}æ¬¡ï¼‰ï¼Œéœ€è­¦æƒ•å¸‚åœºè½¬æŠ˜"
        else:
            tail_risk_summary = "æœªæ£€æµ‹åˆ°å°¾éƒ¨é£é™©ä¿¡å·ï¼Œå¸‚åœºç»“æ„ç›¸å¯¹ç¨³å¥"

        # --- 3.6 å†å¹³è¡¡æ•ˆåº”åˆ†æ ---
        rebalance_signals = index_df['rebalance_signal'].sum()
        rebalance_summary = ""

        if rebalance_signals > n * 0.1:
            rebalance_summary = f"é«˜é¢‘å†å¹³è¡¡ä¿¡å·ï¼ˆ{rebalance_signals}æ¬¡ï¼‰ï¼ŒæŒ‡æ•°è°ƒä»“æ•ˆåº”æ˜¾è‘—"
        elif rebalance_signals > 0:
            rebalance_summary = f"å¶å‘å†å¹³è¡¡ä¿¡å·ï¼ˆ{rebalance_signals}æ¬¡ï¼‰ï¼Œç‰¹å®šæ—¥æœŸå­˜åœ¨è·³ç©ºé£é™©"
        else:
            rebalance_summary = "æœªæ£€æµ‹åˆ°æ˜æ˜¾å†å¹³è¡¡æ•ˆåº”"

        # --- 3.7 é¢†å…ˆ-æ»åå…³ç³»åˆ†æ ---
        lead_lag_results = []
        best_lag = None
        best_corr = 0.0
        if len(left_skew) >= 20 and len(implied_skew) >= 20:
            for lag in range(-7, 8):  # -7åˆ°+7å¤©çš„æ»å
                try:
                    if lag <= 0:
                        corr = left_skew[:lag].corr(implied_skew[-lag:]) if lag != 0 else left_skew.corr(implied_skew)
                    else:
                        corr = left_skew[lag:].corr(implied_skew[:-lag])
                    lead_lag_results.append((lag, corr))
                except:
                    continue

            if lead_lag_results:
                best_lag, best_corr = max(lead_lag_results, key=lambda x: abs(x[1]))
                if abs(best_corr) > 0.4:
                    if best_lag < 0:
                        lead_lag_summary = f"å·¦åé£é™©é¢†å…ˆéšå«ååº¦çº¦{-best_lag}å¤©ï¼ˆæœ€å¤§ç›¸å…³ç³»æ•°={best_corr:.2f}ï¼‰ï¼Œæ˜¯å°¾éƒ¨é£é™©çš„å…ˆè¡ŒæŒ‡æ ‡"
                    elif best_lag > 0:
                        lead_lag_summary = f"éšå«ååº¦é¢†å…ˆå·¦åé£é™©çº¦{best_lag}å¤©ï¼ˆæœ€å¤§ç›¸å…³ç³»æ•°={best_corr:.2f}ï¼‰ï¼Œæƒ…ç»ªå˜åŒ–å…ˆäºä»·æ ¼è¡¨ç°"
                    else:
                        lead_lag_summary = f"å·¦åé£é™©ä¸éšå«ååº¦åŒæ­¥å˜åŒ–ï¼ˆç›¸å…³ç³»æ•°={best_corr:.2f}ï¼‰ï¼Œé£é™©ä¸æƒ…ç»ªç›¸äº’å¼ºåŒ–"
                else:
                    lead_lag_summary = "å·¦åé£é™©ä¸éšå«ååº¦å…³ç³»ä¸ç¨³å®šï¼Œæ— æ˜æ˜¾é¢†å…ˆ-æ»åæ¨¡å¼"
            else:
                lead_lag_summary = "æ— æ³•è®¡ç®—é¢†å…ˆ-æ»åå…³ç³»ï¼Œç›¸å…³ç³»æ•°è®¡ç®—å¤±è´¥"
        else:
            lead_lag_summary = "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œé¢†å…ˆ-æ»ååˆ†æ"

        # ======================
        # 4. è¯†åˆ«å…³é”®åŠ¨æ€æ¨¡å¼
        # ======================

        # æ¨¡å¼1: å°¾éƒ¨é£é™©æ¨¡å¼
        tail_risk_mode = (
                "æ˜¾è‘—ä¸Šå‡è¶‹åŠ¿" in trend_desc and
                "å³å" in curv_status and
                "ä¸‹é™è¶‹åŠ¿" in skew_summary and
                tail_risk_alerts > n * 0.2
        )

        # æ¨¡å¼2: å¸‚åœºç‹‚çƒ­æ¨¡å¼
        market_frenzy = (
                "æ˜¾è‘—ä¸‹é™è¶‹åŠ¿" in trend_desc and
                "å·¦å" in curv_status and
                "ä¸Šå‡è¶‹åŠ¿" in skew_summary
        )

        # æ¨¡å¼3: å¸‚åœºå‡è¡¡æ¨¡å¼
        market_equilibrium = (
                "æ— æ˜¾è‘—è¶‹åŠ¿" in trend_desc and
                "æ¥è¿‘å¯¹ç§°" in curv_status and
                "æ³¢åŠ¨ä½†æ— æ˜¾è‘—è¶‹åŠ¿" in skew_summary and
                tail_risk_alerts == 0
        )

        # ======================
        # 5. ç›¸å¯¹å¸‚åœºå®šä½åˆ†æ
        # ======================

        # åˆå§‹åŒ–ç›¸å¯¹ä½ç½®å˜é‡
        skew_relative_desc = "æ— å¸‚åœºæ¯”è¾ƒæ•°æ®"
        vol_term_relative_desc = "æ— å¸‚åœºæ¯”è¾ƒæ•°æ®"

        skew_relative = None
        vol_term_relative = None

        # 1. éšå«ååº¦ç›¸å¯¹ä½ç½®
        if ('skew_mean' in market_benchmarks and
                market_benchmarks['skew_mean'] is not None and
                not pd.isna(latest['implied_skew']) and
                market_benchmarks['skew_75pct'] is not None and
                market_benchmarks['skew_25pct'] is not None):

            iqr = market_benchmarks['skew_75pct'] - market_benchmarks['skew_25pct']
            if iqr > 1e-5:
                skew_relative = (
                        (latest['implied_skew'] - market_benchmarks['skew_mean']) /
                        (iqr + 1e-5)
                )
                if skew_relative < -1.0:
                    skew_relative_desc = "éšå«ååº¦æ˜¾è‘—ä½äºåŒç±»æŒ‡æ•°ï¼Œå°¾éƒ¨ä¸‹è·Œé£é™©æé«˜"
                elif skew_relative < -0.5:
                    skew_relative_desc = "éšå«ååº¦ä½äºåŒç±»æŒ‡æ•°ï¼Œå°¾éƒ¨ä¸‹è·Œé£é™©è¾ƒé«˜"
                elif skew_relative > 1.0:
                    skew_relative_desc = "éšå«ååº¦æ˜¾è‘—é«˜äºåŒç±»æŒ‡æ•°ï¼Œå¸‚åœºæƒ…ç»ªä¹è§‚"
                elif skew_relative > 0.5:
                    skew_relative_desc = "éšå«ååº¦é«˜äºåŒç±»æŒ‡æ•°ï¼Œå¸‚åœºæƒ…ç»ªè¾ƒä¸ºä¹è§‚"
                else:
                    skew_relative_desc = "éšå«ååº¦å¤„äºåŒç±»æŒ‡æ•°æ­£å¸¸æ°´å¹³"
            else:
                skew_relative_desc = "éšå«ååº¦å¸‚åœºåŸºå‡†æ•°æ®ä¸è¶³"
        else:
            skew_relative_desc = "éšå«ååº¦å¸‚åœºåŸºå‡†æ•°æ®ä¸è¶³"

        # 2. æ³¢åŠ¨ç‡æœŸé™ç»“æ„ç›¸å¯¹ä½ç½®
        if ('vol_term_mean' in market_benchmarks and
                market_benchmarks['vol_term_mean'] is not None and
                not pd.isna(latest['vol_term_structure']) and
                market_benchmarks['vol_term_75pct'] is not None and
                market_benchmarks['vol_term_25pct'] is not None):

            iqr = market_benchmarks['vol_term_75pct'] - market_benchmarks['vol_term_25pct']
            if iqr > 1e-5:
                vol_term_relative = (
                        (latest['vol_term_structure'] - market_benchmarks['vol_term_mean']) /
                        (iqr + 1e-5)
                )
                if vol_term_relative > 1.0:
                    vol_term_relative_desc = "æ³¢åŠ¨ç‡æœŸé™ç»“æ„æ˜¾è‘—é™¡å³­ï¼ŒçŸ­æœŸæ³¢åŠ¨é£é™©çªå‡º"
                elif vol_term_relative > 0.5:
                    vol_term_relative_desc = "æ³¢åŠ¨ç‡æœŸé™ç»“æ„è¾ƒä¸ºé™¡å³­"
                elif vol_term_relative < -1.0:
                    vol_term_relative_desc = "æ³¢åŠ¨ç‡æœŸé™ç»“æ„æ˜¾è‘—å¹³å¦ï¼Œå¸‚åœºé¢„æœŸç¨³å®š"
                elif vol_term_relative < -0.5:
                    vol_term_relative_desc = "æ³¢åŠ¨ç‡æœŸé™ç»“æ„è¾ƒä¸ºå¹³å¦"
                else:
                    vol_term_relative_desc = "æ³¢åŠ¨ç‡æœŸé™ç»“æ„å¤„äºåŒç±»æŒ‡æ•°æ­£å¸¸æ°´å¹³"
            else:
                vol_term_relative_desc = "æ³¢åŠ¨ç‡æœŸé™ç»“æ„å¸‚åœºåŸºå‡†æ•°æ®ä¸è¶³"
        else:
            vol_term_relative_desc = "æ³¢åŠ¨ç‡æœŸé™ç»“æ„å¸‚åœºåŸºå‡†æ•°æ®ä¸è¶³"

        # ======================
        # 6. ç»¼åˆæ€»ç»“è¾“å‡º
        # ======================
        summary = f"""
            ã€{target_index_id} æŒ‡æ•°æ·±åº¦è¶‹åŠ¿åˆ†ææŠ¥å‘Šã€‘ï¼ˆæˆªè‡³ {index_df['date'].max().strftime('%Y-%m-%d')}ï¼‰
            
            ğŸŒ å¸‚åœºç›¸å¯¹å®šä½ï¼ˆåŸºäº{len(market_df)}åªæŒ‡æ•°æœ€æ–°æ•°æ®ï¼‰ï¼š
            - éšå«ååº¦æ°´å¹³ï¼š{skew_relative_desc}
            - æ³¢åŠ¨ç‡æœŸé™ç»“æ„ï¼š{vol_term_relative_desc}
            
            ğŸ” æ ¸å¿ƒè¶‹åŠ¿è¯Šæ–­ï¼ˆåŸºäº{len(index_df)}å¤©æ•°æ®ï¼‰ï¼š
            1. **å·¦åé£é™©è¶‹åŠ¿**ï¼š{trend_desc}
            - å½“å‰å·¦åé£é™©ï¼š{latest['left_skew_risk']:.2f}
            - ç›¸å¯¹å¸‚åœºä½ç½®ï¼š{'é«˜äº' if skew_relative and skew_relative < 0 else 'ä½äº' if skew_relative and skew_relative > 0 else 'æ¥è¿‘'}å¸‚åœºä¸­ä½æ•°ï¼ˆå€¼è¶Šå°è¡¨ç¤ºå°¾éƒ¨é£é™©è¶Šé«˜ï¼‰
            - 5æ—¥ç§»åŠ¨å¹³å‡ï¼š{left_skew.rolling(5).mean().iloc[-1]:.2f}
            
            2. **æ³¢åŠ¨ç‡æ›²é¢åˆ†æ**ï¼š{curv_status}
            - å½“å‰æ›²é¢æ›²ç‡ï¼š{latest['surface_curvature']:.2f}
            
            3. **éšå«ååº¦åˆ†æ**ï¼š{skew_summary}
            - å½“å‰éšå«ååº¦ï¼š{latest['implied_skew']:.2f}
            - ç›¸å¯¹å¸‚åœºä½ç½®ï¼š{'æ›´è´Ÿ' if skew_relative and skew_relative < 0 else 'æ›´æ­£' if skew_relative and skew_relative > 0 else 'æ¥è¿‘'}å¸‚åœºå¹³å‡æ°´å¹³
            
            4. **æ³¢åŠ¨ç‡æœŸé™ç»“æ„**ï¼š{vol_term_summary}
            - å½“å‰æœŸé™ç»“æ„æ–œç‡ï¼š{latest['vol_term_structure']:.2f}
            - ç›¸å¯¹å¸‚åœºä½ç½®ï¼š{'æ›´é™¡å³­' if vol_term_relative and vol_term_relative > 0 else 'æ›´å¹³å¦' if vol_term_relative and vol_term_relative < 0 else 'æ¥è¿‘'}å¸‚åœºå¹³å‡æ°´å¹³
            
            5. **å…³é”®åŠ¨æ€å…³ç³»**ï¼š{lead_lag_summary}
            - {'å·¦åé£é™©å¯ä½œä¸ºå°¾éƒ¨é£é™©çš„é¢†å…ˆæŒ‡æ ‡ï¼Œæå‰é¢„è­¦å¸‚åœºå‹åŠ›'
            if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag < 0
            else 'éšå«ååº¦å˜åŒ–å…ˆäºå·¦åé£é™©ï¼Œéœ€ä¼˜å…ˆå…³æ³¨æƒ…ç»ªæŒ‡æ ‡'
            if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag > 0
            else 'å·¦åé£é™©ä¸éšå«ååº¦åŒæ­¥å˜åŒ–ï¼Œéœ€åŒæ—¶ç›‘æ§'}
            
            ğŸ’¡ è¯†åˆ«åˆ°çš„å¸‚åœºæ¨¡å¼ï¼š
            {'âš ï¸ã€å°¾éƒ¨é£é™©æ¨¡å¼ã€‘å·¦åé£é™©ä¸Šå‡ã€æ³¢åŠ¨ç‡å¾®ç¬‘å³åï¼Œå¸‚åœºè„†å¼±æ€§æé«˜ï¼' if tail_risk_mode else
            'âš ï¸ã€å¸‚åœºç‹‚çƒ­æ¨¡å¼ã€‘å·¦åé£é™©ä¸‹é™ã€æ³¢åŠ¨ç‡å¾®ç¬‘å·¦åï¼Œè­¦æƒ•æ³¡æ²«é£é™©ï¼' if market_frenzy else
            'âœ…ã€å¸‚åœºå‡è¡¡æ¨¡å¼ã€‘é£é™©æŒ‡æ ‡ç¨³å®šï¼Œå¸‚åœºç»“æ„å¥åº·' if market_equilibrium else
            'ğŸ”ã€æ··åˆçŠ¶æ€ã€‘å¸‚åœºå¤„äºè¿‡æ¸¡æœŸï¼Œéœ€å¯†åˆ‡å…³æ³¨é¢†å…ˆæŒ‡æ ‡å˜åŒ–'}
            
            ğŸ“Š é£é™©çŠ¶æ€è¯„ä¼°ï¼š
            - å°¾éƒ¨é£é™©é¢„è­¦ï¼š{tail_risk_summary}
            - å†å¹³è¡¡æ•ˆåº”ï¼š{rebalance_summary}
            - æ³¢åŠ¨ç‡ç»“æ„ï¼š{vol_term_summary}
            
            ğŸ¯ æ“ä½œå»ºè®®ï¼ˆåŸºäºå½“å‰æ¨¡å¼å’Œå¸‚åœºç›¸å¯¹ä½ç½®ï¼‰ï¼š
            {('ğŸ”´ã€ç´§æ€¥è¡ŒåŠ¨ã€‘å°¾éƒ¨é£é™©æ¨¡å¼å·²ç¡®è®¤ï¼å»ºè®®ï¼š' +
            '   - ç«‹å³ä¹°å…¥è™šå€¼PutæœŸæƒå¯¹å†²å°¾éƒ¨é£é™©' +
            '   - å‡å°‘é«˜betaèµ„äº§é…ç½®ï¼Œå¢åŠ é˜²å¾¡æ€§èµ„äº§' +
            '   - å¯†åˆ‡ç›‘æ§å·¦åé£é™©æŒ‡æ ‡ï¼Œè‹¥æŒç»­ä¸Šå‡åˆ™è¿›ä¸€æ­¥å¯¹å†²' if tail_risk_mode else
            'ğŸŸ¡ã€è°¨æ…æ“ä½œã€‘å¸‚åœºç‹‚çƒ­æ¨¡å¼ç¡®è®¤ï¼å»ºè®®ï¼š' +
            '   - é€‚å½“é™ä½é£é™©æ•å£ï¼Œé”å®šéƒ¨åˆ†æ”¶ç›Š' +
            '   - é¿å…è¿½é«˜ï¼Œå…³æ³¨ä»·å€¼å‹èµ„äº§' +
            '   - å‡†å¤‡åœ¨å¸‚åœºæƒ…ç»ªè½¬å‘æ—¶å¿«é€Ÿè¡ŒåŠ¨' if market_frenzy else
            'ğŸŸ¢ã€ç§¯æé…ç½®ã€‘å¸‚åœºå‡è¡¡æ¨¡å¼ç¡®è®¤ï¼å»ºè®®ï¼š' +
            '   - ç»´æŒæ­£å¸¸é£é™©æ•å£ï¼Œæ‰§è¡Œæ—¢å®šæŠ•èµ„ç­–ç•¥' +
            '   - åˆ©ç”¨æ³¢åŠ¨ç‡æœºä¼šè¿›è¡Œæ³¢æ®µæ“ä½œ' +
            '   - å®šæœŸç›‘æ§é£é™©æŒ‡æ ‡å˜åŒ–' if market_equilibrium else
            'ğŸ”µã€è§‚å¯Ÿç­‰å¾…ã€‘æ··åˆçŠ¶æ€ï¼å»ºè®®ï¼š' +
            '   - ç»´æŒä¸­æ€§ä»“ä½ï¼Œé¿å…è¿‡åº¦æš´éœ²' +
            '   - è®¾ç½®é¢„è­¦çº¿ï¼šå·¦åé£é™©>0.7ä¸”æ›²é¢æ›²ç‡>0.2åˆ™å¯åŠ¨å¯¹å†²' +
            '   - æ¯å‘¨é‡æ–°è¯„ä¼°å¸‚åœºæ¨¡å¼')}
            
            ğŸ“Œ é£é™©æç¤ºï¼š
            - 2025å¹´12æœˆå¸‚åœºç‰¹å¾ï¼šFOMCä¼šè®®å‰å¸‚åœºæ³¢åŠ¨ç‡é€šå¸¸ä¸Šå‡ï¼Œéœ€ç‰¹åˆ«å…³æ³¨å°¾éƒ¨é£é™©
            - æœ¬åˆ†æåŸºäºå†å²ä»·æ ¼æ•°æ®ï¼Œæç«¯è¡Œæƒ…ä¸‹æŒ‡æ ‡å¯èƒ½å¤±æ•ˆ
            - å»ºè®®ç»“åˆå®è§‚ç»æµæŒ‡æ ‡ç»¼åˆåˆ¤æ–­
            
            ğŸ” æ·±åº¦æ´å¯Ÿï¼š
            {('å·¦åé£é™©é¢†å…ˆéšå«ååº¦å˜åŒ–çº¦' + str(-best_lag) + 'å¤©ï¼Œå¯ä½œä¸ºæ—©æœŸé¢„è­¦ä¿¡å·ã€‚'
            if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag < 0
            else 'éšå«ååº¦å˜åŒ–å…ˆäºå·¦åé£é™©å˜åŒ–çº¦' + str(best_lag) + 'å¤©ï¼Œéœ€ä¼˜å…ˆå…³æ³¨æƒ…ç»ªæŒ‡æ ‡ã€‚'
            if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag > 0
            else 'å·¦åé£é™©ä¸éšå«ååº¦åŒæ­¥å˜åŒ–ï¼Œéœ€åŒæ—¶ç›‘æ§ä¸¤ç±»æŒ‡æ ‡ã€‚')}
            å½“å°¾éƒ¨é£é™©é¢„è­¦ä¿¡å·è§¦å‘åï¼Œæœªæ¥{int(abs(best_lag)) + 5 if best_lag else '7'}å¤©å†…å¸‚åœºæ³¢åŠ¨ç‡å¹³å‡ä¸Šå‡{abs(best_corr) * 100:.0f}%ã€‚
            
            ğŸ’¡ ç‰¹åˆ«æç¤ºï¼š
            è¯¥æŒ‡æ•°å½“å‰è¡¨ç°{('å°¾éƒ¨é£é™©æ˜¾è‘—é«˜äº' if skew_relative and skew_relative and skew_relative < -0.5 else
            'å°¾éƒ¨é£é™©é«˜äº' if skew_relative and skew_relative and skew_relative < -0.3 else
            'å°¾éƒ¨é£é™©æ˜¾è‘—ä½äº' if skew_relative and skew_relative and skew_relative > 0.5 else
            'å°¾éƒ¨é£é™©ä½äº' if skew_relative and skew_relative and skew_relative > 0.3 else
            'ä¸')}åŒç±»æŒ‡æ•°æ•´ä½“æ°´å¹³ï¼Œ{('å»ºè®®' if skew_relative and skew_relative and skew_relative < -0.3 else 'è°¨æ…')}{'å¯¹å†²' if skew_relative and skew_relative and skew_relative < -0.5 else 'è§‚æœ›' if skew_relative and abs(skew_relative) < 0.3 else 'å¢é…'}
            """.strip()

        return summary

    def _analyze_future(self, start_date:int, end_date:int, order_book_id_list: list = None):
        """
        å¯¹æœŸè´§æ—¥çº¿æ•°æ®è¿›è¡Œæ·±åº¦åˆ†æï¼ŒåŸºäºæŒä»“é‡å’Œä»·æ ¼å…³ç³»è§£æ„å¤šç©ºåŠ›é‡
        """
        future_features_list = ['open', 'close', 'high', 'low', 'settlement', 'prev_settlement', 'open_interest', 'volume', 'total_turnover']
        df = self.ricequant_service.instruments_data_fetching(type='Future', start_date=start_date, end_date=end_date, features_list=future_features_list, order_book_id_list=order_book_id_list)

        # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®å¹¶æ’åº
        df['date'] = pd.to_datetime(df['date'], format='%Y/%m/%d')
        df = df.sort_values(['order_book_id', 'date']).reset_index(drop=True)

        # 2. åŸºç¡€æŒ‡æ ‡è®¡ç®—
        # ä»·æ ¼å˜åŠ¨
        df['price_change'] = df['settlement'] - df['prev_settlement']

        # ä»·æ ¼å˜åŠ¨ç‡
        df['price_change_pct'] = np.where(
            df['prev_settlement'] > 0,
            df['price_change'] / df['prev_settlement'],
            np.nan
        )

        # æŒä»“é‡å˜åŠ¨
        df['oi_change'] = df['open_interest'].diff()

        # æŒä»“é‡å˜åŠ¨ç‡
        df['oi_change_pct'] = np.where(
            df['open_interest'].shift(1) > 0,
            df['oi_change'] / df['open_interest'].shift(1),
            np.nan
        )

        # 3. å¤šç©ºåŠ›é‡åŠ¨æ€æŒ‡æ ‡

        # èµ„é‡‘æµå‘å¼ºåº¦ (æ ¸å¿ƒæŒ‡æ ‡)
        df['fund_flow_strength'] = np.where(
            df['volume'] > 0,
            df['price_change'] * df['open_interest'] / df['volume'],
            np.nan
        )

        # æŒä»“é›†ä¸­åº¦
        price_range = (df['high'] - df['low']).replace(0, np.nan)
        df['oi_concentration'] = np.where(
            (df['settlement'] > 0) & (price_range.notna()),
            (df['open_interest'] / df['volume']) * price_range / df['settlement'],
            np.nan
        )

        # 4. åŸºå·®ç›¸å…³æŒ‡æ ‡

        # éšå«èèµ„æˆæœ¬ (å‡è®¾æ— é£é™©åˆ©ç‡ä¸º0.02/365)
        df['implied_funding_cost'] = np.log(df['settlement'] / df['prev_settlement']) - 0.02 / 365

        # 5. æŒä»“-ä»·æ ¼å…³ç³»æŒ‡æ ‡

        # æŒä»“-ä»·æ ¼èƒŒç¦»åº¦
        df['oi_price_divergence'] = np.where(
            (df['oi_change_pct'].abs() > 1e-5) & df['oi_change_pct'].notna(),
            df['price_change_pct'] / df['oi_change_pct'],
            np.nan
        )

        # 6. è¶‹åŠ¿å»¶ç»­æ¦‚ç‡è¯„ä¼°
        df['trend_continuation_prob'] = np.nan

        # ä»…å½“æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®æ—¶è®¡ç®—
        for i in range(10, len(df)):
            # ä½¿ç”¨10æ—¥çª—å£è®¡ç®—åŠ¨æ€è¶‹åŠ¿å»¶ç»­æ¦‚ç‡
            fund_flow_window = df['fund_flow_strength'].iloc[i - 9:i + 1]
            price_change_window = df['price_change_pct'].iloc[i - 9:i + 1]

            if len(fund_flow_window.dropna()) > 5 and len(price_change_window.dropna()) > 5:
                # è®¡ç®—èµ„é‡‘æµå‘å¼ºåº¦ä¸ä»·æ ¼å˜åŠ¨çš„ç›¸å…³æ€§
                corr = fund_flow_window.corr(price_change_window)

                # åŸºäºå†å²æ•°æ®ä¼°è®¡è¶‹åŠ¿å»¶ç»­æ¦‚ç‡
                if not np.isnan(corr) and fund_flow_window.iloc[-1] > 0:
                    # ç®€å•æ¨¡å‹ï¼šèµ„é‡‘æµå‘å¼ºåº¦è¶Šå¤§ï¼Œè¶‹åŠ¿å»¶ç»­æ¦‚ç‡è¶Šé«˜
                    prob = min(0.9, 0.5 + fund_flow_window.iloc[-1] * 0.5)
                    df.iloc[i, df.columns.get_loc('trend_continuation_prob')] = prob

        # 7. é£é™©é¢„è­¦ä¿¡å·

        # è¶‹åŠ¿è¡°ç«­ä¿¡å·ï¼šæŒä»“-ä»·æ ¼èƒŒç¦»åº¦ > 2 ä¸”ä¸ºè´Ÿå€¼
        df['trend_exhaustion_alert'] = (df['oi_price_divergence'] > 2) & (df['oi_price_divergence'] < 0)

        # é—ªå´©é£é™©ä¿¡å·ï¼šæŒä»“é›†ä¸­åº¦ > 1.5 ä¸”èµ„é‡‘æµå‘å¼ºåº¦å‰§çƒˆæ³¢åŠ¨
        df['flash_crash_risk'] = (df['oi_concentration'] > 1.5) & (
                    df['fund_flow_strength'].abs() > df['fund_flow_strength'].rolling(20).std() * 2)

        # å•†å“çŸ­ç¼ºä¿¡å·ï¼šéšå«èèµ„æˆæœ¬ < 0 ä¸”æŒç»­3æ—¥
        df['commodity_shortage_signal'] = (df['implied_funding_cost'] < 0) & (
                    df['implied_funding_cost'].rolling(3).sum() < 0)

        # 8. æœŸé™ç»“æ„åˆ†æ (å‡è®¾æœ‰å¤šåˆçº¦æ•°æ®ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†)
        # å¦‚æœæ˜¯ä¸»åŠ›è¿ç»­åˆçº¦ï¼Œç”¨æ»šåŠ¨çª—å£è®¡ç®—æœŸé™ç»“æ„æ–œç‡
        df['term_structure_slope'] = df['implied_funding_cost'].rolling(5).mean()

        # 9. æ„å»ºç»“æœå­—å…¸
        results = []
        for _, row in df.iterrows():
            result = {
                "date": row['date'].strftime('%Y-%m-%d'),
                "order_book_id": row['order_book_id'],
                "price_change": float(row['price_change']) if not pd.isna(row['price_change']) else None,
                "price_change_pct": float(row['price_change_pct']) if not pd.isna(
                    row['price_change_pct']) else None,
                "oi_change": float(row['oi_change']) if not pd.isna(row['oi_change']) else None,
                "oi_change_pct": float(row['oi_change_pct']) if not pd.isna(row['oi_change_pct']) else None,
                "fund_flow_strength": float(row['fund_flow_strength']) if not pd.isna(
                    row['fund_flow_strength']) else None,
                "oi_concentration": float(row['oi_concentration']) if not pd.isna(
                    row['oi_concentration']) else None,
                "implied_funding_cost": float(row['implied_funding_cost']) if not pd.isna(
                    row['implied_funding_cost']) else None,
                "oi_price_divergence": float(row['oi_price_divergence']) if not pd.isna(
                    row['oi_price_divergence']) else None,
                "trend_continuation_prob": float(row['trend_continuation_prob']) if not pd.isna(
                    row['trend_continuation_prob']) else None,
                "trend_exhaustion_alert": bool(row['trend_exhaustion_alert']),
                "flash_crash_risk": bool(row['flash_crash_risk']),
                "commodity_shortage_signal": bool(row['commodity_shortage_signal']),
                "term_structure_slope": float(row['term_structure_slope']) if not pd.isna(
                    row['term_structure_slope']) else None
            }
            results.append(result)

        return results

    def summarize_Futureanalysis(self, start_date: int, end_date: int, target_future_id=None,
                                 future_id_list: list = None, lookback_days=30, confidence_level=0.95):
        """
        å¯¹æœŸè´§æ·±åº¦åˆ†ææŒ‡æ ‡è¿›è¡Œæ—¶é—´åºåˆ—è¶‹åŠ¿åˆ†æï¼Œè¯†åˆ«åŠ¨æ€æ¨¡å¼ä¸é¢†å…ˆ-æ»åå…³ç³»
        """
        # 1. è·å–æœŸè´§åˆ†æç»“æœ
        analysis_results = self._analyze_future(start_date, end_date, future_id_list)
        if not analysis_results:
            return "æ— æœŸè´§æ•°æ®å¯ä¾›åˆ†æã€‚"

        # è½¬æ¢ä¸ºDataFrameå¹¶é¢„å¤„ç†
        df = pd.DataFrame(analysis_results)

        # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
        if not pd.api.types.is_datetime64_any_dtype(df['date']):
            df['date'] = pd.to_datetime(df['date'])

        # æŒ‰æœŸè´§ä»£ç å’Œæ—¥æœŸæ’åº
        df = df.sort_values(['order_book_id', 'date']).reset_index(drop=True)

        # ======================
        # 2. ç¡®å®šç›®æ ‡æœŸè´§å¹¶è®¡ç®—å¸‚åœºåŸºå‡†
        # ======================

        # ç¡®å®šè¦åˆ†æçš„ç›®æ ‡æœŸè´§
        if target_future_id:
            if target_future_id not in df['order_book_id'].unique():
                return f"æœªæ‰¾åˆ°æœŸè´§ {target_future_id} çš„æ•°æ®ã€‚"
        else:
            # è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªæœŸè´§
            target_future_id = df['order_book_id'].iloc[0]

        # è·å–æœ€æ–°æ—¥æœŸï¼ˆç”¨äºå¸‚åœºåŸºå‡†è®¡ç®—ï¼‰
        latest_date = df['date'].max()

        # è·å–æ‰€æœ‰æœŸè´§åœ¨æœ€æ–°æ—¥æœŸçš„æ•°æ®ï¼ˆç”¨äºè®¡ç®—å¸‚åœºåŸºå‡†ï¼‰
        market_df = df[df['date'] == latest_date].copy()

        # è®¡ç®—å¸‚åœºåŸºå‡†ï¼ˆæ’é™¤ç›®æ ‡æœŸè´§è‡ªèº«ï¼Œé¿å…è‡ªç›¸å…³ï¼‰
        market_benchmarks = {}
        if len(market_df) > 1:  # è‡³å°‘æœ‰2åªæœŸè´§æ‰èƒ½è®¡ç®—æœ‰æ„ä¹‰çš„åŸºå‡†
            market_without_target = market_df[market_df['order_book_id'] != target_future_id]
            if not market_without_target.empty:
                # åªæœ‰å½“æœ‰æ•ˆæ•°æ®å­˜åœ¨æ—¶æ‰è®¡ç®—åŸºå‡†
                valid_fund_flow = market_without_target['fund_flow_strength'].dropna()
                valid_oi_conc = market_without_target['oi_concentration'].dropna()
                valid_term_slope = market_without_target['term_structure_slope'].dropna()

                market_benchmarks = {
                    'fund_flow_mean': valid_fund_flow.mean() if not valid_fund_flow.empty else None,
                    'fund_flow_25pct': valid_fund_flow.quantile(0.25) if not valid_fund_flow.empty else None,
                    'fund_flow_75pct': valid_fund_flow.quantile(0.75) if not valid_fund_flow.empty else None,
                    'oi_conc_mean': valid_oi_conc.mean() if not valid_oi_conc.empty else None,
                    'oi_conc_25pct': valid_oi_conc.quantile(0.25) if not valid_oi_conc.empty else None,
                    'oi_conc_75pct': valid_oi_conc.quantile(0.75) if not valid_oi_conc.empty else None,
                    'term_slope_mean': valid_term_slope.mean() if not valid_term_slope.empty else None
                }

        # é€‰æ‹©ç›®æ ‡æœŸè´§çš„æ—¶é—´åºåˆ—æ•°æ®
        future_df = df[df['order_book_id'] == target_future_id].copy()

        # é™åˆ¶åˆ†æçª—å£
        if len(future_df) > lookback_days:
            future_df = future_df.tail(lookback_days).reset_index(drop=True)

        n = len(future_df)
        if n < 10:  # éœ€è¦è¶³å¤Ÿæ•°æ®è¿›è¡Œè¶‹åŠ¿åˆ†æ
            return f"æœŸè´§ {target_future_id} æ•°æ®ç‚¹ä¸è¶³ï¼ˆ{n}å¤©ï¼‰ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆè¶‹åŠ¿åˆ†æã€‚"

        # è·å–æœ€æ–°æ•°æ®ç‚¹
        latest = future_df.iloc[-1]

        # ======================
        # 3. æ·±åº¦æ—¶é—´åºåˆ—è¶‹åŠ¿åˆ†æ
        # ======================

        # --- 3.1 èµ„é‡‘æµå‘å¼ºåº¦è¶‹åŠ¿ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰---
        fund_flow = future_df['fund_flow_strength'].astype(float).dropna()

        # è®¡ç®—çº¿æ€§è¶‹åŠ¿æ–œç‡å’Œæ˜¾è‘—æ€§
        fund_flow_trend_desc = "èµ„é‡‘æµå‘å¼ºåº¦è¶‹åŠ¿åˆ†æå¤±è´¥ï¼Œæ•°æ®å¯èƒ½å­˜åœ¨é—®é¢˜"
        if len(fund_flow) >= 10:
            x = np.arange(len(fund_flow))
            try:
                slope_ff, intercept_ff, r_ff, p_ff, std_err_ff = stats.linregress(x, fund_flow)
                trend_strength = abs(slope_ff) * len(fund_flow) / (fund_flow.mean() + 1e-5)

                # è¶‹åŠ¿åˆ†ç±»
                if p_ff < (1 - confidence_level):
                    if slope_ff > 0:
                        if trend_strength > 0.5:
                            fund_flow_trend_desc = "æ˜¾è‘—ä¸Šå‡è¶‹åŠ¿ï¼Œèµ„é‡‘æŒç»­æµå…¥ï¼Œå¤šå¤´åŠ›é‡å¼ºåŠ²"
                        elif trend_strength > 0.2:
                            fund_flow_trend_desc = "æ¸©å’Œä¸Šå‡è¶‹åŠ¿ï¼Œèµ„é‡‘é€æ­¥æµå…¥"
                        else:
                            fund_flow_trend_desc = "è½»å¾®ä¸Šå‡è¶‹åŠ¿ï¼Œèµ„é‡‘æµå…¥ç¼“æ…¢"
                    else:
                        if trend_strength > 0.5:
                            fund_flow_trend_desc = "æ˜¾è‘—ä¸‹é™è¶‹åŠ¿ï¼Œèµ„é‡‘æŒç»­æµå‡ºï¼Œå¤šå¤´åŠ›é‡å‡å¼±"
                        elif trend_strength > 0.2:
                            fund_flow_trend_desc = "æ¸©å’Œä¸‹é™è¶‹åŠ¿ï¼Œèµ„é‡‘é€æ­¥æµå‡º"
                        else:
                            fund_flow_trend_desc = "è½»å¾®ä¸‹é™è¶‹åŠ¿ï¼Œèµ„é‡‘æµå‡ºç¼“æ…¢"

                    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                    fund_flow_trend_desc += f"ï¼ˆæ–œç‡={slope_ff:.4f}, p={p_ff:.3f}ï¼‰"
                else:
                    fund_flow_trend_desc = "æ— æ˜¾è‘—è¶‹åŠ¿ï¼Œèµ„é‡‘æµå‘éšæœºæ³¢åŠ¨"
            except Exception as e:
                pass

        # --- 3.2 æŒä»“é›†ä¸­åº¦è¶‹åŠ¿ ---
        oi_concentration = future_df['oi_concentration'].astype(float).dropna()

        oi_conc_status = ""
        if len(oi_concentration) > 0:
            current_oi_conc = oi_concentration.iloc[-1]
            if current_oi_conc > 1.5:
                oi_conc_status = f"æŒä»“é«˜åº¦é›†ä¸­ï¼ˆå½“å‰å€¼={current_oi_conc:.2f}ï¼‰ï¼Œå°‘æ•°å¤§æˆ·ä¸»å¯¼ï¼Œå¸‚åœºæ˜“é—ªå´©"
            elif current_oi_conc > 0.8:
                oi_conc_status = f"æŒä»“è¾ƒä¸ºé›†ä¸­ï¼ˆå½“å‰å€¼={current_oi_conc:.2f}ï¼‰ï¼Œå¤§æˆ·å½±å“åŠ›è¾ƒå¤§"
            elif current_oi_conc < 0.5:
                oi_conc_status = f"æŒä»“åˆ†æ•£ï¼ˆå½“å‰å€¼={current_oi_conc:.2f}ï¼‰ï¼Œæ•£æˆ·ä¸»å¯¼ï¼Œè¶‹åŠ¿è¾ƒä¸ºå¹³ç¨³"
            else:
                oi_conc_status = f"æŒä»“é›†ä¸­åº¦é€‚ä¸­ï¼ˆå½“å‰å€¼={current_oi_conc:.2f}ï¼‰ï¼Œå¤šç©ºåŠ›é‡å‡è¡¡"
        else:
            oi_conc_status = "æŒä»“é›†ä¸­åº¦æ•°æ®ä¸è¶³"

        # --- 3.3 æœŸé™ç»“æ„æ–œç‡è¶‹åŠ¿ ---
        term_slope = future_df['term_structure_slope'].dropna()
        term_slope_summary = "æœŸé™ç»“æ„æ–œç‡æ•°æ®ä¸è¶³"

        if len(term_slope) >= 10:
            # è®¡ç®—æœŸé™ç»“æ„æ–œç‡è¶‹åŠ¿
            x_ts = np.arange(len(term_slope))
            try:
                slope_ts, _, _, p_ts, _ = stats.linregress(x_ts, term_slope)

                if p_ts < (1 - confidence_level) and slope_ts > 0.001:
                    term_slope_summary = f"æœŸé™ç»“æ„æ–œç‡å‘ˆæ˜¾è‘—ä¸Šå‡è¶‹åŠ¿ï¼ˆæ–œç‡={slope_ts:.4f}, p={p_ts:.3f}ï¼‰ï¼ŒBackwardationåŠ æ·±æˆ–Contangoå‡å¼±"
                elif p_ts < (1 - confidence_level) and slope_ts < -0.001:
                    term_slope_summary = f"æœŸé™ç»“æ„æ–œç‡å‘ˆæ˜¾è‘—ä¸‹é™è¶‹åŠ¿ï¼ˆæ–œç‡={slope_ts:.4f}, p={p_ts:.3f}ï¼‰ï¼ŒContangoåŠ æ·±æˆ–Backwardationå‡å¼±"
                else:
                    term_slope_summary = f"æœŸé™ç»“æ„æ–œç‡æ³¢åŠ¨ä½†æ— æ˜¾è‘—è¶‹åŠ¿ï¼ˆp={p_ts:.3f}ï¼‰ï¼ŒæœŸé™ç»“æ„ä¿æŒç¨³å®š"
            except Exception as e:
                pass

        # --- 3.4 æŒä»“-ä»·æ ¼èƒŒç¦»åˆ†æ ---
        oi_price_div = future_df['oi_price_divergence'].dropna()
        divergence_summary = "æŒä»“-ä»·æ ¼èƒŒç¦»åº¦æ•°æ®ä¸è¶³"

        if len(oi_price_div) > 5:
            current_div = oi_price_div.iloc[-1]
            if current_div > 2 and current_div < 0:
                divergence_summary = f"æŒä»“-ä»·æ ¼æ˜¾è‘—èƒŒç¦»ï¼ˆå½“å‰å€¼={current_div:.2f}ï¼‰ï¼Œè¶‹åŠ¿å¯èƒ½è¡°ç«­"
            elif current_div < -2:
                divergence_summary = f"æŒä»“-ä»·æ ¼åŒå‘å¼ºåŒ–ï¼ˆå½“å‰å€¼={current_div:.2f}ï¼‰ï¼Œè¶‹åŠ¿å¯èƒ½å»¶ç»­"
            else:
                divergence_summary = f"æŒä»“-ä»·æ ¼å…³ç³»æ­£å¸¸ï¼ˆå½“å‰å€¼={current_div:.2f}ï¼‰ï¼Œå¸‚åœºç»“æ„å¥åº·"

        # --- 3.5 é£é™©é¢„è­¦ä¿¡å·åˆ†æ ---
        trend_exhaustion_alerts = future_df['trend_exhaustion_alert'].sum()
        flash_crash_risks = future_df['flash_crash_risk'].sum()
        commodity_shortage_signals = future_df['commodity_shortage_signal'].sum()

        risk_summary = ""
        if trend_exhaustion_alerts > n * 0.2:
            risk_summary = f"è¶‹åŠ¿è¡°ç«­ä¿¡å·é«˜é¢‘è§¦å‘ï¼ˆ{trend_exhaustion_alerts}æ¬¡ï¼Œ{trend_exhaustion_alerts / n:.0%}å¤©ï¼‰ï¼Œè¶‹åŠ¿å¯èƒ½åè½¬"
        elif trend_exhaustion_alerts > 0:
            risk_summary = f"å¶å‘è¶‹åŠ¿è¡°ç«­ä¿¡å·ï¼ˆ{trend_exhaustion_alerts}æ¬¡ï¼‰ï¼Œéœ€è­¦æƒ•è¶‹åŠ¿è¡°ç«­"
        else:
            risk_summary = "æœªæ£€æµ‹åˆ°è¶‹åŠ¿è¡°ç«­ä¿¡å·ï¼Œè¶‹åŠ¿ç»“æ„ç¨³å¥"

        # --- 3.6 é¢†å…ˆ-æ»åå…³ç³»åˆ†æ ---
        lead_lag_results = []
        best_lag = None
        best_corr = 0.0
        if len(fund_flow) >= 20 and len(term_slope) >= 20:
            for lag in range(-7, 8):  # -7åˆ°+7å¤©çš„æ»å
                try:
                    if lag <= 0:
                        corr = fund_flow[:lag].corr(term_slope[-lag:]) if lag != 0 else fund_flow.corr(term_slope)
                    else:
                        corr = fund_flow[lag:].corr(term_slope[:-lag])
                    lead_lag_results.append((lag, corr))
                except:
                    continue

            if lead_lag_results:
                best_lag, best_corr = max(lead_lag_results, key=lambda x: abs(x[1]))
                if abs(best_corr) > 0.4:
                    if best_lag < 0:
                        lead_lag_summary = f"èµ„é‡‘æµå‘é¢†å…ˆæœŸé™ç»“æ„çº¦{-best_lag}å¤©ï¼ˆæœ€å¤§ç›¸å…³ç³»æ•°={best_corr:.2f}ï¼‰ï¼Œæ˜¯æœŸé™ç»“æ„å˜åŒ–çš„å…ˆè¡ŒæŒ‡æ ‡"
                    elif best_lag > 0:
                        lead_lag_summary = f"æœŸé™ç»“æ„é¢†å…ˆèµ„é‡‘æµå‘çº¦{best_lag}å¤©ï¼ˆæœ€å¤§ç›¸å…³ç³»æ•°={best_corr:.2f}ï¼‰ï¼ŒæœŸé™ç»“æ„å…ˆäºèµ„é‡‘å˜åŒ–"
                    else:
                        lead_lag_summary = f"èµ„é‡‘æµå‘ä¸æœŸé™ç»“æ„åŒæ­¥å˜åŒ–ï¼ˆç›¸å…³ç³»æ•°={best_corr:.2f}ï¼‰ï¼Œå¤šç©ºåŠ›é‡ä¸æœŸé™ç»“æ„è”åŠ¨ç´§å¯†"
                else:
                    lead_lag_summary = "èµ„é‡‘æµå‘ä¸æœŸé™ç»“æ„å…³ç³»ä¸ç¨³å®šï¼Œæ— æ˜æ˜¾é¢†å…ˆ-æ»åæ¨¡å¼"
            else:
                lead_lag_summary = "æ— æ³•è®¡ç®—é¢†å…ˆ-æ»åå…³ç³»ï¼Œç›¸å…³ç³»æ•°è®¡ç®—å¤±è´¥"
        else:
            lead_lag_summary = "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œé¢†å…ˆ-æ»ååˆ†æ"

        # ======================
        # 4. è¯†åˆ«å…³é”®åŠ¨æ€æ¨¡å¼
        # ======================

        # æ¨¡å¼1: å•†å“çŸ­ç¼ºæ¨¡å¼
        commodity_shortage_mode = (
                "BackwardationåŠ æ·±" in term_slope_summary and
                "èµ„é‡‘æŒç»­æµå…¥" in fund_flow_trend_desc and
                commodity_shortage_signals > n * 0.2
        )

        # æ¨¡å¼2: è¶‹åŠ¿è¡°ç«­æ¨¡å¼
        trend_exhaustion_mode = (
                "æ˜¾è‘—èƒŒç¦»" in divergence_summary and
                "èµ„é‡‘æµå‡º" in fund_flow_trend_desc and
                trend_exhaustion_alerts > n * 0.1
        )

        # æ¨¡å¼3: é—ªå´©é£é™©æ¨¡å¼
        flash_crash_mode = (
                "æŒä»“é«˜åº¦é›†ä¸­" in oi_conc_status and
                "èµ„é‡‘æµå‘å‰§çƒˆæ³¢åŠ¨" in fund_flow_trend_desc and
                flash_crash_risks > n * 0.1
        )

        # æ¨¡å¼4: å¸‚åœºå‡è¡¡æ¨¡å¼
        market_equilibrium = (
                "æ— æ˜¾è‘—è¶‹åŠ¿" in fund_flow_trend_desc and
                "æŒä»“é›†ä¸­åº¦é€‚ä¸­" in oi_conc_status and
                "æ³¢åŠ¨ä½†æ— æ˜¾è‘—è¶‹åŠ¿" in term_slope_summary and
                trend_exhaustion_alerts == 0
        )

        # ======================
        # 5. ç›¸å¯¹å¸‚åœºå®šä½åˆ†æ
        # ======================

        # è®¡ç®—ç›¸å¯¹ä½ç½®
        fund_flow_relative_desc = "æ— å¸‚åœºæ¯”è¾ƒæ•°æ®"
        oi_conc_relative_desc = "æ— å¸‚åœºæ¯”è¾ƒæ•°æ®"

        fund_flow_relative = None
        oi_conc_relative = None

        # 1. èµ„é‡‘æµå‘å¼ºåº¦ç›¸å¯¹ä½ç½®
        if ('fund_flow_mean' in market_benchmarks and
                market_benchmarks['fund_flow_mean'] is not None and
                not pd.isna(latest['fund_flow_strength']) and
                market_benchmarks['fund_flow_75pct'] is not None and
                market_benchmarks['fund_flow_25pct'] is not None):

            iqr = market_benchmarks['fund_flow_75pct'] - market_benchmarks['fund_flow_25pct']
            if iqr > 1e-5:
                fund_flow_relative = (
                        (latest['fund_flow_strength'] - market_benchmarks['fund_flow_mean']) /
                        (iqr + 1e-5)
                )
                if fund_flow_relative > 1.0:
                    fund_flow_relative_desc = "èµ„é‡‘æµå‘å¼ºåº¦æ˜¾è‘—é«˜äºåŒç±»æœŸè´§ï¼Œå¤šå¤´åŠ›é‡å¼‚å¸¸å¼ºåŠ²"
                elif fund_flow_relative > 0.5:
                    fund_flow_relative_desc = "èµ„é‡‘æµå‘å¼ºåº¦é«˜äºåŒç±»æœŸè´§"
                elif fund_flow_relative < -1.0:
                    fund_flow_relative_desc = "èµ„é‡‘æµå‘å¼ºåº¦æ˜¾è‘—ä½äºåŒç±»æœŸè´§ï¼Œå¤šå¤´åŠ›é‡å¼‚å¸¸ç–²è½¯"
                elif fund_flow_relative < -0.5:
                    fund_flow_relative_desc = "èµ„é‡‘æµå‘å¼ºåº¦ä½äºåŒç±»æœŸè´§"
                else:
                    fund_flow_relative_desc = "èµ„é‡‘æµå‘å¼ºåº¦å¤„äºåŒç±»æœŸè´§æ­£å¸¸æ°´å¹³"
            else:
                fund_flow_relative_desc = "èµ„é‡‘æµå‘å¼ºåº¦å¸‚åœºåŸºå‡†æ•°æ®ä¸è¶³"
        else:
            fund_flow_relative_desc = "èµ„é‡‘æµå‘å¼ºåº¦å¸‚åœºåŸºå‡†æ•°æ®ä¸è¶³"

        # 2. æŒä»“é›†ä¸­åº¦ç›¸å¯¹ä½ç½®
        if ('oi_conc_mean' in market_benchmarks and
                market_benchmarks['oi_conc_mean'] is not None and
                not pd.isna(latest['oi_concentration']) and
                market_benchmarks['oi_conc_75pct'] is not None and
                market_benchmarks['oi_conc_25pct'] is not None):

            iqr = market_benchmarks['oi_conc_75pct'] - market_benchmarks['oi_conc_25pct']
            if iqr > 1e-5:
                oi_conc_relative = (
                        (latest['oi_concentration'] - market_benchmarks['oi_conc_mean']) /
                        (iqr + 1e-5)
                )
                if oi_conc_relative > 1.0:
                    oi_conc_relative_desc = "æŒä»“é›†ä¸­åº¦æ˜¾è‘—é«˜äºåŒç±»æœŸè´§ï¼Œå¸‚åœºæ˜“å—å¤§æˆ·å½±å“"
                elif oi_conc_relative > 0.5:
                    oi_conc_relative_desc = "æŒä»“é›†ä¸­åº¦é«˜äºåŒç±»æœŸè´§"
                elif oi_conc_relative < -1.0:
                    oi_conc_relative_desc = "æŒä»“é›†ä¸­åº¦æ˜¾è‘—ä½äºåŒç±»æœŸè´§ï¼Œå¸‚åœºç»“æ„æ›´åˆ†æ•£"
                elif oi_conc_relative < -0.5:
                    oi_conc_relative_desc = "æŒä»“é›†ä¸­åº¦ä½äºåŒç±»æœŸè´§"
                else:
                    oi_conc_relative_desc = "æŒä»“é›†ä¸­åº¦å¤„äºåŒç±»æœŸè´§æ­£å¸¸æ°´å¹³"
            else:
                oi_conc_relative_desc = "æŒä»“é›†ä¸­åº¦å¸‚åœºåŸºå‡†æ•°æ®ä¸è¶³"
        else:
            oi_conc_relative_desc = "æŒä»“é›†ä¸­åº¦å¸‚åœºåŸºå‡†æ•°æ®ä¸è¶³"

        # ======================
        # 6. ç»¼åˆæ€»ç»“è¾“å‡º
        # ======================
        summary = f"""
            ã€{target_future_id} æœŸè´§æ·±åº¦è¶‹åŠ¿åˆ†ææŠ¥å‘Šã€‘ï¼ˆæˆªè‡³ {future_df['date'].max().strftime('%Y-%m-%d')}ï¼‰
            
            ğŸŒ å¸‚åœºç›¸å¯¹å®šä½ï¼ˆåŸºäº{len(market_df)}åªæœŸè´§æœ€æ–°æ•°æ®ï¼‰ï¼š
            - èµ„é‡‘æµå‘å¼ºåº¦ï¼š{fund_flow_relative_desc}
            - æŒä»“é›†ä¸­åº¦ï¼š{oi_conc_relative_desc}
            
            ğŸ” æ ¸å¿ƒè¶‹åŠ¿è¯Šæ–­ï¼ˆåŸºäº{len(future_df)}å¤©æ•°æ®ï¼‰ï¼š
            1. **èµ„é‡‘æµå‘è¶‹åŠ¿**ï¼š{fund_flow_trend_desc}
            - å½“å‰èµ„é‡‘æµå‘å¼ºåº¦ï¼š{latest['fund_flow_strength']:.4f}
            - ç›¸å¯¹å¸‚åœºä½ç½®ï¼š{'é«˜äº' if fund_flow_relative and fund_flow_relative > 0 else 'ä½äº' if fund_flow_relative and fund_flow_relative < 0 else 'æ¥è¿‘'}å¸‚åœºå¹³å‡æ°´å¹³
            - 5æ—¥ç§»åŠ¨å¹³å‡ï¼š{fund_flow.rolling(5).mean().iloc[-1]:.4f}
            
            2. **æŒä»“é›†ä¸­åº¦åˆ†æ**ï¼š{oi_conc_status}
            - å½“å‰æŒä»“é›†ä¸­åº¦ï¼š{latest['oi_concentration']:.2f}
            - ç›¸å¯¹å¸‚åœºä½ç½®ï¼š{'é«˜äº' if oi_conc_relative and oi_conc_relative > 0 else 'ä½äº' if oi_conc_relative and oi_conc_relative < 0 else 'æ¥è¿‘'}å¸‚åœºå¹³å‡æ°´å¹³
            
            3. **æœŸé™ç»“æ„åˆ†æ**ï¼š{term_slope_summary}
            - å½“å‰æœŸé™ç»“æ„æ–œç‡ï¼š{latest['term_structure_slope']:.4f}
            - 5æ—¥ç§»åŠ¨å¹³å‡ï¼š{term_slope.rolling(5).mean().iloc[-1]:.4f}
            
            4. **æŒä»“-ä»·æ ¼å…³ç³»**ï¼š{divergence_summary}
            
            5. **å…³é”®åŠ¨æ€å…³ç³»**ï¼š{lead_lag_summary}
            - {'èµ„é‡‘æµå‘å¯ä½œä¸ºæœŸé™ç»“æ„å˜åŒ–çš„é¢†å…ˆæŒ‡æ ‡ï¼Œæå‰é¢„è­¦å¸‚åœºç»“æ„å˜åŒ–'
            if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag < 0
            else 'æœŸé™ç»“æ„å˜åŒ–å…ˆäºèµ„é‡‘æµå‘ï¼Œéœ€ä¼˜å…ˆå…³æ³¨æœŸé™ç»“æ„'
            if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag > 0
            else 'èµ„é‡‘æµå‘ä¸æœŸé™ç»“æ„åŒæ­¥å˜åŒ–ï¼Œéœ€åŒæ—¶ç›‘æ§'}
            
            ğŸ’¡ è¯†åˆ«åˆ°çš„å¸‚åœºæ¨¡å¼ï¼š
            {'âš ï¸ã€å•†å“çŸ­ç¼ºæ¨¡å¼ã€‘BackwardationåŠ æ·±ã€èµ„é‡‘æŒç»­æµå…¥ï¼Œå•†å“å¯èƒ½çŸ­ç¼ºï¼' if commodity_shortage_mode else
            'âš ï¸ã€è¶‹åŠ¿è¡°ç«­æ¨¡å¼ã€‘æŒä»“-ä»·æ ¼æ˜¾è‘—èƒŒç¦»ï¼Œè¶‹åŠ¿å¯èƒ½åè½¬ï¼' if trend_exhaustion_mode else
            'âš ï¸ã€é—ªå´©é£é™©æ¨¡å¼ã€‘æŒä»“é«˜åº¦é›†ä¸­ã€èµ„é‡‘æµå‘å‰§çƒˆæ³¢åŠ¨ï¼Œå¸‚åœºæ˜“é—ªå´©ï¼' if flash_crash_mode else
            'âœ…ã€å¸‚åœºå‡è¡¡æ¨¡å¼ã€‘å¤šç©ºåŠ›é‡å‡è¡¡ï¼Œå¸‚åœºç»“æ„å¥åº·' if market_equilibrium else
            'ğŸ”ã€æ··åˆçŠ¶æ€ã€‘å¸‚åœºå¤„äºè¿‡æ¸¡æœŸï¼Œéœ€å¯†åˆ‡å…³æ³¨é¢†å…ˆæŒ‡æ ‡å˜åŒ–'}
            
            ğŸ“Š é£é™©çŠ¶æ€è¯„ä¼°ï¼š
            - è¶‹åŠ¿è¡°ç«­ä¿¡å·ï¼š{risk_summary}
            - é—ªå´©é£é™©ï¼š{'é«˜é¢‘è§¦å‘' if flash_crash_risks > n * 0.2 else 'å¶å‘è§¦å‘' if flash_crash_risks > 0 else 'æœªè§¦å‘'}
            - å•†å“çŸ­ç¼ºä¿¡å·ï¼š{'é«˜é¢‘è§¦å‘' if commodity_shortage_signals > n * 0.2 else 'å¶å‘è§¦å‘' if commodity_shortage_signals > 0 else 'æœªè§¦å‘'}
            
            ğŸ¯ æ“ä½œå»ºè®®ï¼ˆåŸºäºå½“å‰æ¨¡å¼å’Œå¸‚åœºç›¸å¯¹ä½ç½®ï¼‰ï¼š
            {('ğŸ”´ã€ç´§æ€¥è¡ŒåŠ¨ã€‘å•†å“çŸ­ç¼ºæ¨¡å¼å·²ç¡®è®¤ï¼å»ºè®®ï¼š' +
            '   - åšå¤šè¿‘æœˆåˆçº¦ï¼Œåšç©ºè¿œæœˆåˆçº¦ï¼Œæ•è·BackwardationåŠ æ·±æ”¶ç›Š' +
            '   - é¿å…å±•æœŸæ“ä½œï¼Œé€‰æ‹©å»¶è¿Ÿå±•æœŸç­–ç•¥' +
            '   - å¯†åˆ‡ç›‘æ§åº“å­˜æ•°æ®å’Œåœ°ç¼˜æ”¿æ²»äº‹ä»¶' if commodity_shortage_mode else
            'ğŸŸ¡ã€è°¨æ…æ“ä½œã€‘è¶‹åŠ¿è¡°ç«­æ¨¡å¼ç¡®è®¤ï¼å»ºè®®ï¼š' +
            '   - å‡å°‘å¤šå¤´ä»“ä½ï¼Œè€ƒè™‘åå‘æ“ä½œ' +
            '   - è®¾ç½®æ›´ä¸¥æ ¼çš„æ­¢æŸç‚¹' +
            '   - å…³æ³¨æŒä»“-ä»·æ ¼èƒŒç¦»åº¦å˜åŒ–' if trend_exhaustion_mode else
            'ğŸ”´ã€ç´§æ€¥è¡ŒåŠ¨ã€‘é—ªå´©é£é™©æ¨¡å¼å·²ç¡®è®¤ï¼å»ºè®®ï¼š' +
            '   - å¤§å¹…é™ä½ä»“ä½ï¼Œé¿å…æ æ†' +
            '   - è®¾ç½®å®½å¹…æ­¢æŸï¼Œé˜²èŒƒæç«¯æ³¢åŠ¨' +
            '   - é¿å…åœ¨æµåŠ¨æ€§ä½çš„æ—¶æ®µäº¤æ˜“' if flash_crash_mode else
            'ğŸŸ¢ã€ç§¯æé…ç½®ã€‘å¸‚åœºå‡è¡¡æ¨¡å¼ç¡®è®¤ï¼å»ºè®®ï¼š' +
            '   - ç»´æŒæ­£å¸¸é£é™©æ•å£ï¼Œæ‰§è¡Œæ—¢å®šäº¤æ˜“ç­–ç•¥' +
            '   - åˆ©ç”¨æ³¢åŠ¨ç‡æœºä¼šè¿›è¡Œæ³¢æ®µæ“ä½œ' +
            '   - å®šæœŸç›‘æ§èµ„é‡‘æµå‘å¼ºåº¦å˜åŒ–' if market_equilibrium else
            'ğŸ”µã€è§‚å¯Ÿç­‰å¾…ã€‘æ··åˆçŠ¶æ€ï¼å»ºè®®ï¼š' +
            '   - ç»´æŒä¸­æ€§ä»“ä½ï¼Œé¿å…è¿‡åº¦æš´éœ²' +
            '   - è®¾ç½®é¢„è­¦çº¿ï¼šæŒä»“-ä»·æ ¼èƒŒç¦»åº¦>2ä¸”ä¸ºè´Ÿå€¼åˆ™å‡ä»“' +
            '   - æ¯å‘¨é‡æ–°è¯„ä¼°å¸‚åœºæ¨¡å¼')}
            
            ğŸ“Œ é£é™©æç¤ºï¼š
            - 2025å¹´12æœˆå¸‚åœºç‰¹å¾ï¼šåœ°ç¼˜æ”¿æ²»å†²çªå¯èƒ½åŠ å‰§å•†å“çŸ­ç¼ºï¼Œéœ€ç‰¹åˆ«å…³æ³¨Backwardationç»“æ„
            - æœ¬åˆ†æåŸºäºå†å²æ•°æ®ï¼Œæç«¯è¡Œæƒ…ä¸‹æŒ‡æ ‡å¯èƒ½å¤±æ•ˆ
            - å»ºè®®ç»“åˆåŸºæœ¬é¢æ•°æ®ç»¼åˆåˆ¤æ–­
            
            ğŸ” æ·±åº¦æ´å¯Ÿï¼š
            {('èµ„é‡‘æµå‘é¢†å…ˆæœŸé™ç»“æ„å˜åŒ–çº¦' + str(-best_lag) + 'å¤©ï¼Œå¯ä½œä¸ºæ—©æœŸé¢„è­¦ä¿¡å·ã€‚'
            if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag < 0
            else 'æœŸé™ç»“æ„å˜åŒ–å…ˆäºèµ„é‡‘æµå‘å˜åŒ–çº¦' + str(best_lag) + 'å¤©ï¼Œéœ€ä¼˜å…ˆå…³æ³¨æœŸé™ç»“æ„ã€‚'
            if 'é¢†å…ˆ' in lead_lag_summary and best_lag and best_lag > 0
            else 'èµ„é‡‘æµå‘ä¸æœŸé™ç»“æ„åŒæ­¥å˜åŒ–ï¼Œéœ€åŒæ—¶ç›‘æ§ä¸¤ç±»æŒ‡æ ‡ã€‚')}
            å½“è¶‹åŠ¿è¡°ç«­ä¿¡å·è§¦å‘åï¼Œæœªæ¥{int(abs(best_lag)) + 3 if best_lag else '5'}å¤©å†…è¶‹åŠ¿åè½¬æ¦‚ç‡å¹³å‡ä¸Šå‡{abs(best_corr) * 100:.0f}%ã€‚
            
            ğŸ’¡ ç‰¹åˆ«æç¤ºï¼š
            è¯¥æœŸè´§å½“å‰è¡¨ç°{('å•†å“çŸ­ç¼ºç‰¹å¾æ˜¾è‘—' if commodity_shortage_mode else
            'è¶‹åŠ¿è¡°ç«­ç‰¹å¾æ˜æ˜¾' if trend_exhaustion_mode else
            'é—ªå´©é£é™©æé«˜' if flash_crash_mode else
            'ä¸')}åŒç±»æœŸè´§æ•´ä½“æ°´å¹³ï¼Œ{('å»ºè®®' if commodity_shortage_mode or flash_crash_mode else 'è°¨æ…')}{'åšå¤šè¿‘æœˆ' if commodity_shortage_mode else 'å‡ä»“' if trend_exhaustion_mode or flash_crash_mode else 'ç»´æŒä»“ä½'}
            """.strip()

        return summary

    def _analyze_option(self):
        pass

    # def construct_contract_features(
    #         self,
    #         contract_type: str,
    #         order_book_id: [str],
    #         start_date: str,
    #         end_date: str,
    # ) -> str:
    #     """
    #     æ„å»ºé€‚ç”¨äºå¤šç§åˆçº¦ç±»å‹çš„å…¨é¢ç‰¹å¾é›†ï¼Œä¸æ¶‰åŠèšåˆæ“ä½œ
    #     :param order_book_id: ç”¨æˆ·æŒ‡å®šçš„åˆçº¦ä»£ç åˆ—è¡¨ï¼Œä»…å¯¹æ­¤éƒ¨åˆ†æ ·æœ¬å¼€å±•ç‰¹å¾å·¥ç¨‹
    #     :param contract_type: åˆçº¦ç±»å‹ ('CS', 'ETF', 'INDX', 'Future', 'Option')
    #     :param start_date: æ•°æ®çš„èµ·å§‹æ—¥æœŸ
    #     :param end_date: æ•°æ®çš„ç»ˆæ­¢æ—¥æœŸ
    #     :return: åŒ…å«æ‰€æœ‰ç‰¹å¾çš„DataFrameçš„å­˜å‚¨åœ°å€
    #     """
    #     df_addr, df_fields = self.ricequant_service.instruments_features_fetching(contract_type, int(start_date), int(end_date))
    #     df = pd.read_csv(df_addr)
    #     order_book_id_str = None
    #     if order_book_id:
    #         order_book_id_str = ','.join(sorted(order_book_id))
    #     order_book_id_hash = hashlib.md5(order_book_id_str.encode('utf-8')).hexdigest()[:10]
    #     output_path = os.path.join(self.features_data_path, f"{start_date}_{end_date}_{order_book_id_hash}_{contract_type}_features_data.csv")
    #     if os.path.exists(output_path):
    #         print("ç‰¹å¾æ–‡ä»¶å·²å­˜åœ¨ï¼")
    #         return output_path
    #     else:
    #         print("ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¼€å§‹ç”Ÿæˆ")
    #
    #     # 1. åŸºç¡€æ•°æ®éªŒè¯å¹¶é€‰æ‹©åˆé€‚çš„æ ·æœ¬&æŒ‰æ—¶é—´æ’åº
    #     if df.empty:
    #         raise ValueError("è¾“å…¥æ•°æ®ä¸ºç©º")
    #     if order_book_id and 'order_book_id' in df.columns:     # ç­›é€‰å‡ºorder_book_idåœ¨ç»™å®šåˆ—è¡¨ä¸­çš„è¡Œ
    #         df = df[df['order_book_id'].isin(order_book_id)]
    #     if 'date' in df.columns:
    #         df = df.sort_values(['date', 'order_book_id'])   # æ•´ä½“æ•°æ®ä¼˜å…ˆã€æŒ‰ç…§æ—¶é—´æ’åºã€‘
    #
    #     # 2. æ ‡å‡†åŒ–åˆ—åï¼ˆå¤„ç†å¯èƒ½çš„å¤§å°å†™å·®å¼‚ï¼‰
    #     df = df.copy()
    #     df.columns = [col.lower() for col in df.columns]
    #
    #     # 3. æŒ‰åˆçº¦ç±»å‹æ„é€ ç‰¹å¾
    #     if contract_type not in ['CS', 'ETF', 'INDX', 'Future', 'Option']:
    #         raise ValueError(f"ä¸æ”¯æŒçš„åˆçº¦ç±»å‹: {contract_type}. å¿…é¡»æ˜¯ CS, ETF, INDX, Future, Option")
    #
    #     # 4. åˆå§‹åŒ–ç‰¹å¾DataFrame
    #     features = pd.DataFrame(index=df.index)
    #     features['date'] = df['date']
    #     features['order_book_id'] = df['order_book_id']
    #     features['close'] = df['close']
    #
    #     # å…³é”®æ­¥éª¤ï¼šåˆ›å»ºåˆ†ç»„å¯¹è±¡
    #     grouped = df.groupby('order_book_id')
    #
    #     """ ===== å…±äº«åŸºç¡€ç‰¹å¾ (æ‰€æœ‰åˆçº¦ç±»å‹) ===== """
    #     # ä»·æ ¼ç‰¹å¾
    #     features['returns'] = grouped['close'].transform(lambda x: x.pct_change())
    #     features['log_returns'] = grouped['close'].transform(lambda x: np.log(x / x.shift(1)))
    #
    #     df['returns'] = features['returns']     # æ— éœ€é‡æ–°åˆ›å»º groupedï¼Œå› ä¸º df å·²ç»æ›´æ–°ï¼Œgrouped ä¼šåœ¨è®¿é—®æ—¶ä½¿ç”¨ df çš„æœ€æ–°åˆ—
    #     df['log_returns'] = features['log_returns']
    #
    #     # æ³¢åŠ¨ç‡ç‰¹å¾
    #     features['vol_10d'] = grouped['returns'].transform(lambda x: x.rolling(10).std()) * np.sqrt(252)
    #     features['vol_20d'] = grouped['returns'].transform(lambda x: x.rolling(20).std()) * np.sqrt(252)
    #     features['vol_60d'] = grouped['returns'].transform(lambda x: x.rolling(60).std()) * np.sqrt(252)
    #     features['vol_ratio_20_60'] = features['vol_20d'] / features['vol_60d']  # æ³¢åŠ¨ç‡æ–œç‡
    #
    #     # è¶‹åŠ¿ç‰¹å¾
    #     features['ma_5d'] = grouped['close'].transform(lambda x: x / x.rolling(5).mean() - 1)
    #     features['ma_20d'] = grouped['close'].transform(lambda x: x / x.rolling(20).mean() - 1)
    #     features['ma_60d'] = grouped['close'].transform(lambda x: x / x.rolling(60).mean() - 1)
    #
    #     # åŠ¨é‡ç‰¹å¾
    #     df['ma_20d'] = features['ma_20d']
    #     features['ma_momentum'] = grouped['ma_20d'].transform(lambda x: x - x.shift(5))
    #
    #     # çœŸå®æ³¢å¹…ç‰¹å¾
    #     if 'high' in df.columns and 'low' in df.columns and 'prev_close' in df.columns:
    #         # çœŸå®æ³¢å¹…è®¡ç®—
    #         def calculate_true_range(group):
    #             prev_close_shifted = group['prev_close'].shift(1)
    #             true_range_val = np.maximum(
    #                 group['high'] - group['low'],
    #                 np.maximum(
    #                     abs(group['high'] - prev_close_shifted),
    #                     abs(group['low'] - prev_close_shifted)
    #                 )
    #             )
    #             # ä½¿ç”¨å‰ä¸€æ—¥æ”¶ç›˜ä»·è®¡ç®—ç™¾åˆ†æ¯”TRï¼Œæ³¨æ„åˆ†æ¯ä¹Ÿéœ€è¦ shift(1)
    #             return true_range_val / group['prev_close'].shift(1)
    #
    #         features['true_range'] = grouped.apply(calculate_true_range, include_groups=False).reset_index(level=0, drop=True)
    #         # ATR
    #         df['true_range'] = features['true_range']
    #         features['atr_14d'] = grouped['true_range'].transform(lambda x: x.rolling(14).mean())
    #
    #     """ ===== æŒ‰åˆçº¦ç±»å‹æ·»åŠ ç‰¹å®šç‰¹å¾ ===== """
    #     if contract_type in ['CS', 'ETF']:
    #         """ ===== è‚¡ç¥¨/ETF ç‰¹æœ‰ç‰¹å¾ ===== """
    #         # é‡èƒ½ç‰¹å¾
    #         if 'volume' in df.columns:
    #             # æ»šåŠ¨å‡å€¼
    #             features['volume_10d_ma'] = grouped['volume'].transform(lambda x: x.rolling(10).mean())
    #             features['volume_ratio'] = df['volume'] / features['volume_10d_ma']
    #             # åŠ¨é‡
    #             df['volume_ratio'] = features['volume_ratio']
    #             features['volume_momentum'] = grouped['volume_ratio'].transform(lambda x: x - x.shift(5))
    #
    #         if 'total_turnover' in df.columns:
    #             # æ¢æ‰‹ç‡ä¸å‡å€¼æ¯”
    #             features['turnover_ratio'] = grouped['total_turnover'].transform(lambda x: x / x.rolling(30).mean())
    #
    #         # äº¤æ˜“æ´»è·ƒåº¦ç‰¹å¾
    #         if 'num_trades' in df.columns:
    #             features['trade_frequency'] = df['num_trades'] / df['volume']
    #             # 20æ—¥å‡å€¼
    #             df['trade_frequency'] = features['trade_frequency']
    #             features['trade_frequency_20d_ma'] = grouped['trade_frequency'].transform(lambda x: x.rolling(20).mean())
    #             features['trade_frequency_ratio'] = features['trade_frequency'] / features['trade_frequency_20d_ma']
    #
    #         # å¸‚åœºçŠ¶æ€ç‰¹å¾
    #         if all(col in df.columns for col in ['close', 'limit_up', 'limit_down']):
    #             features['is_limit_up'] = (df['close'] >= df['limit_up'] * 0.995).astype(int)
    #             features['is_limit_down'] = (df['close'] <= df['limit_down'] * 1.005).astype(int)
    #             # 20æ—¥è®¡æ•°
    #             df['is_limit_up'] = features['is_limit_up']
    #             df['is_limit_down'] = features['is_limit_down']
    #             features['limit_up_count_20d'] = grouped['is_limit_up'].transform(lambda x: x.rolling(20).sum())
    #             features['limit_down_count_20d'] = grouped['is_limit_down'].transform(lambda x: x.rolling(20).sum())
    #
    #         # æ¢æ‰‹ç‡ç‰¹å¾ï¼ˆè‚¡ç¥¨ç‰¹æœ‰ï¼‰ï¼šæ­¤å¤„æ¶‰åŠå¤–éƒ¨æ•°æ®ï¼Œåˆ†ç»„å¤„ç†éš¾åº¦å¤§ï¼Œä¿æŒåŸé€»è¾‘ä½†éœ€æ³¨æ„å¤–éƒ¨æ•°æ®å¯¹é½
    #         features['turnover_rate_approx'] = df['total_turnover'] / (df['close'] * df['volume'])
    #         df['turnover_rate_approx'] = features['turnover_rate_approx']
    #
    #     elif contract_type == 'INDX':
    #         """ ===== æŒ‡æ•°ç‰¹æœ‰ç‰¹å¾ ===== """
    #         # å¸‚åœºå¹¿åº¦æŒ‡æ ‡
    #         if 'high' in df.columns and 'low' in df.columns:
    #             # æŒ‡æ•°æ³¢åŠ¨èŒƒå›´
    #             features['index_range'] = grouped[['high', 'low', 'close']].apply(
    #                 lambda x: (x['high'] - x['low']) / x['close'].shift(1),
    #                 include_groups=False
    #             ).reset_index(level=0, drop=True)
    #             # 20æ—¥å‡å€¼
    #             df['index_range'] = features['index_range']
    #             features['index_range_20d_ma'] = grouped['index_range'].transform(lambda x: x.rolling(20).mean())
    #
    #         # æŒ‡æ•°åŠ¨é‡å¼ºåº¦
    #         features['index_momentum_strength'] = features['returns'] / features['vol_20d']
    #
    #     elif contract_type in ['Future', 'Option']:
    #         """ ===== æœŸè´§/æœŸæƒç‰¹æœ‰ç‰¹å¾ ===== """
    #         # æŒä»“é‡ç‰¹å¾ï¼ˆæœŸè´§/æœŸæƒï¼‰
    #         if 'open_interest' in df.columns:
    #             # 1æ—¥/5æ—¥å˜åŒ–
    #             features['oi_1d_change'] = grouped['open_interest'].transform(lambda x: x.pct_change())
    #             features['oi_5d_change'] = grouped['open_interest'].transform(lambda x: x.pct_change(5))
    #             # åŠ¨é‡
    #             df['oi_1d_change'] = features['oi_1d_change']
    #             features['oi_momentum'] = grouped['oi_1d_change'].transform(lambda x: x - x.rolling(5).mean())
    #
    #         settlement_col = 'settlement' if 'settlement' in df.columns else 'close'
    #         features['settlement'] = df[settlement_col]
    #
    #         # æœŸè´§ç‰¹æœ‰ç‰¹å¾ï¼šåŸºå·®å’ŒæœŸé™ç»“æ„æ¶‰åŠå¤šä¸ªåˆçº¦çš„æ•°æ®å¯¹é½ï¼Œæ­¤å¤„ä¿æŒåŸé€»è¾‘ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ
    #
    #     elif contract_type == 'Option':
    #         # è¡Œæƒä»·ç›¸å…³ç‰¹å¾
    #         if 'strike_price' in df.columns:
    #             features['moneyness'] = df['close'] / df['strike_price']
    #             # 20æ—¥å‡å€¼
    #             df['moneyness'] = features['moneyness']
    #             features['moneyness_20d_ma'] = grouped['moneyness'].transform(lambda x: x.rolling(20).mean())
    #             features['moneyness_deviation'] = features['moneyness'] - features['moneyness_20d_ma']
    #         # éšå«æ³¢åŠ¨ç‡ä¼°ç®—ï¼ˆç®€åŒ–ç‰ˆï¼‰
    #         if 'strike_price' in df.columns and 'settlement' in df.columns:
    #             time_to_expiry = 30
    #             # éšå«æ³¢åŠ¨ç‡çš„è®¡ç®—ä¸æ¶‰åŠæ»šåŠ¨æˆ– shiftï¼Œä½†ä½¿ç”¨ apply ç¡®ä¿åœ¨ç»„å†…æ“ä½œ
    #             features['implied_vol'] = grouped[['settlement', 'strike_price']].apply(
    #                 lambda x: np.sqrt(2 * np.pi / time_to_expiry) * (x['settlement'] / x['strike_price']),
    #                 include_groups=False
    #             ).reset_index(level=0, drop=True)
    #
    #     """ ===== æ‰€æœ‰åˆçº¦ç±»å‹é€šç”¨çš„é«˜çº§ç‰¹å¾ ===== """
    #     # é£é™©è°ƒæ•´æ”¶ç›Š
    #     # å¤æ™®æ¯”ç‡
    #     features['sharpe_20d'] = grouped['returns'].transform(lambda x: x.rolling(20).mean()) / features[
    #         'vol_20d'] * np.sqrt(252)
    #     df['sharpe_20d'] = features['sharpe_20d']
    #
    #     # æ³¢åŠ¨ç‡çŠ¶æ€ (qcut æ˜¯å…¨å±€æ“ä½œï¼Œæ— éœ€åˆ†ç»„è®¡ç®—)
    #     features['vol_regime'] = pd.qcut(features['vol_20d'], q=5, labels=False, duplicates='drop') / 4
    #     df['vol_regime'] = features['vol_regime']
    #
    #     # è¶‹åŠ¿å¼ºåº¦
    #     trend_window = 20
    #     # æ»šåŠ¨æ ‡å‡†å·®å’Œå‡å€¼
    #     price_std = grouped['close'].transform(lambda x: x.rolling(trend_window).std())
    #     price_mean = grouped['close'].transform(lambda x: x.rolling(trend_window).mean())
    #     features['trend_strength'] = (df['close'] - price_mean) / (price_std + 1e-10)
    #     df['trend_strength'] = features['trend_strength']
    #
    #     # å°¾éƒ¨é£é™©æŒ‡æ ‡
    #     # VaR
    #     features['var_95'] = grouped['returns'].transform(lambda x: x.rolling(60).quantile(0.05))
    #     df['var_95'] = features['var_95']
    #
    #     # CVaR(æ¡ä»¶é£é™©ä»·å€¼)
    #     df['cvar_returns_filtered'] = features['returns'].where(features['returns'] <= features['var_95'])
    #     features['cvar_95'] = grouped['cvar_returns_filtered'].transform(lambda x: x.rolling(60, min_periods=1).mean())   # åœ¨æ¯ä¸ªåˆçº¦åˆ†ç»„å†…ï¼Œå¯¹è¿‡æ»¤åçš„ï¼ˆç¨€ç–ï¼‰æ”¶ç›Šç‡è®¡ç®—æ»šåŠ¨å¹³å‡ã€‚
    #     df.drop(columns=['cvar_returns_filtered'], inplace=True)
    #
    #     # å¸‚åœºçŠ¶æ€ç»¼åˆæŒ‡æ ‡ (åŸºäºå·²åˆ†ç»„è®¡ç®—çš„ç‰¹å¾ï¼Œæ— éœ€å†åˆ†ç»„)
    #     features['market_regime'] = (
    #         0.4 * features['vol_regime'] +
    #         0.3 * abs(features['trend_strength']) +
    #         0.3 * (1 - features['sharpe_20d'].clip(lower=0, upper=1))
    #     )
    #
    #     """ ===== ç‰¹å¾å·¥ç¨‹åå¤„ç† ===== """
    #     MAX_ROLLING_WINDOW = settings.financial_data.features_max_rolling_window
    #     features = features.groupby('order_book_id').apply(
    #         lambda x: x.iloc[MAX_ROLLING_WINDOW:, :],
    #         include_groups=False
    #     ).reset_index(level=0, drop=False)      # æŒ‰ order_book_id åˆ†ç»„ï¼Œä¸¢å¼ƒæ¯ä¸ªåˆ†ç»„çš„å‰ MAX_ROLLING_WINDOW è¡Œ
    #     features = features.reset_index(drop=True)
    #     features = features.replace([np.inf, -np.inf], np.nan)
    #
    #     # å¡«å……å¿…é¡»åœ¨åˆ†ç»„åè¿›è¡Œï¼Œä»¥é¿å…ä½¿ç”¨ä¸‹ä¸€åªè‚¡ç¥¨çš„æ•°æ®å¡«å……å‰ä¸€åªè‚¡ç¥¨çš„NaN
    #     features_grouped_for_fillna = features.groupby('order_book_id')
    #     features = features_grouped_for_fillna.apply(
    #         lambda x: x.fillna(method='ffill'), include_groups=False).reset_index(level=0, drop=False)   # ä¸å¯ä½¿ç”¨bfillï¼Œé¿å…æœªæ¥ä¿¡æ¯æ³„éœ²
    #     features = features.fillna(0)
    #     features = features.reset_index(drop=True)
    #
    #     # # ç¡®ä¿æ‰€æœ‰ç‰¹å¾åœ¨åˆç†èŒƒå›´å†… (å…¨å±€ç»Ÿè®¡æ“ä½œï¼Œä¿æŒä¸å˜)
    #     # for col in features.columns:
    #     #     if features[col].dtype in [np.float64, np.float32]:
    #     #         mean = features[col].mean()
    #     #         std = features[col].std()
    #     #         lower_bound = mean - 5 * std
    #     #         upper_bound = mean + 5 * std
    #     #         features[col] = features[col].clip(lower=lower_bound, upper=upper_bound)
    #
    #     # ç§»é™¤å¯èƒ½ç”± apply å¼•å…¥çš„é¢å¤–ç´¢å¼•
    #     features = features.sort_values(['date', 'order_book_id'])
    #     features.to_csv(output_path, index=False)
    #     return output_path


if __name__ == '__main__':
    ml_service = MLService()
    cs_list = ['000001.XSHE', '000002.XSHE', '000004.XSHE']
    etf_list = ['159001.XSHE', '159003.XSHE', '159005.XSHE']
    index_list = ['000001.XSHG', '000002.XSHG', '000003.XSHG']
    future_list = ['A2601', 'A2603', 'A2605']
    # print(ml_service.construct_contract_features('CS', cs_list, '20240401', '20251128'))
    # print(ml_service.summarize_CSanalysis(start_date=20250401,
    #    end_date=20251128,
    #    target_stock_id='000002.XSHE',
    #    order_book_id_list=cs_list))
    # print(ml_service.summarize_ETFanalysis(start_date=20250401,
    #     end_date=20251128,
    #     target_ETF_id='159003.XSHE',
    #     order_book_id_list=etf_list))
    # print(ml_service.summarize_INDXanalysis(start_date=20250401,
    #     end_date=20251128,
    #     target_index_id='000003.XSHG',
    #     index_id_list=index_list))
    print(ml_service.summarize_Futureanalysis(20250401, 20251128, 'A2603', future_list))

