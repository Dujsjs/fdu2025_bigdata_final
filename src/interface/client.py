from src.agent.chat_engine import create_invest_agent
from src.services.llm_service import init_llm_and_embed_models
from src.agent.tools import get_rag_service
import asyncio


async def main_async():
    # 1. åˆå§‹åŒ– LLM å’Œ Embedding æ¨¡å‹ (ä¿æŒä¸å˜)
    try:
        init_llm_and_embed_models()
    except Exception as e:
        print(f"è‡´å‘½é”™è¯¯ï¼šLLM æˆ– Embedding æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ã€‚è¯·æ£€æŸ¥ models é…ç½®ã€‚é”™è¯¯: {e}")
        return

    # 2. å¼ºåˆ¶åˆå§‹åŒ– RAGService (ä¿æŒä¸å˜)
    print("åˆå§‹åŒ– RAG çŸ¥è¯†åº“...")
    try:
        rag_service = get_rag_service()
        rag_service.get_query_engine()
    except Exception as e:
        print(f"è‡´å‘½é”™è¯¯ï¼šRAG ç´¢å¼•åŠ è½½æˆ–æ„å»ºå¤±è´¥ã€‚è¯·æ£€æŸ¥ data/raw å’Œ data/storage ç›®å½•ã€‚é”™è¯¯: {e}")
        return

    # 3. åˆ›å»º Agent
    invest_agent = create_invest_agent()

    print("\n--- AI æŠ•èµ„é¡¾é—®å¯åŠ¨æˆåŠŸ ---")
    print("è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡ºã€‚")

    # 4. è¿›å…¥å¾ªç¯èŠå¤©
    while True:
        try:
            user_input = input("\nğŸ‘¤ æ‚¨: ")
            if user_input.lower() in ["quit", "exit"]:
                print("æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
                break

            print("æ€è€ƒä¸­... (Agent æ­£åœ¨æ¨ç†å’Œè°ƒåº¦å·¥å…·)")
            response = await invest_agent.run(user_input)
            final_answer = response.response
            print(f"\nğŸ¤– é¡¾é—®: {final_answer}")

        except Exception as e:
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
            if "out of memory" in str(e).lower():
                break


# å®šä¹‰åŒæ­¥ main å‡½æ•°ä½œä¸ºå…¥å£ç‚¹ï¼Œå¯åŠ¨å¼‚æ­¥äº‹ä»¶å¾ªç¯
def main():
    # å¯åŠ¨å¼‚æ­¥äº‹ä»¶å¾ªç¯
    asyncio.run(main_async())


if __name__ == "__main__":
    main()